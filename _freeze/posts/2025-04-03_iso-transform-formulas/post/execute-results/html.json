{
  "hash": "992a72a01f20963dc4d3af3f11d9f299",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Improving Cross-Cultural Soundscape Assessment: A Refined Approach to Normalization Factors\"\nauthor: \"Soundscape Research Team\"\ndate: \"2024-04-03\"\nformat: html\njupyter: python3\n---\n\n\n\n\n\n## Introduction\n\nThe assessment and characterization of soundscapes across different cultures and languages present significant methodological challenges. In particular, the standardized approach outlined in the ISO 12913 series for soundscape assessment must be adaptable to diverse linguistic and cultural contexts while maintaining conceptual integrity.\n\nDuring our work on the Soundscape Attributes Translation Project (SATP), which involved translating standardized soundscape descriptors into multiple languages, we identified an important limitation in the normalization method when applied to non-equally spaced perceptual attributes around the circumplex model. This blog post presents a refined approach to the normalization factors used in soundscape assessment that significantly improves cross-cultural comparability.\n\nWe will demonstrate how this refinement preserves the original methodology's strengths while extending its applicability to diverse linguistic and cultural contexts. Through mathematical derivation, implementation testing, and Monte Carlo simulations, we provide evidence for the improved performance of the proposed approach.\n\n::: {#9375f79f .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n:::\n\n\n## The Soundscape Circumplex Model: Background\n\nSoundscape assessment is typically conducted within a circumplex model framework where different perceptual attributes (pleasant, vibrant, eventful, chaotic, annoying, monotonous, uneventful, and calm) are arranged in a circular pattern. The original model, as conceptualized in the ISO 12913 series, positioned these attributes at equally spaced 45° intervals around a circle.\n\nThe original method for calculating the coordinates in this perceptual space was based on direct differences between opposing attributes:\n\n$$P = (p - a) + \\cos45° \\cdot (ca - ch) + \\cos45° \\cdot (v - m)$$ $$E = (e - u) + \\cos45° \\cdot (ch - ca) + \\cos45° \\cdot (v - m)$$\n\nWhere: - p = pleasant, a = annoying - e = eventful, u = uneventful - ca = calm, ch = chaotic - v = vibrant, m = monotonous - cos45° ≈ 0.7071\n\nThis approach was later generalized in the ISO 12913-3 standard to a trigonometric formulation that accommodates varying angles:\n\n$$P_{ISO} = \\frac{1}{\\lambda_{Pl}}\\sum_{i=1}^{8}\\cos(\\theta_i) \\times \\sigma_i$$\n\n$$E_{ISO} = \\frac{1}{\\lambda_{Ev}}\\sum_{i=1}^{8}\\sin(\\theta_i) \\times \\sigma_i$$\n\nWith scaling factors:\n\n$$\\lambda_{Pl} = \\frac{\\rho}{2}\\sum_{i=1}^{8}|\\cos(\\theta_i)|$$\n\n$$\\lambda_{Ev} = \\frac{\\rho}{2}\\sum_{i=1}^{8}|\\sin(\\theta_i)|$$\n\nWhere: - $\\theta_i$ is the angle for each circumplex scale - $\\sigma_i$ is the score for each scale - $\\rho$ is the range of possible response values (e.g., $\\rho = 4$ for a 5-point Likert scale with values 1-5)\n\n## A First-Principles Approach to Generalization\n\nTo understand why a refinement is needed, let's revisit the original formula and systematically derive a generalized form from first principles. This approach will allow us to identify the most appropriate normalization method.\n\n### Understanding the Key Principles\n\nThe original direct difference formula for pleasantness encodes three key insights:\n\n1.  **Direct opposition**: Attributes that are 180° apart directly oppose each other (pleasant vs annoying)\n2.  **Weighted contribution**: Attributes at 45° angles contribute partially to pleasantness\n3.  **Projection principle**: The cos45° factor represents how much these angled attributes project onto the pleasantness axis\n\n### Step 1: Represent Each Attribute's Contribution Through Projection\n\nIn the original formula, each attribute contributes to pleasantness based on its angular position. Generalizing this, each attribute should contribute based on how it projects onto the pleasantness dimension (the horizontal axis):\n\n$$\\text{Contribution of attribute } i = \\cos(\\theta_i) \\times \\sigma_i$$\n\n### Step 2: Sum All Contributions\n\nInstead of explicitly writing out each pair of opposing attributes, we can sum the contributions from all attributes:\n\n$$P_{\\text{raw}} = \\sum_{i=1}^{n} \\cos(\\theta_i) \\times \\sigma_i$$\n\nWhere n is the total number of attributes (typically 8).\n\n### Step 3: Determine the Proper Normalization Factor\n\nThe original formula has an implicit normalization that ensures the result falls within a certain range. To determine the appropriate normalization, we need to consider the maximum possible value of P_raw.\n\nThe maximum value would occur when: - Attributes with positive cosine values (those contributing positively to pleasantness) receive maximum scores - Attributes with negative cosine values (those contributing negatively) receive minimum scores\n\nIf we have a scale from 1 to 5 (range ρ = 4), then: - Maximum contribution from attribute i = ρ × cos(θᵢ) if cos(θᵢ) \\> 0 - Minimum contribution from attribute i = 0 × cos(θᵢ) = 0 if cos(θᵢ) \\< 0 (since we'd give minimum scores to negative contributors)\n\nSo the maximum value would be: $$P_{\\text{max}} = \\rho \\times \\sum_{i=1}^{n} \\max(0, \\cos(\\theta_i))$$\n\nSimilarly, the minimum value would be: $$P_{\\text{min}} = \\rho \\times \\sum_{i=1}^{n} \\min(0, \\cos(\\theta_i))$$\n\nThe total range is thus: $$\\text{Range} = P_{\\text{max}} - P_{\\text{min}} = \\rho \\times [\\sum \\max(0, \\cos(\\theta_i)) - \\sum \\min(0, \\cos(\\theta_i))]$$\n\nSince min(0, cos(θᵢ)) = -max(0, -cos(θᵢ)), and for a balanced set of attributes, the sum of positive cosines equals the absolute sum of negative cosines, the range becomes:\n\n$$\\text{Range} = 2\\rho \\times \\sum \\max(0, \\cos(\\theta_i))$$\n\nTo normalize to \\[-1, +1\\], we divide by half this range:\n\n$$\\lambda_{pl} = \\rho \\times \\sum \\max(0, \\cos(\\theta_i))$$\n\n### Step 4: Formulate the Complete Generalized Equation\n\nPutting it all together, the generalized formula becomes:\n\n$$P_{ISO} = \\frac{\\sum_{i=1}^{n} \\cos(\\theta_i) \\times \\sigma_i}{\\rho \\times \\sum_{i=1}^{n} \\max(0, \\cos(\\theta_i))}$$\n\nThis can be written more compactly as:\n\n$$P_{ISO} = \\frac{1}{\\lambda_{pl}}\\sum_{i=1}^{n}\\cos(\\theta_i) \\times \\sigma_i$$\n\nWhere: $$\\lambda_{pl} = \\rho\\sum_{i=1}^{n} \\max(0,\\cos \\theta_i)$$\n\nThe same principles apply to the eventfulness dimension, with sine replacing cosine:\n\n$$E_{ISO} = \\frac{\\sum_{i=1}^{n} \\sin(\\theta_i) \\times \\sigma_i}{\\rho \\times \\sum_{i=1}^{n} \\max(0, \\sin(\\theta_i))}$$\n\n### Verifying the Generalization\n\nTo verify this generalization, let's check with the standard 8 attributes at 45° intervals:\n\nWith angles \\[0°, 45°, 90°, 135°, 180°, 225°, 270°, 315°\\], the cosine values are: \\[1, 0.7071, 0, -0.7071, -1, -0.7071, 0, 0.7071\\]\n\nThe sum of positive cosines is: 1 + 0.7071 + 0 + 0.7071 = 2.4142\n\nWith ρ = 4, λₚₗ = 4 × 2.4142 = 9.6568, which is very close to the original normalization factor (4 + √32) ≈ 9.66.\n\nThis first-principles derivation reveals that the most appropriate normalization factor should only consider positive contributions to each dimension, rather than using the absolute values as in the original ISO 12913-3 approach.\n\n## Comparing the Original and Refined Approaches\n\nThe normalization approach in the ISO 12913-3 standard uses the absolute values of sine and cosine:\n\n$$\\lambda_{Pl} = \\frac{\\rho}{2}\\sum_{i=1}^{8}|\\cos(\\theta_i)|$$\n\n$$\\lambda_{Ev} = \\frac{\\rho}{2}\\sum_{i=1}^{8}|\\sin(\\theta_i)|$$\n\nOur first-principles analysis suggests that a more theoretically sound approach would be:\n\n$$\\lambda_{pl} = \\rho\\sum_{i=1}^{8} \\max(0,\\cos \\theta_i)$$\n\n$$\\lambda_{ev} = \\rho\\sum_{i=1}^{8} \\max(0,\\sin \\theta_i)$$\n\nThis refinement can also be expressed as:\n\n$$\\lambda_{pl} = \\frac{\\rho}{2} \\sum_{i=1}^{8} (|\\cos \\theta_i| + \\cos \\theta_i)$$\n\n$$\\lambda_{ev} = \\frac{\\rho}{2} \\sum_{i=1}^{8} (|\\sin \\theta_i| + \\sin \\theta_i)$$\n\nThe refined approach addresses the limitation of the original method when dealing with non-equally spaced angles—a common situation in cross-cultural contexts.\n\n## Mathematical Derivation of the Refined Formula\n\nLet's examine the expression $(|\\sin \\theta_i| + \\sin \\theta_i)$ to understand its behavior:\n\n1.  When $\\sin \\theta_i \\geq 0$ (angles between 0° and 180°): $|\\sin \\theta_i| = \\sin \\theta_i$, so $(|\\sin \\theta_i| + \\sin \\theta_i) = 2\\sin \\theta_i$\n\n2.  When $\\sin \\theta_i < 0$ (angles between 180° and 360°): $|\\sin \\theta_i| = -\\sin \\theta_i$, so $(|\\sin \\theta_i| + \\sin \\theta_i) = (-\\sin \\theta_i) + \\sin \\theta_i = 0$\n\nTherefore, the expression $(|\\sin \\theta_i| + \\sin \\theta_i)$ equals $2\\sin \\theta_i$ when sine is positive, and 0 when sine is negative. This can be represented as $2\\max(0, \\sin \\theta_i)$. Substituting this into our formula:\n\n$$\\lambda_{ev} = \\frac{\\rho}{2} \\sum_{i=1}^{8} (|\\sin \\theta_i| + \\sin \\theta_i) = \\frac{\\rho}{2} \\sum_{i=1}^{8} 2\\max(0, \\sin \\theta_i) = \\rho\\sum_{i=1}^{8} \\max(0, \\sin \\theta_i)$$\n\nThe equivalent derivation applies to $\\lambda_{pl}$ using cosine values.\n\nThis refinement addresses the problem by considering only positive contributions to each dimension. For the eventfulness dimension, only attributes with angles between 0° and 180° contribute to the normalization factor. For the pleasantness dimension, only attributes with angles between 270° and 90° (through 0°) contribute.\n\n## Implementation and Testing\n\nLet's implement both the original and refined normalization factors and test them with various angle configurations:\n\n::: {#69d4241b .cell execution_count=2}\n``` {.python .cell-code}\n# Function to calculate the original lambda_ev\ndef original_lambda_ev(angles, rho=4):\n    \"\"\"\n    Calculate the original lambda_ev\n    \n    Parameters:\n    angles (array): Array of angles in degrees for the 8 scales\n    rho (float): Range of possible response values (default 4 for 5-point Likert scale)\n    \n    Returns:\n    float: The lambda_ev scaling factor\n    \"\"\"\n    angles_rad = np.radians(angles)\n    return (rho/2) * np.sum(np.abs(np.sin(angles_rad)))\n\n# Function to calculate the refined lambda_ev\ndef refined_lambda_ev(angles, rho=4):\n    \"\"\"\n    Calculate the refined lambda_ev using max(0, sin) approach\n    \n    Parameters:\n    angles (array): Array of angles in degrees for the 8 scales\n    rho (float): Range of possible response values (default 4 for 5-point Likert scale)\n    \n    Returns:\n    float: The refined lambda_ev scaling factor\n    \"\"\"\n    angles_rad = np.radians(angles)\n    return rho * np.sum(np.maximum(0, np.sin(angles_rad)))\n\n# Function to calculate the original lambda_pl\ndef original_lambda_pl(angles, rho=4):\n    \"\"\"\n    Calculate the original lambda_pl\n    \n    Parameters:\n    angles (array): Array of angles in degrees for the 8 scales\n    rho (float): Range of possible response values (default 4 for 5-point Likert scale)\n    \n    Returns:\n    float: The lambda_pl scaling factor\n    \"\"\"\n    angles_rad = np.radians(angles)\n    return (rho/2) * np.sum(np.abs(np.cos(angles_rad)))\n\n# Function to calculate the refined lambda_pl\ndef refined_lambda_pl(angles, rho=4):\n    \"\"\"\n    Calculate the refined lambda_pl using max(0, cos) approach\n    \n    Parameters:\n    angles (array): Array of angles in degrees for the 8 scales\n    rho (float): Range of possible response values (default 4 for 5-point Likert scale)\n    \n    Returns:\n    float: The refined lambda_pl scaling factor\n    \"\"\"\n    angles_rad = np.radians(angles)\n    return rho * np.sum(np.maximum(0, np.cos(angles_rad)))\n\n```\n:::\n\n\n### Testing with Equally Spaced Angles\n\nFirst, let's test with the standard equally spaced angles (45° increments) used in the original circumplex model:\n\n::: {#cf6b1672 .cell execution_count=3}\n``` {.python .cell-code}\n# Standard equally spaced angles (45° increments)\nequal_angles = np.array([0, 45, 90, 135, 180, 225, 270, 315])\n\n# Calculate and compare the results for equally spaced angles\nlambda_ev_original = original_lambda_ev(equal_angles)\nlambda_ev_refined = refined_lambda_ev(equal_angles)\n\nlambda_pl_original = original_lambda_pl(equal_angles)\nlambda_pl_refined = refined_lambda_pl(equal_angles)\n\nprint(\"For equally spaced angles:\")\nprint(\"Eventfulness scaling factors:\")\nprint(f\"Original lambda_ev: {lambda_ev_original:.4f}\")\nprint(f\"Refined lambda_ev: {lambda_ev_refined:.4f}\")\n\nprint(\"\\nPleasantness scaling factors:\")\nprint(f\"Original lambda_pl: {lambda_pl_original:.4f}\")\nprint(f\"Refined lambda_pl: {lambda_pl_refined:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFor equally spaced angles:\nEventfulness scaling factors:\nOriginal lambda_ev: 9.6569\nRefined lambda_ev: 9.6569\n\nPleasantness scaling factors:\nOriginal lambda_pl: 9.6569\nRefined lambda_pl: 9.6569\n```\n:::\n:::\n\n\nAs expected, with equally spaced angles, both approaches produce identical results. This confirms that our refinement preserves the behavior of the original method in this standard case.\n\n### Testing with Non-Equally Spaced Angles\n\nNow, let's test with a non-equally spaced angle configuration from our cross-cultural research:\n\n::: {#5f40b145 .cell execution_count=4}\n``` {.python .cell-code}\n# Example from a non-English language translation\nnon_equal_angles = np.array([0, 53, 104, 123, 139, 202, 284, 308])\n\n# Calculate and compare the results for non-equally spaced angles\nlambda_ev_original_ne = original_lambda_ev(non_equal_angles)\nlambda_ev_refined_ne = refined_lambda_ev(non_equal_angles)\n\nlambda_pl_original_ne = original_lambda_pl(non_equal_angles)\nlambda_pl_refined_ne = refined_lambda_pl(non_equal_angles)\n\nprint(\"\\nFor non-equally spaced angles:\")\nprint(\"Eventfulness scaling factors:\")\nprint(f\"Original lambda_ev: {lambda_ev_original_ne:.4f}\")\nprint(f\"Refined lambda_ev: {lambda_ev_refined_ne:.4f}\")\n\nprint(\"\\nPleasantness scaling factors:\")\nprint(f\"Original lambda_pl: {lambda_pl_original_ne:.4f}\")\nprint(f\"Refined lambda_pl: {lambda_pl_refined_ne:.4f}\")\n\n# Let's decompose the calculation to show the components\nangles_rad = np.radians(non_equal_angles)\nabs_sin = np.abs(np.sin(angles_rad))\nsin_values = np.sin(angles_rad)\npos_sin = np.maximum(0, sin_values)\n\nabs_cos = np.abs(np.cos(angles_rad))\ncos_values = np.cos(angles_rad)\npos_cos = np.maximum(0, cos_values)\n\nprint(\"\\nDecomposition of the eventfulness calculation:\")\nprint(f\"Sum of absolute sines: {np.sum(abs_sin):.4f}\")\nprint(f\"Sum of positive sines only: {np.sum(pos_sin):.4f}\")\nprint(f\"Sum of sines: {np.sum(sin_values):.4f}\")\n\nprint(\"\\nDecomposition of the pleasantness calculation:\")\nprint(f\"Sum of absolute cosines: {np.sum(abs_cos):.4f}\")\nprint(f\"Sum of positive cosines only: {np.sum(pos_cos):.4f}\")\nprint(f\"Sum of cosines: {np.sum(cos_values):.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFor non-equally spaced angles:\nEventfulness scaling factors:\nOriginal lambda_ev: 10.7931\nRefined lambda_ev: 13.0546\n\nPleasantness scaling factors:\nOriginal lambda_pl: 9.8557\nRefined lambda_pl: 9.8376\n\nDecomposition of the eventfulness calculation:\nSum of absolute sines: 5.3966\nSum of positive sines only: 3.2637\nSum of sines: 1.1307\n\nDecomposition of the pleasantness calculation:\nSum of absolute cosines: 4.9279\nSum of positive cosines only: 2.4594\nSum of cosines: -0.0091\n```\n:::\n:::\n\n\nWith non-equally spaced angles, the two approaches produce different results. The decomposition reveals why: the imbalance in the distribution of angles affects the sum of sines and cosines. Our refined approach addresses this imbalance by focusing on positive contributions.\n\n## Visual Comparison of Original and Refined Approaches\n\nTo better understand the difference between the two approaches, let's visualize how they treat sine and cosine values:\n\n::: {#06942028 .cell execution_count=5}\n``` {.python .cell-code}\n# Create a range of angles from 0 to 360 degrees\nangles = np.linspace(0, 360, 361)\nangles_rad = np.radians(angles)\n\n# Calculate sine and cosine values\nsin_values = np.sin(angles_rad)\ncos_values = np.cos(angles_rad)\n\n# Calculate the components for both formulas\nabs_sin = np.abs(sin_values)\nmax_sin = np.maximum(0, sin_values)\n\nabs_cos = np.abs(cos_values)\nmax_cos = np.maximum(0, cos_values)\n\n# Set up the figure with two subplots\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n\n# Plot sine functions\nax1.plot(angles, sin_values, label='sin(θ)', linestyle='-')\nax1.plot(angles, abs_sin, label='|sin(θ)| (original)', linestyle='--')\nax1.plot(angles, max_sin, label='max(0,sin(θ)) (refined)', linestyle='-.')\nax1.axhline(y=0, color='k', linestyle='-', alpha=0.3)\nax1.axvline(x=0, color='k', linestyle='-', alpha=0.3)\nax1.axvline(x=180, color='k', linestyle='--', alpha=0.3)\nax1.axvline(x=360, color='k', linestyle='--', alpha=0.3)\n\nfor angle in [0, 90, 180, 270, 360]:\n    ax1.axvline(x=angle, color='gray', linestyle=':', alpha=0.5)\n\nax1.set_xlabel('Angle (degrees)')\nax1.set_ylabel('Value')\nax1.set_title('Original vs. Refined Approach for Eventfulness (Sine Component)')\nax1.grid(True, alpha=0.3)\nax1.legend()\n\n# Plot cosine functions\nax2.plot(angles, cos_values, label='cos(θ)', linestyle='-')\nax2.plot(angles, abs_cos, label='|cos(θ)| (original)', linestyle='--')\nax2.plot(angles, max_cos, label='max(0,cos(θ)) (refined)', linestyle='-.')\nax2.axhline(y=0, color='k', linestyle='-', alpha=0.3)\nax2.axvline(x=0, color='k', linestyle='-', alpha=0.3)\nax2.axvline(x=180, color='k', linestyle='--', alpha=0.3)\nax2.axvline(x=360, color='k', linestyle='--', alpha=0.3)\n\nfor angle in [0, 90, 180, 270, 360]:\n    ax2.axvline(x=angle, color='gray', linestyle=':', alpha=0.5)\n\nax2.set_xlabel('Angle (degrees)')\nax2.set_ylabel('Value')\nax2.set_title('Original vs. Refined Approach for Pleasantness (Cosine Component)')\nax2.grid(True, alpha=0.3)\nax2.legend()\n\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](post_files/figure-html/cell-6-output-1.png){width=1142 height=950}\n:::\n:::\n\n\nThis visualization clearly illustrates the key difference between the two approaches:\n\n-   For the eventfulness dimension (top graph), the original approach (dotted line) considers the absolute value of sine, treating positive and negative values equally. The refined approach (dash-dot line) only considers positive sine values (angles 0-180°) and zeros out the negative values.\n\n-   For the pleasantness dimension (bottom graph), a similar pattern applies to cosine values, with the refined approach only considering angles where cosine is positive (270-90° through 0°).\n\nThis selective consideration of positive contributions aligns with the theoretical understanding of the circumplex model, where attributes in specific quadrants contribute positively to a dimension.\n\n## Impact on Coordinate Calculations\n\nNow, let's examine how these different normalization approaches affect the actual coordinate calculations:\n\n::: {#af953f5c .cell execution_count=6}\n``` {.python .cell-code}\ndef calculate_iso_coordinates(angles, scores, method='original', rho=4, range=(1,5)):\n    \"\"\"\n    Calculate ISO Pleasant and ISO Eventful based on angles and scores\n    \n    Parameters:\n    angles (array): Array of angles in degrees for the 8 scales\n    scores (array): Array of scores for each scale (1-5)\n    method (str): 'original' or 'refined' to choose which lambda calculation to use\n    rho (float): Range of possible response values\n    \n    Returns:\n    tuple: (ISO Pleasant, ISO Eventful) coordinates\n    \"\"\"\n    angles_rad = np.radians(angles)\n\n    if method == 'centred':\n        return centered_iso_coord(angles, scores, range)\n    \n    # Numerators\n    numerator_pleasant = np.sum(np.cos(angles_rad) * scores)\n    numerator_eventful = np.sum(np.sin(angles_rad) * scores)\n    \n    # Denominators (lambda values)\n    if method == 'original':\n        denominator_pleasant = original_lambda_pl(angles, rho)\n        denominator_eventful = original_lambda_ev(angles, rho)\n    else:  # refined\n        denominator_pleasant = refined_lambda_pl(angles, rho)\n        denominator_eventful = refined_lambda_ev(angles, rho)\n    \n    return (numerator_pleasant / denominator_pleasant, \n            numerator_eventful / denominator_eventful)\n\ndef centered_iso_coord(angles, scores, range=(1, 5)):\n    angles_rad = np.radians(angles)\n\n    numerator_pleasant = np.sum(np.cos(angles_rad) * (scores - np.mean(range)))\n    numerator_eventful = np.sum(np.sin(angles_rad) * (scores - np.mean(range)))\n\n    denominator_pleasant = np.sum(np.abs(np.cos(angles_rad)))\n    denominator_eventful = np.sum(np.abs(np.sin(angles_rad)))\n\n    return (0.5 * numerator_pleasant / denominator_pleasant, 0.5 * numerator_eventful / denominator_eventful)\n\ndef custom_iso_coord(angles, scores, range=(1, 5)):\n    angles_rad = np.radians(angles)\n\n    #normalise values\n    norm_scores = (scores - np.mean(range)) / (np.max(range) - np.min(range))\n\n    return norm_scores\n                                \n\n# Define an example with non-equally spaced angles\nexample_angles = non_equal_angles\n# Example scores on 1-5 scale\nexample_scores = np.array([4, 3, 4, 2, 1, 2, 3, 3])  \n\n# Calculate ISO coordinates with both methods\niso_coords_original = calculate_iso_coordinates(example_angles, example_scores, 'original')\niso_coords_refined = calculate_iso_coordinates(example_angles, example_scores, 'refined')\niso_coords_centred = calculate_iso_coordinates(example_angles, example_scores, 'centred', range=(1, 5))\n\nprint(\"\\nExample ISO coordinate calculation (non-equally spaced angles):\")\nprint(f\"Using original lambda values: (P={iso_coords_original[0]:.4f}, E={iso_coords_original[1]:.4f})\")\nprint(f\"Using refined lambda values: (P={iso_coords_refined[0]:.4f}, E={iso_coords_refined[1]:.4f})\")\nprint(f\"Using centred ISO calculation: (P={iso_coords_centred[0]:.4f}, E={iso_coords_centred[1]:.4f})\")\nprint(f\"Percentage difference in P: {abs((iso_coords_refined[0] - iso_coords_original[0]) / iso_coords_original[0]) * 100:.2f}%\")\nprint(f\"Percentage difference in E: {abs((iso_coords_refined[1] - iso_coords_original[1]) / iso_coords_original[1]) * 100:.2f}%\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nExample ISO coordinate calculation (non-equally spaced angles):\nUsing original lambda values: (P=0.3767, E=0.2396)\nUsing refined lambda values: (P=0.3773, E=0.1981)\nUsing centred ISO calculation: (P=0.3794, E=-0.0747)\nPercentage difference in P: 0.18%\nPercentage difference in E: 17.32%\n```\n:::\n:::\n\n\n::: {#1502194c .cell execution_count=7}\n``` {.python .cell-code}\ndef custom_iso_coords(angles, scores, range=(0, 100)):\n    angles_rad = np.deg2rad(angles)\n\n    # normalise values\n    norm_scores = (scores - np.mean(range)) / ((np.max(range) - np.min(range)) / 2)\n\n    p_num = []\n    e_num = []\n    for score, angle in zip(norm_scores, angles_rad):\n        p_num.append(np.cos(angle) * score)\n        e_num.append(np.sin(angle) * score)\n\n    p_num = np.sum(p_num)\n    e_num = np.sum(e_num)\n\n    p_den = np.sum(np.abs(np.cos(angles_rad)))\n    e_den = np.sum(np.abs(np.sin(angles_rad)))\n  \n    return (p_num / p_den, e_num / e_den)\n\ndef max_pleasantness(angles, range=(0, 100)):\n    scores = []    \n    rad_angles = np.deg2rad(angles)    \n    for angle in rad_angles:\n        if np.cos(angle) >= 0:\n            scores.append(np.max(range))\n        if np.cos(angle) < 0:\n            scores.append(np.min(range))\n    return scores\n\ndef min_pleasantness(angles, range=(0, 100)):\n    scores = []    \n    rad_angles = np.deg2rad(angles)    \n    for angle in rad_angles:\n        if np.cos(angle) >= 0:\n            scores.append(np.min(range))\n        if np.cos(angle) < 0:\n            scores.append(np.max(range))\n    return scores\n\ndef max_eventfulness(angles, range=(0, 100)):\n    scores = []    \n    rad_angles = np.deg2rad(angles)    \n    for angle in rad_angles:\n        if np.sin(angle) >= 0:\n            scores.append(np.max(range))\n        if np.sin(angle) < 0:\n            scores.append(np.min(range))\n    return scores         \n    \ndef min_eventfulness(angles, range=(0, 100)):\n    scores = []    \n    rad_angles = np.deg2rad(angles)    \n    for angle in rad_angles:\n        if np.sin(angle) >= 0:\n            scores.append(np.min(range))\n        if np.sin(angle) < 0:\n            scores.append(np.max(range))\n    return scores    \n\nfor _ in range(10):\n    angles = np.random.uniform(0, 360, 8)\n    \n    max_p_scores = max_pleasantness(angles)\n    min_p_scores = min_pleasantness(angles)\n    max_e_scores = max_eventfulness(angles)\n    min_e_scores = min_eventfulness(angles)\n\n    print(f\"\\nAngles:   {angles}\")\n    print(f\"Max pleasant values: {max_p_scores}\")\n    print(f\"Max Pleasant: {custom_iso_coords(angles, max_p_scores)[0]:2f}\")\n    print(f\"Min Pleasant: {custom_iso_coords(angles, min_p_scores)[0]:2f}\")    \n    print(f\"Max Eventful values: {max_e_scores}\")\n    print(f\"Max Eventful: {custom_iso_coords(angles, max_e_scores)[1]:2f}\")\n    print(f\"Min Eventful: {custom_iso_coords(angles, min_e_scores)[1]:2f}\")   \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nAngles:   [233.4789924  321.59288645  72.05259817 203.36741547 327.72408106\n 201.68031867 252.12620299 349.26694289]\nMax pleasant values: [np.int64(0), np.int64(100), np.int64(100), np.int64(0), np.int64(100), np.int64(0), np.int64(0), np.int64(100)]\nMax Pleasant: 1.000000\nMin Pleasant: -1.000000\nMax Eventful values: [np.int64(0), np.int64(0), np.int64(100), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\nMax Eventful: 1.000000\nMin Eventful: -1.000000\n\nAngles:   [288.30494286  35.2193889  171.55766764 200.47489272 305.78061678\n   2.67525878 151.45971748  35.82800846]\nMax pleasant values: [np.int64(100), np.int64(100), np.int64(0), np.int64(0), np.int64(100), np.int64(100), np.int64(0), np.int64(100)]\nMax Pleasant: 1.000000\nMin Pleasant: -1.000000\nMax Eventful values: [np.int64(0), np.int64(100), np.int64(100), np.int64(0), np.int64(0), np.int64(100), np.int64(100), np.int64(100)]\nMax Eventful: 1.000000\nMin Eventful: -1.000000\n\nAngles:   [196.75760123 205.85066406 152.09218711  97.26266918 219.33417884\n 119.12657676  89.43362273 232.58991576]\nMax pleasant values: [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(100), np.int64(0)]\nMax Pleasant: 1.000000\nMin Pleasant: -1.000000\nMax Eventful values: [np.int64(0), np.int64(0), np.int64(100), np.int64(100), np.int64(0), np.int64(100), np.int64(100), np.int64(0)]\nMax Eventful: 1.000000\nMin Eventful: -1.000000\n\nAngles:   [311.86505154 192.81691651  84.63240219 102.84696563 201.07128329\n 319.43690971   1.16100899  53.83277455]\nMax pleasant values: [np.int64(100), np.int64(0), np.int64(100), np.int64(0), np.int64(0), np.int64(100), np.int64(100), np.int64(100)]\nMax Pleasant: 1.000000\nMin Pleasant: -1.000000\nMax Eventful values: [np.int64(0), np.int64(0), np.int64(100), np.int64(100), np.int64(0), np.int64(0), np.int64(100), np.int64(100)]\nMax Eventful: 1.000000\nMin Eventful: -1.000000\n\nAngles:   [278.42717887 267.8660137  143.50177845 299.77306464 104.46530284\n   6.14585184 260.95740714 154.90553926]\nMax pleasant values: [np.int64(100), np.int64(0), np.int64(0), np.int64(100), np.int64(0), np.int64(100), np.int64(0), np.int64(0)]\nMax Pleasant: 1.000000\nMin Pleasant: -1.000000\nMax Eventful values: [np.int64(0), np.int64(0), np.int64(100), np.int64(0), np.int64(100), np.int64(100), np.int64(0), np.int64(100)]\nMax Eventful: 1.000000\nMin Eventful: -1.000000\n\nAngles:   [ 48.02220859 138.4603252  357.56870009 311.61260425 327.05023287\n 206.69269682 350.10070556 100.50668584]\nMax pleasant values: [np.int64(100), np.int64(0), np.int64(100), np.int64(100), np.int64(100), np.int64(0), np.int64(100), np.int64(0)]\nMax Pleasant: 1.000000\nMin Pleasant: -1.000000\nMax Eventful values: [np.int64(100), np.int64(100), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(100)]\nMax Eventful: 1.000000\nMin Eventful: -1.000000\n\nAngles:   [187.05905857  66.74068475   4.15499947 162.34197745 139.54628455\n  74.16306098 127.95047485  97.14681319]\nMax pleasant values: [np.int64(0), np.int64(100), np.int64(100), np.int64(0), np.int64(0), np.int64(100), np.int64(0), np.int64(0)]\nMax Pleasant: 1.000000\nMin Pleasant: -1.000000\nMax Eventful values: [np.int64(0), np.int64(100), np.int64(100), np.int64(100), np.int64(100), np.int64(100), np.int64(100), np.int64(100)]\nMax Eventful: 1.000000\nMin Eventful: -1.000000\n\nAngles:   [294.88294493 140.96676223  91.02402165  88.39315062 332.17303461\n 189.82244471  35.95280663 247.03291457]\nMax pleasant values: [np.int64(100), np.int64(0), np.int64(0), np.int64(100), np.int64(100), np.int64(0), np.int64(100), np.int64(0)]\nMax Pleasant: 1.000000\nMin Pleasant: -1.000000\nMax Eventful values: [np.int64(0), np.int64(100), np.int64(100), np.int64(100), np.int64(0), np.int64(0), np.int64(100), np.int64(0)]\nMax Eventful: 1.000000\nMin Eventful: -1.000000\n\nAngles:   [207.52135632 227.70528816 199.12550047  83.2640418   51.80641948\n 199.60336612 156.32688846 351.90106492]\nMax pleasant values: [np.int64(0), np.int64(0), np.int64(0), np.int64(100), np.int64(100), np.int64(0), np.int64(0), np.int64(100)]\nMax Pleasant: 1.000000\nMin Pleasant: -1.000000\nMax Eventful values: [np.int64(0), np.int64(0), np.int64(0), np.int64(100), np.int64(100), np.int64(0), np.int64(100), np.int64(0)]\nMax Eventful: 1.000000\nMin Eventful: -1.000000\n\nAngles:   [ 78.59051833 339.6841554   37.49570886 149.34029386 211.47295665\n 274.79889075 241.81130927 255.53588092]\nMax pleasant values: [np.int64(100), np.int64(100), np.int64(100), np.int64(0), np.int64(0), np.int64(100), np.int64(0), np.int64(0)]\nMax Pleasant: 1.000000\nMin Pleasant: -1.000000\nMax Eventful values: [np.int64(100), np.int64(0), np.int64(100), np.int64(100), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\nMax Eventful: 1.000000\nMin Eventful: -1.000000\n```\n:::\n:::\n\n\nThis example demonstrates that the choice of normalization approach can significantly affect the coordinate calculations, potentially changing the interpretation of a soundscape's position within the circumplex model.\n\n## Ensuring Coordinate Range Validity: Monte Carlo Simulation\n\nTo verify that our refined approach consistently produces coordinates within the desired \\[-1, +1\\] range, we conducted a Monte Carlo simulation with random angles and scores:\n\n::: {#87e39c86 .cell execution_count=8}\n``` {.python .cell-code}\ndef run_monte_carlo_simulation(num_iterations=1000):\n    \"\"\"\n    Run a Monte Carlo simulation to verify that coordinates always fall within [-1, +1] range\n    \n    Parameters:\n    num_iterations (int): Number of simulation iterations\n    \n    Returns:\n    dict: Dictionary with simulation results\n    \"\"\"\n    # Storage for results\n    results = {\n        'original_pleasant': [],\n        'original_eventful': [],\n        'refined_pleasant': [],\n        'refined_eventful': [],\n        'centred_pleasant': [],\n        'centred_eventful': [],\n        'original_out_of_range': 0,\n        'refined_out_of_range': 0,\n        'centred_out_of_range': 0\n    }\n    \n    for _ in range(num_iterations):\n        # Generate random angles (8 angles between 0 and 360)\n        angles = np.random.uniform(0, 360, 8)\n        \n        # Generate random scores (8 scores between 1 and 5)\n        scores = np.random.uniform(1, 5, 8)\n        \n        # Calculate ISO coordinates with both methods\n        orig_coords = calculate_iso_coordinates(angles, scores, 'original')\n        refined_coords = calculate_iso_coordinates(angles, scores, 'refined')\n        centred_coords = calculate_iso_coordinates(angles, scores, 'centred')\n        \n        # Store results\n        results['original_pleasant'].append(orig_coords[0])\n        results['original_eventful'].append(orig_coords[1])\n        results['refined_pleasant'].append(refined_coords[0])\n        results['refined_eventful'].append(refined_coords[1])\n        results['centred_pleasant'].append(centred_coords[0])\n        results['centred_eventful'].append(centred_coords[1])\n        \n        # Check if any coordinates are out of range\n        if abs(orig_coords[0]) > 1 or abs(orig_coords[1]) > 1:\n            results['original_out_of_range'] += 1\n        \n        if abs(refined_coords[0]) > 1 or abs(refined_coords[1]) > 1:\n            results['refined_out_of_range'] += 1\n\n        if abs(centred_coords[0]) > 1 or abs(centred_coords[1]) > 1:\n            results['centred_out_of_range'] += 1\n    \n    return results\n\n# Run simulation\nnp.random.seed(42)  # For reproducibility\nsim_results = run_monte_carlo_simulation(5000)\n\n# Report results\nprint(\"\\nMonte Carlo Simulation Results (5000 iterations):\")\nprint(f\"Original approach out-of-range instances: {sim_results['original_out_of_range']} ({sim_results['original_out_of_range']/50:.2f}%)\")\nprint(f\"Refined approach out-of-range instances: {sim_results['refined_out_of_range']} ({sim_results['refined_out_of_range']/50:.2f}%)\")\nprint(f\"Centred approach out-of-range instances: {sim_results['centred_out_of_range']} ({sim_results['centred_out_of_range']/50:.2f}%)\")\n\n# Visualize the results\nplt.figure(figsize=(12, 10))\n\n# Set up the subplots\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 8))\n\n# Plot original formula results\nscatter1 = ax1.scatter(sim_results['original_pleasant'], sim_results['original_eventful'], \n                      alpha=0.3, s=5, c=np.abs(np.array(sim_results['original_pleasant'])) + np.abs(np.array(sim_results['original_eventful'])))\nax1.set_xlim(-1.5, 1.5)\nax1.set_ylim(-1.5, 1.5)\nax1.axhline(y=0, color='k', linestyle='-', alpha=0.2)\nax1.axvline(x=0, color='k', linestyle='-', alpha=0.2)\nax1.grid(alpha=0.2)\nax1.set_title('Original Approach: Coordinate Distribution')\nax1.set_xlabel('ISO Pleasant')\nax1.set_ylabel('ISO Eventful')\n\n# Draw circle boundary at radius 1\ncircle1 = plt.Circle((0, 0), 1, fill=False, linestyle='-', color='red', alpha=0.7)\nax1.add_patch(circle1)\n\n# Plot refined formula results\nscatter2 = ax2.scatter(sim_results['refined_pleasant'], sim_results['refined_eventful'], \n                      alpha=0.3, s=5, c=np.abs(np.array(sim_results['refined_pleasant'])) + np.abs(np.array(sim_results['refined_eventful'])))\nax2.set_xlim(-1.5, 1.5)\nax2.set_ylim(-1.5, 1.5)\nax2.axhline(y=0, color='k', linestyle='-', alpha=0.2)\nax2.axvline(x=0, color='k', linestyle='-', alpha=0.2)\nax2.grid(alpha=0.2)\nax2.set_title('Refined Approach: Coordinate Distribution')\nax2.set_xlabel('ISO Pleasant')\nax2.set_ylabel('ISO Eventful')\n\n# Draw circle boundary at radius 1\ncircle2 = plt.Circle((0, 0), 1, fill=False, linestyle='-', color='red', alpha=0.7)\nax2.add_patch(circle2)\n\n# Plot centred formula results\nscatter3 = ax3.scatter(sim_results['centred_pleasant'], sim_results['centred_eventful'], \n                      alpha=0.3, s=5, c=np.abs(np.array(sim_results['centred_pleasant'])) + np.abs(np.array(sim_results['centred_eventful'])))\nax3.set_xlim(-1.5, 1.5)\nax3.set_ylim(-1.5, 1.5)\nax3.axhline(y=0, color='k', linestyle='-', alpha=0.2)\nax3.axvline(x=0, color='k', linestyle='-', alpha=0.2)\nax3.grid(alpha=0.2)\nax3.set_title('Centred Approach: Coordinate Distribution')\nax3.set_xlabel('ISO Pleasant')\nax3.set_ylabel('ISO Eventful')\n\n# Draw circle boundary at radius 1\ncircle3 = plt.Circle((0, 0), 1, fill=False, linestyle='-', color='red', alpha=0.7)\nax3.add_patch(circle3)\n\nplt.colorbar(scatter1, ax=ax1, label='Distance from origin')\nplt.colorbar(scatter2, ax=ax2, label='Distance from origin')\nplt.colorbar(scatter3, ax=ax3, label='Distance from origin')\n\n\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMonte Carlo Simulation Results (5000 iterations):\nOriginal approach out-of-range instances: 1087 (21.74%)\nRefined approach out-of-range instances: 1509 (30.18%)\nCentred approach out-of-range instances: 0 (0.00%)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/6t/7h8wn9n92w5f24ml_bkwck9m0000gn/T/ipykernel_45688/209576974.py:32: RuntimeWarning: divide by zero encountered in scalar divide\n  numerator_eventful / denominator_eventful)\n/var/folders/6t/7h8wn9n92w5f24ml_bkwck9m0000gn/T/ipykernel_45688/209576974.py:31: RuntimeWarning: divide by zero encountered in scalar divide\n  return (numerator_pleasant / denominator_pleasant,\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```\n<Figure size 1152x960 with 0 Axes>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](post_files/figure-html/cell-9-output-4.png){width=2276 height=758}\n:::\n:::\n\n\nThe simulation results demonstrate that the refined approach provides more reliable normalization, ensuring that coordinates always fall within the desired \\[-1, +1\\] range. In contrast, the original approach can produce out-of-range coordinates when angles are not equally spaced around the circumplex.\n\n## Application to Cross-Cultural Soundscape Research\n\nThe implications of this methodological refinement are particularly relevant for cross-cultural soundscape research. In the Soundscape Attributes Translation Project (SATP), we worked with multiple language translations of the standard soundscape attributes, each with its own angle configuration based on linguistic and cultural factors.\n\nLet's examine how the normalization factors differ across these translations:\n\n::: {#bd014f6d .cell execution_count=9}\n``` {.python .cell-code}\n# Define language examples from cross-cultural research\nlanguages = {\n    \"English\": np.array([0, 46, 94, 138, 177, 231, 275, 340]),\n    \"Chinese\": np.array([0, 36, 45, 135, 167, 201, 242, 308]),\n    \"Indonesian\": np.array([0, 53, 104, 123, 139, 202, 284, 308]),\n    \"German\": np.array([0, 64, 97, 132, 182, 254, 282, 336]),\n    \"Italian\": np.array([0, 57, 104, 142, 170, 274, 285, 336])\n}\n\n# Calculate lambda values for each language\nev_results = {}\npl_results = {}\nfor lang, angles in languages.items():\n    # Eventfulness\n    ev_orig = original_lambda_ev(angles)\n    ev_refined = refined_lambda_ev(angles)\n    ev_diff_pct = (ev_refined - ev_orig) / ev_orig * 100\n    ev_results[lang] = {\"original\": ev_orig, \"refined\": ev_refined, \"diff_pct\": ev_diff_pct}\n    \n    # Pleasantness\n    pl_orig = original_lambda_pl(angles)\n    pl_refined = refined_lambda_pl(angles)\n    pl_diff_pct = (pl_refined - pl_orig) / pl_orig * 100\n    pl_results[lang] = {\"original\": pl_orig, \"refined\": pl_refined, \"diff_pct\": pl_diff_pct}\n    \n# Display eventfulness results\nprint(\"\\nEventfulness normalization factors across languages:\")\nprint(\"-\" * 70)\nprint(f\"{'Language':<12} {'Original λ':<12} {'Refined λ':<12} {'Difference %':<12}\")\nprint(\"-\" * 70)\nfor lang, values in ev_results.items():\n    print(f\"{lang:<12} {values['original']:<12.4f} {values['refined']:<12.4f} {values['diff_pct']:<12.2f}\")\n\n# Display pleasantness results\nprint(\"\\nPleasantness normalization factors across languages:\")\nprint(\"-\" * 70)\nprint(f\"{'Language':<12} {'Original λ':<12} {'Refined λ':<12} {'Difference %':<12}\")\nprint(\"-\" * 70)\nfor lang, values in pl_results.items():\n    print(f\"{lang:<12} {values['original']:<12.4f} {values['refined']:<12.4f} {values['diff_pct']:<12.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nEventfulness normalization factors across languages:\n----------------------------------------------------------------------\nLanguage     Original λ   Refined λ    Difference %\n----------------------------------------------------------------------\nEnglish      9.1075       9.7535       7.09        \nChinese      8.5126       8.9078       4.64        \nIndonesian   10.7931      13.0546      20.95       \nGerman       10.0311      10.5379      5.05        \nItalian      9.9370       10.3931      4.59        \n\nPleasantness normalization factors across languages:\n----------------------------------------------------------------------\nLanguage     Original λ   Refined λ    Difference %\n----------------------------------------------------------------------\nEnglish      10.3247      10.8860      5.44        \nChinese      12.4326      12.5271      0.76        \nIndonesian   9.8557       9.8376       -0.18       \nGerman       9.2517       10.2393      10.67       \nItalian      9.6030       11.1470      16.08       \n```\n:::\n:::\n\n\nThe results show that the difference between the original and refined normalization factors varies significantly across languages for both dimensions. This highlights the importance of our refinement when working with translated soundscape descriptors, as the angle distributions can differ substantially.\n\nTo better understand how these differences affect the positioning of soundscapes within the circumplex model, let's visualize how the same set of scores would be positioned using different language translations:\n\n::: {#036a51fc .cell execution_count=10}\n``` {.python .cell-code}\ndef plot_circumplex_comparison_multiple_languages(scores):\n    \"\"\"\n    Plot the circumplex comparison for multiple languages with the same scores\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(10, 10))\n    \n    # Draw circles and axes\n    circle = plt.Circle((0, 0), 1, fill=False, linestyle='-', color='black', alpha=0.3)\n    ax.add_patch(circle)\n    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n    ax.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n    \n    # Colors for different languages\n    colors = ['red', 'blue', 'green', 'purple', 'orange']\n    markers = ['o', 's', '^', 'D', 'v']\n    \n    # Plot points for each language\n    for i, (lang, angles) in enumerate(languages.items()):\n        # Calculate with original method\n        orig_coords = calculate_iso_coordinates(angles, scores, 'original')\n        # Calculate with refined method\n        refined_coords = calculate_iso_coordinates(angles, scores, 'refined')\n        \n        # Plot the points\n        ax.plot(orig_coords[0], orig_coords[1], marker=markers[i], color=colors[i], \n                linestyle='', markersize=10, alpha=0.5,\n                label=f\"{lang} (Original)\")\n        ax.plot(refined_coords[0], refined_coords[1], marker=markers[i], color=colors[i], \n                linestyle='', markersize=10, fillstyle='none',\n                label=f\"{lang} (Refined)\")\n        \n        # Draw line connecting the points\n        ax.plot([orig_coords[0], refined_coords[0]], [orig_coords[1], refined_coords[1]], \n                color=colors[i], linestyle='-', alpha=0.3)\n    \n    # Add labels and title\n    ax.set_xlabel('ISO Pleasant')\n    ax.set_ylabel('ISO Eventful')\n    ax.set_title('Impact of Normalization Refinement on Circumplex Coordinates\\nAcross Different Languages')\n    \n    # Set equal aspect and limits\n    ax.set_aspect('equal')\n    ax.set_xlim(-1.1, 1.1)\n    ax.set_ylim(-1.1, 1.1)\n    \n    # Add legend\n    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n    \n    # Label the four quadrants\n    ax.text(0.7, 0.7, 'Vibrant', ha='center', fontsize=10)\n    ax.text(-0.7, 0.7, 'Chaotic', ha='center', fontsize=10)\n    ax.text(-0.7, -0.7, 'Monotonous', ha='center', fontsize=10)\n    ax.text(0.7, -0.7, 'Calm', ha='center', fontsize=10)\n    \n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n\n# Example scores with a bias toward the eventful/vibrant quadrant\nexample_scores = np.array([4, 5, 4, 3, 2, 2, 2, 3])\n\n# Plot example\nplot_circumplex_comparison_multiple_languages(example_scores)\n```\n\n::: {.cell-output .cell-output-display}\n![](post_files/figure-html/cell-11-output-1.png){width=948 height=733}\n:::\n:::\n\n\nThis visualization demonstrates how our refined normalization approach affects the positioning of soundscapes within the circumplex model across different language translations. The corrections are most substantial for languages with the greatest imbalance in angle distribution.\n\n## Conclusion\n\nIn this blog post, we presented a refined approach to the normalization factors used in soundscape assessment. Starting with a first-principles analysis of the original direct-difference formula, we derived a theoretically sound generalization that only considers positive contributions to each dimension. This refinement addresses a limitation in the original approach when dealing with non-equally spaced angles—a common situation in cross-cultural contexts.\n\nThe key advantages of our refined approach are:\n\n1.  **Theoretical consistency**: It aligns with the directional nature of the pleasantness and eventfulness dimensions, where attributes in specific quadrants contribute positively, and those in opposing quadrants contribute negatively.\n\n2.  **Cross-cultural applicability**: It ensures accurate normalization across different language translations, where the angles of the attributes may not be equally spaced.\n\n3.  **Mathematical robustness**: Our Monte Carlo simulation confirms that it guarantees coordinates within the desired \\[-1, +1\\] range, regardless of angle distribution.\n\n4.  **Seamless integration**: For equally spaced angles, it produces identical results to the original approach, ensuring backward compatibility with existing data.\n\nThese refinements are particularly important for cross-cultural soundscape research, such as the Soundscape Attributes Translation Project (SATP), where accurate positioning of soundscapes within the circumplex model is essential for meaningful comparisons across different languages and cultural contexts.\n\nWe believe this methodological advancement contributes to the overall robustness of soundscape assessment and enhances its applicability in diverse cultural settings. By addressing the limitations of the original approach, we take a step toward a more inclusive and globally valid framework for soundscape assessment.\n\n",
    "supporting": [
      "post_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}