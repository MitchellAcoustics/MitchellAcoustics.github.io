{
  "hash": "8e07a1114a4bf1a2dda0dbd1c15e76da",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"A Robust Approach to Soundscape Circumplex Coordinate Projections\"\ndate: \"2025-04-03\"\nformat: \n    html:\n        embed-resources: true\n        code-fold: true\n    elsevier-pdf:\n        output-file: 'circumplex-formulae.pdf'\n        hyperrefoptions: \n          - \"citecolor=black\"\n        echo: false\n        journal:\n            name: Working paper\n            formatting: preprint\n            model: 1p\n            cite-style: authoryear\njupyter: python3\nbibliography: refs.bib\ncitation: true\n---\n\n::: {#c3d89b82 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n:::\n\n\n## Introduction\n\nThe ISO 12913 series established a framework for soundscape assessment using a circumplex model with perceptual attributes arranged in a circular pattern. When adapting these methods for cross-cultural applications, we encountered significant challenges with the normalization factors that ensure coordinates remain within the desired range. This paper presents a mathematically rigorous solution to these challenges, ensuring consistent normalization across different language adaptations of the ISO soundscape attributes.\n\n## Analysis of Existing Normalization Methods\n\n### Original ISO Direct Differences Method\n\nThe original method for calculating coordinates in the soundscape perceptual space was based on direct differences between opposing attributes:\n\n$$P = (p - a) + \\cos45° \\cdot (ca - ch) + \\cos45° \\cdot (v - m)$$\n$$E = (e - u) + \\cos45° \\cdot (ch - ca) + \\cos45° \\cdot (v - m)$$\n\nWhere:\n\n- p = pleasant, a = annoying\n- e = eventful, u = uneventful\n- ca = calm, ch = chaotic\n- v = vibrant, m = monotonous\n\nA scaling factor of $\\pm (4 + \\sqrt{32})$ was used to normalize the coordinates to the range [-1, +1]. This scaling factor represents the maximum possible contribution from all terms in the formula:\n\nFor a 5-point Likert scale (range 1-5), the maximum difference between opposing attributes is 4 (5-1). The direct opposition term contributes a maximum of 4 units, while each angled attribute pair contributes a maximum of 4 × cos45° ≈ 2.8284 units. The total maximum contribution is:\n\n4 + 2.8284 + 2.8284 = 9.6568 ≈ 4 + √32 ≈ 9.6569\n\nThis approach works effectively with equally spaced attributes at 45° intervals but cannot be directly applied when attributes are arranged at different angles in cross-cultural translations.\n\n### SATP Trigonometric Formulation\n\nThe Soundscape Attributes Translation Project (SATP) generalized the approach using a trigonometric formulation to accommodate varying angles and response ranges [@Aletta2024Soundscape]:\n\n$$P_{ISO} = \\frac{1}{\\lambda_{Pl}}\\sum_{i=1}^{8}\\cos(\\theta_i) \\times \\xi_i$$\n\n$$E_{ISO} = \\frac{1}{\\lambda_{Ev}}\\sum_{i=1}^{8}\\sin(\\theta_i) \\times \\xi_i$$\n\nWith scaling factors:\n\n$$\\lambda_{Pl} = \\frac{\\rho}{2}\\sum_{i=1}^{8}|\\cos(\\theta_i)|$$\n\n$$\\lambda_{Ev} = \\frac{\\rho}{2}\\sum_{i=1}^{8}|\\sin(\\theta_i)|$$\n\nWhere:\n\n- $\\theta_i$ is the angle for each circumplex scale\n- $\\xi_i$ is the score for each scale\n- $\\rho$ is the range of possible response values (e.g., $\\rho = 4$ for a 5-point Likert scale)\n\nThis generalization was a significant advancement, but our testing revealed limitations when dealing with uneven angle distributions.\n\n## Identification of Specific Limitations\n\n### Uneven Angle Distribution Problem\n\nIn cross-cultural adaptations, translated attributes may cluster in certain quadrants of the circumplex rather than being evenly distributed. For example, the Indonesian translation has the following angle distribution:\n\n::: {#6fa8d78b .cell execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=520 height=427}\n:::\n:::\n\n\nLet's implement the original SATP approach to demonstrate the issues:\n\n::: {#c1c409a1 .cell execution_count=3}\n``` {.python .cell-code}\ndef original_iso_coordinates(angles, scores, score_range=(1, 5)):\n    \"\"\"\n    Calculate ISO coordinates using the original SATP approach\n    \n    Parameters:\n    angles (array): Array of angles in degrees for the 8 scales\n    scores (array): Array of scores for each scale\n    score_range (tuple): Min and max of the score range (default: 1-5 Likert scale)\n    \n    Returns:\n    tuple: (ISO Pleasant, ISO Eventful) coordinates\n    \"\"\"\n    angles_rad = np.radians(angles)\n    rho = score_range[1] - score_range[0]\n    \n    # Numerators\n    numerator_pleasant = np.sum(np.cos(angles_rad) * scores)\n    numerator_eventful = np.sum(np.sin(angles_rad) * scores)\n    \n    # Denominators (lambda values)\n    denominator_pleasant = (rho / 2) * np.sum(np.abs(np.cos(angles_rad)))\n    denominator_eventful = (rho / 2) * np.sum(np.abs(np.sin(angles_rad)))\n    \n    # ISO coordinates\n    iso_pleasant = numerator_pleasant / denominator_pleasant\n    iso_eventful = numerator_eventful / denominator_eventful\n    \n    return iso_pleasant, iso_eventful\n```\n:::\n\n\n### Maximum Value Exceedance Problem\n\nWhen dealing with unevenly spaced attributes, the SATP method can produce coordinates outside the range of [-1, 1] with certain combinations of responses. To demonstrate this, we'll create functions that generate score sets designed to produce maximum/minimum pleasantness and eventfulness:\n\n::: {#801ae905 .cell execution_count=4}\n``` {.python .cell-code}\ndef max_pleasantness(angles, score_range=(1, 5)):\n    \"\"\"Generate scores that should produce maximum pleasantness\"\"\"\n    scores = []    \n    rad_angles = np.radians(angles)    \n    for angle in rad_angles:\n        if np.cos(angle) >= 0:\n            scores.append(score_range[1])  # Maximum score\n        else:\n            scores.append(score_range[0])  # Minimum score\n    return np.array(scores)\n\ndef min_pleasantness(angles, score_range=(1, 5)):\n    \"\"\"Generate scores that should produce minimum pleasantness\"\"\"\n    scores = []    \n    rad_angles = np.radians(angles)    \n    for angle in rad_angles:\n        if np.cos(angle) >= 0:\n            scores.append(score_range[0])  # Minimum score\n        else:\n            scores.append(score_range[1])  # Maximum score\n    return np.array(scores)\n\ndef max_eventfulness(angles, score_range=(1, 5)):\n    \"\"\"Generate scores that should produce maximum eventfulness\"\"\"\n    scores = []    \n    rad_angles = np.radians(angles)    \n    for angle in rad_angles:\n        if np.sin(angle) >= 0:\n            scores.append(score_range[1])  # Maximum score\n        else:\n            scores.append(score_range[0])  # Minimum score\n    return np.array(scores)        \n    \ndef min_eventfulness(angles, score_range=(1, 5)):\n    \"\"\"Generate scores that should produce minimum eventfulness\"\"\"\n    scores = []    \n    rad_angles = np.radians(angles)    \n    for angle in rad_angles:\n        if np.sin(angle) >= 0:\n            scores.append(score_range[0])  # Minimum score\n        else:\n            scores.append(score_range[1])  # Maximum score\n    return np.array(scores)\n```\n:::\n\n\nTesting with evenly and unevenly spaced angles:\n\n::: {#484f45b9 .cell execution_count=5}\n``` {.python .cell-code}\n# Standard equally spaced angles (45° increments)\nequal_angles = np.array([0, 45, 90, 135, 180, 225, 270, 315])\n\n# Example of uneven angles (Indonesian translation)\nuneven_angles = np.array([0, 53, 104, 123, 139, 202, 284, 308])\n\n# Test extreme cases\ntest_directions = [\"max_pleasant\", \"min_pleasant\", \"max_eventful\", \"min_eventful\"]\nresults = {}\n\nfor direction in test_directions:\n    if direction == \"max_pleasant\":\n        equal_scores = max_pleasantness(equal_angles)\n        uneven_scores = max_pleasantness(uneven_angles)\n    elif direction == \"min_pleasant\":\n        equal_scores = min_pleasantness(equal_angles)\n        uneven_scores = min_pleasantness(uneven_angles)\n    elif direction == \"max_eventful\":\n        equal_scores = max_eventfulness(equal_angles)\n        uneven_scores = max_eventfulness(uneven_angles)\n    elif direction == \"min_eventful\":\n        equal_scores = min_eventfulness(equal_angles)\n        uneven_scores = min_eventfulness(uneven_angles)\n        \n    equal_coords = original_iso_coordinates(equal_angles, equal_scores)\n    uneven_coords = original_iso_coordinates(uneven_angles, uneven_scores)\n    \n    results[f\"{direction}_equal\"] = equal_coords\n    results[f\"{direction}_uneven\"] = uneven_coords\n    \n    print(f\"With scores that should produce {direction}:\")\n    print(f\"  Equal angles: P={equal_coords[0]:.2f}, E={equal_coords[1]:.2f}\")\n    print(f\"  Uneven angles: P={uneven_coords[0]:.2f}, E={uneven_coords[1]:.2f}\")\n    print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWith scores that should produce max_pleasant:\n  Equal angles: P=1.00, E=0.41\n  Uneven angles: P=1.00, E=-0.25\n\nWith scores that should produce min_pleasant:\n  Equal angles: P=-1.00, E=-0.41\n  Uneven angles: P=-1.00, E=0.88\n\nWith scores that should produce max_eventful:\n  Equal angles: P=0.00, E=1.00\n  Uneven angles: P=0.02, E=1.31\n\nWith scores that should produce min_eventful:\n  Equal angles: P=-0.00, E=-1.00\n  Uneven angles: P=-0.03, E=-0.69\n\n```\n:::\n:::\n\n\nFor the Indonesian angles, the SATP formulation produces a maximum $E_{ISO}$ value of 1.31, exceeding the expected 1.00 bound. Similarly, the minimum $E_{ISO}$ value is only -0.69, not reaching the expected -1.00. This occurs because the angles are unevenly distributed across the positive and negative $E_{ISO}$ hemispheres, with more attributes contributing positively to $E_{ISO}$ than negatively.\n\n### Neutral Score Displacement Issue\n\nAnother critical issue is that neutral scores (all middle values) don't map to the origin (0,0) when angles are unevenly distributed:\n\n::: {#38206c3d .cell execution_count=6}\n``` {.python .cell-code}\n# Neutral scores (all 3's on a 1-5 scale)\nneutral_scores = np.ones(8) * 3\n\n# Calculate coordinates with equally spaced angles\nequal_coords = original_iso_coordinates(equal_angles, neutral_scores)\nprint(\"With equally spaced angles and neutral scores:\")\nprint(f\"Pleasantness: {equal_coords[0]:.4f}\")\nprint(f\"Eventfulness: {equal_coords[1]:.4f}\")\n\n# Calculate coordinates with uneven angles\nuneven_coords = original_iso_coordinates(uneven_angles, neutral_scores)\nprint(\"\\nWith unevenly spaced angles and neutral scores:\")\nprint(f\"Pleasantness: {uneven_coords[0]:.4f}\")\nprint(f\"Eventfulness: {uneven_coords[1]:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWith equally spaced angles and neutral scores:\nPleasantness: -0.0000\nEventfulness: 0.0000\n\nWith unevenly spaced angles and neutral scores:\nPleasantness: -0.0028\nEventfulness: 0.3143\n```\n:::\n:::\n\n\nWith evenly spaced angles, neutral scores correctly map to (0,0). However, with unevenly distributed angles, we get non-zero coordinates even with neutral scores, which is problematic for interpretation and cross-cultural comparability.\n\n## Development of Robust Normalization\n\n### Mathematical Derivation from First Principles\n\nTo address these limitations, we developed a new approach that guarantees coordinates within the [-1, +1] range regardless of angle distribution and ensures neutral scores always map to the origin. Our derivation follows a two-stage normalization process:\n\n#### Stage 1: Normalize Scores to [-1, +1]\n\nFor a scale with values in range [min, max], we first normalize all scores to the [-1, +1] range:\n\n1. Center around the midpoint: subtract (min + max)/2\n2. Scale by half the range: divide by (max - min)/2\n\nFor a standard 5-point Likert scale [1, 5], this gives:\n\n$$\\hat{\\xi}_i = \\frac{\\xi_i - 3}{2}$$\n\nThis ensures that neutral scores (e.g., all 3's on a 1-5 scale) are mapped to 0, which is essential for proper origin placement.\n\n#### Stage 2: Project and Scale by Maximum Possible Projection\n\nWe then project these normalized scores using trigonometric functions:\n\n$$P_{raw} = \\sum_{i=1}^{n} \\cos(\\theta_i) \\times \\hat{\\xi_i}$$\n$$E_{raw} = \\sum_{i=1}^{n} \\sin(\\theta_i) \\times \\hat{\\xi_i}$$\n\nThe maximum projection in any direction is determined by the sum of absolute trigonometric values:\n\n$$P_{max} = \\sum_{i=1}^{n} |\\cos(\\theta_i)|$$\n$$E_{max} = \\sum_{i=1}^{n} |\\sin(\\theta_i)|$$\n\nDividing by these values ensures coordinates stay within [-1, +1]:\n\n$$P_{ISO} = \\frac{P_{raw}}{P_{max}} = \\frac{\\sum_{i=1}^{n} \\cos(\\theta_i) \\times \\hat{\\xi}_i}{\\sum_{i=1}^{n} |\\cos(\\theta_i)|}$$\n\n### Final Formulation\n\nSubstituting our definition of $\\hat{\\xi}_i$ for a general scale with range [min, max]:\n\n$$P_{ISO} = \\frac{\\sum_{i=1}^{n} \\cos(\\theta_i) \\cdot (\\xi_i - \\mu)}{\\rho \\cdot \\sum_{i=1}^{n} |\\cos(\\theta_i)|}$$\n\n$$E_{ISO} = \\frac{\\sum_{i=1}^{n} \\sin(\\theta_i) \\cdot (\\xi_i - \\mu)}{\\rho \\cdot \\sum_{i=1}^{n} |\\sin(\\theta_i)|}$$\n\nWhere:\n\n- $\\mu = \\frac{\\min + \\max}{2}$ is the midpoint of the scale\n- $\\rho = \\frac{\\max - \\min}{2}$ is half the range of the scale\n\n## Implementation and Validation\n\n### Computational Implementation\n\n::: {#bee7fca7 .cell execution_count=7}\n``` {.python .cell-code code-fold=\"false\"}\ndef robust_iso_coordinates(angles, scores, score_range=(1, 5)):\n    \"\"\"\n    Calculate ISO coordinates using our robust normalization approach\n\n    Parameters:\n    angles (array): Array of angles in degrees for the 8 scales\n    scores (array): Array of scores for each scale\n    score_range (tuple): Min and max of the score range (default: 1-5 Likert scale)\n\n    Returns:\n    tuple: (ISO Pleasant, ISO Eventful) coordinates\n    \"\"\"\n    angles_rad = np.radians(angles)\n\n    # Calculate scale parameters\n    min_val, max_val = score_range\n    midpoint = (min_val + max_val) / 2\n    half_range = (max_val - min_val) / 2\n\n    # Stage 1: Normalize scores to [-1, 1]\n    norm_scores = (scores - midpoint) / half_range\n\n    # Stage 2: Project and scale by maximum possible projection\n    p_num = np.sum(np.cos(angles_rad) * norm_scores)\n    e_num = np.sum(np.sin(angles_rad) * norm_scores)\n\n    p_den = np.sum(np.abs(np.cos(angles_rad)))\n    e_den = np.sum(np.abs(np.sin(angles_rad)))\n\n    return (p_num / p_den, e_num / e_den)\n```\n:::\n\n\n### Neutral Score Response Testing\n\n::: {#c2f5966e .cell execution_count=8}\n``` {.python .cell-code}\n# Calculate coordinates with our robust formula\nrobust_equal_coords = robust_iso_coordinates(equal_angles, neutral_scores)\nrobust_uneven_coords = robust_iso_coordinates(uneven_angles, neutral_scores)\n\nprint(\"Neutral score handling comparison:\")\nprint(\"\\nWith equally spaced angles:\")\nprint(f\"Original approach: P={equal_coords[0]:.4f}, E={equal_coords[1]:.4f}\")\nprint(f\"Robust approach:   P={robust_equal_coords[0]:.4f}, E={robust_equal_coords[1]:.4f}\")\n\nprint(\"\\nWith unevenly spaced angles:\")\nprint(f\"Original approach: P={uneven_coords[0]:.4f}, E={uneven_coords[1]:.4f}\")\nprint(f\"Robust approach:   P={robust_uneven_coords[0]:.4f}, E={robust_uneven_coords[1]:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNeutral score handling comparison:\n\nWith equally spaced angles:\nOriginal approach: P=-0.0000, E=0.0000\nRobust approach:   P=0.0000, E=0.0000\n\nWith unevenly spaced angles:\nOriginal approach: P=-0.0028, E=0.3143\nRobust approach:   P=0.0000, E=0.0000\n```\n:::\n:::\n\n\nOur robust approach correctly maps neutral scores to (0,0) regardless of angle distribution, solving the neutral score displacement issue.\n\n### Boundary Condition Verification\n\n::: {#2d549b32 .cell execution_count=9}\n``` {.python .cell-code}\n# Test with equally spaced angles\nmax_p_scores = max_pleasantness(equal_angles)\nmin_p_scores = min_pleasantness(equal_angles)\nmax_e_scores = max_eventfulness(equal_angles)\nmin_e_scores = min_eventfulness(equal_angles)\n\nprint(\"Boundary condition tests with equally spaced angles:\")\nprint(f\"Max Pleasant: {robust_iso_coordinates(equal_angles, max_p_scores)[0]:.4f}\")\nprint(f\"Min Pleasant: {robust_iso_coordinates(equal_angles, min_p_scores)[0]:.4f}\")\nprint(f\"Max Eventful: {robust_iso_coordinates(equal_angles, max_e_scores)[1]:.4f}\")\nprint(f\"Min Eventful: {robust_iso_coordinates(equal_angles, min_e_scores)[1]:.4f}\")\n\n# Test with uneven angles\nmax_p_scores = max_pleasantness(uneven_angles)\nmin_p_scores = min_pleasantness(uneven_angles)\nmax_e_scores = max_eventfulness(uneven_angles)\nmin_e_scores = min_eventfulness(uneven_angles)\n\nprint(\"\\nBoundary condition tests with unevenly spaced angles:\")\nprint(f\"Max Pleasant: {robust_iso_coordinates(uneven_angles, max_p_scores)[0]:.4f}\")\nprint(f\"Min Pleasant: {robust_iso_coordinates(uneven_angles, min_p_scores)[0]:.4f}\")\nprint(f\"Max Eventful: {robust_iso_coordinates(uneven_angles, max_e_scores)[1]:.4f}\")\nprint(f\"Min Eventful: {robust_iso_coordinates(uneven_angles, min_e_scores)[1]:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBoundary condition tests with equally spaced angles:\nMax Pleasant: 1.0000\nMin Pleasant: -1.0000\nMax Eventful: 1.0000\nMin Eventful: -1.0000\n\nBoundary condition tests with unevenly spaced angles:\nMax Pleasant: 1.0000\nMin Pleasant: -1.0000\nMax Eventful: 1.0000\nMin Eventful: -1.0000\n```\n:::\n:::\n\n\nOur formula correctly maps extreme scores to exactly +1 or -1, regardless of angle distribution, solving the maximum value exceedance problem.\n\n### Compatibility with Original ISO Method\n\nTo verify backward compatibility, we'll compare our approach with the original ISO direct differences method when using evenly spaced angles:\n\n::: {#870a6b50 .cell execution_count=10}\n``` {.python .cell-code}\ndef iso_direct_differences(scores):\n    \"\"\"\n    Calculate ISO coordinates using the original direct differences method\n    \n    Parameters:\n    scores (array): Array of 8 scores in order [pleasant, vibrant, eventful, chaotic,\n                    annoying, monotonous, uneventful, calm]\n    \n    Returns:\n    tuple: (ISO Pleasant, ISO Eventful) coordinates\n    \"\"\"\n    # Extract scores for specific attributes\n    p = scores[0]  # pleasant (0°)\n    v = scores[1]  # vibrant (45°)\n    e = scores[2]  # eventful (90°)\n    ch = scores[3]  # chaotic (135°)\n    a = scores[4]  # annoying (180°)\n    m = scores[5]  # monotonous (225°)\n    u = scores[6]  # uneventful (270°)\n    ca = scores[7]  # calm (315°)\n\n    # Calculate using direct differences formula\n    cos45 = np.cos(np.radians(45))\n    pleasant = (p - a) + cos45 * (ca - ch) + cos45 * (v - m)\n    eventful = (e - u) + cos45 * (ch - ca) + cos45 * (v - m)\n\n    # Normalize to [-1, +1] range\n    scaling_factor = 4 + np.sqrt(32)\n    pleasant = pleasant / scaling_factor\n    eventful = eventful / scaling_factor\n\n    return (pleasant, eventful)\n\ndef run_compatibility_simulation(num_iterations=5000):\n    \"\"\"\n    Run a Monte Carlo simulation to verify compatibility between original ISO direct differences\n    and our robust approach when using evenly spaced angles\n    \n    Parameters:\n    num_iterations (int): Number of simulation iterations\n    \n    Returns:\n    dict: Dictionary with simulation results\n    \"\"\"\n    # Evenly spaced angles (45° increments)\n    equal_angles = np.array([0, 45, 90, 135, 180, 225, 270, 315])\n    \n    # Storage for results\n    results = {\n        'direct_pleasant': [],\n        'direct_eventful': [],\n        'robust_pleasant': [],\n        'robust_eventful': []\n    }\n    \n    for _ in range(num_iterations):\n        # Generate random scores (8 scores between 1 and 5)\n        scores = np.random.uniform(1, 5, 8)\n        \n        # Calculate coordinates with both methods\n        direct_coords = iso_direct_differences(scores)\n        robust_coords = robust_iso_coordinates(equal_angles, scores)\n        \n        # Store results\n        results['direct_pleasant'].append(direct_coords[0])\n        results['direct_eventful'].append(direct_coords[1])\n        results['robust_pleasant'].append(robust_coords[0])\n        results['robust_eventful'].append(robust_coords[1])\n    \n    return results\n\n# Run compatibility simulation\nnp.random.seed(42)  # For reproducibility\ncompat_results = run_compatibility_simulation(5000)\n\n# Calculate statistics\ndirect_p_mean = np.mean(compat_results['direct_pleasant'])\ndirect_p_std = np.std(compat_results['direct_pleasant'])\nrobust_p_mean = np.mean(compat_results['robust_pleasant'])\nrobust_p_std = np.std(compat_results['robust_pleasant'])\n\ndirect_e_mean = np.mean(compat_results['direct_eventful'])\ndirect_e_std = np.std(compat_results['direct_eventful'])\nrobust_e_mean = np.mean(compat_results['robust_eventful'])\nrobust_e_std = np.std(compat_results['robust_eventful'])\n\nprint(\"Compatibility Statistics (with evenly spaced angles):\")\nprint(\"\\nPleasantness:\")\nprint(f\"Direct differences method: mean={direct_p_mean:.4f}, std={direct_p_std:.4f}\")\nprint(f\"Robust approach:           mean={robust_p_mean:.4f}, std={robust_p_std:.4f}\")\nprint(f\"Difference in means:       {abs(direct_p_mean - robust_p_mean):.4f}\")\nprint(f\"Ratio of standard deviations: {direct_p_std/robust_p_std:.4f}\")\n\nprint(\"\\nEventfulness:\")\nprint(f\"Direct differences method: mean={direct_e_mean:.4f}, std={direct_e_std:.4f}\")\nprint(f\"Robust approach:           mean={robust_e_mean:.4f}, std={robust_e_std:.4f}\")\nprint(f\"Difference in means:       {abs(direct_e_mean - robust_e_mean):.4f}\")\nprint(f\"Ratio of standard deviations: {direct_e_std/robust_e_std:.4f}\")\n\n# Visualize the compatibility\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Scatter plot\naxes[0].scatter(compat_results['direct_pleasant'], compat_results['direct_eventful'], \n               alpha=0.3, s=3, c='blue', label='Direct Differences')\naxes[0].scatter(compat_results['robust_pleasant'], compat_results['robust_eventful'], \n               alpha=0.3, s=3, c='red', label='Robust Method')\naxes[0].set_xlim(-1.1, 1.1)\naxes[0].set_ylim(-1.1, 1.1)\naxes[0].axhline(y=0, color='k', linestyle='-', alpha=0.2)\naxes[0].axvline(x=0, color='k', linestyle='-', alpha=0.2)\naxes[0].grid(alpha=0.2)\naxes[0].set_title('Comparison with Evenly Spaced Angles')\naxes[0].set_xlabel('ISO Pleasant')\naxes[0].set_ylabel('ISO Eventful')\naxes[0].legend()\n\n# Draw circle boundary at radius 1\ncircle = plt.Circle((0, 0), 1, fill=False, linestyle='-', color='black', alpha=0.7)\naxes[0].add_patch(circle)\n\n# Distribution comparison\npleasant_bins = np.linspace(-1, 1, 50)\neventful_bins = np.linspace(-1, 1, 50)\n\naxes[1].hist(compat_results['direct_pleasant'], bins=pleasant_bins, alpha=0.5, color='blue', label='Direct (P)')\naxes[1].hist(compat_results['robust_pleasant'], bins=pleasant_bins, alpha=0.5, color='red', label='Robust (P)')\naxes[1].hist(compat_results['direct_eventful'], bins=eventful_bins, alpha=0.5, color='green', label='Direct (E)')\naxes[1].hist(compat_results['robust_eventful'], bins=eventful_bins, alpha=0.5, color='orange', label='Robust (E)')\naxes[1].set_title('Distribution of Coordinates')\naxes[1].set_xlabel('Coordinate Value')\naxes[1].set_ylabel('Frequency')\naxes[1].legend()\n\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompatibility Statistics (with evenly spaced angles):\n\nPleasantness:\nDirect differences method: mean=-0.0015, std=0.2424\nRobust approach:           mean=-0.0015, std=0.2424\nDifference in means:       0.0000\nRatio of standard deviations: 1.0000\n\nEventfulness:\nDirect differences method: mean=-0.0035, std=0.2385\nRobust approach:           mean=-0.0035, std=0.2385\nDifference in means:       0.0000\nRatio of standard deviations: 1.0000\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-11-output-2.png){width=1334 height=566}\n:::\n:::\n\n\nThe statistics and visualizations demonstrate that our robust approach produces results that are statistically equivalent to the original ISO direct differences method when using evenly spaced angles, confirming backward compatibility.\n\n### Monte Carlo Simulation\n\nTo thoroughly test our approach against the original SATP method, we'll run a Monte Carlo simulation with thousands of random angle configurations and score combinations:\n\n::: {#0c13bff5 .cell execution_count=11}\n``` {.python .cell-code}\ndef run_monte_carlo_simulation(num_iterations=5000):\n    \"\"\"\n    Run a Monte Carlo simulation to verify that coordinates always fall within [-1, +1] range\n    \n    Parameters:\n    num_iterations (int): Number of simulation iterations\n    \n    Returns:\n    dict: Dictionary with simulation results\n    \"\"\"\n    # Storage for results\n    results = {\n        'original_pleasant': [],\n        'original_eventful': [],\n        'robust_pleasant': [],\n        'robust_eventful': [],\n        'original_out_of_range': 0,\n        'robust_out_of_range': 0\n    }\n    \n    for _ in range(num_iterations):\n        # Generate random angles (8 angles between 0 and 360)\n        angles = np.random.uniform(0, 360, 8)\n        \n        # Generate random scores (8 scores between 1 and 5)\n        scores = np.random.uniform(1, 5, 8)\n        \n        # Calculate ISO coordinates with both methods\n        orig_coords = original_iso_coordinates(angles, scores)\n        robust_coords = robust_iso_coordinates(angles, scores)\n        \n        # Store results\n        results['original_pleasant'].append(orig_coords[0])\n        results['original_eventful'].append(orig_coords[1])\n        results['robust_pleasant'].append(robust_coords[0])\n        results['robust_eventful'].append(robust_coords[1])\n        \n        # Check if any coordinates are out of range\n        if abs(orig_coords[0]) > 1 or abs(orig_coords[1]) > 1:\n            results['original_out_of_range'] += 1\n        \n        if abs(robust_coords[0]) > 1 or abs(robust_coords[1]) > 1:\n            results['robust_out_of_range'] += 1\n    \n    return results\n\n# Run simulation\nnp.random.seed(42)  # For reproducibility\nsim_results = run_monte_carlo_simulation(5000)\n\n# Report results\nprint(\"\\nMonte Carlo Simulation Results (5000 iterations):\")\nprint(f\"Original SATP approach out-of-range instances: {sim_results['original_out_of_range']} ({sim_results['original_out_of_range']/50:.2f}%)\")\nprint(f\"Robust approach out-of-range instances: {sim_results['robust_out_of_range']} ({sim_results['robust_out_of_range']/50:.2f}%)\")\n\n# Visualize the simulation results\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Plot original SATP approach results\nscatter1 = axes[0].scatter(sim_results['original_pleasant'], sim_results['original_eventful'], \n                          alpha=0.3, s=5, c=np.abs(np.array(sim_results['original_pleasant'])) + np.abs(np.array(sim_results['original_eventful'])))\naxes[0].set_xlim(-1.5, 1.5)\naxes[0].set_ylim(-1.5, 1.5)\naxes[0].axhline(y=0, color='k', linestyle='-', alpha=0.2)\naxes[0].axvline(x=0, color='k', linestyle='-', alpha=0.2)\naxes[0].grid(alpha=0.2)\naxes[0].set_title('Original SATP Approach')\naxes[0].set_xlabel('ISO Pleasant')\naxes[0].set_ylabel('ISO Eventful')\n\n# Draw circle boundary at radius 1\ncircle1 = plt.Circle((0, 0), 1, fill=False, linestyle='-', color='red', alpha=0.7)\naxes[0].add_patch(circle1)\n\n# Plot robust approach results\nscatter2 = axes[1].scatter(sim_results['robust_pleasant'], sim_results['robust_eventful'], \n                          alpha=0.3, s=5, c=np.abs(np.array(sim_results['robust_pleasant'])) + np.abs(np.array(sim_results['robust_eventful'])))\naxes[1].set_xlim(-1.5, 1.5)\naxes[1].set_ylim(-1.5, 1.5)\naxes[1].axhline(y=0, color='k', linestyle='-', alpha=0.2)\naxes[1].axvline(x=0, color='k', linestyle='-', alpha=0.2)\naxes[1].grid(alpha=0.2)\naxes[1].set_title('New Robust Approach')\naxes[1].set_xlabel('ISO Pleasant')\naxes[1].set_ylabel('ISO Eventful')\n\n# Draw circle boundary at radius 1\ncircle2 = plt.Circle((0, 0), 1, fill=False, linestyle='-', color='red', alpha=0.7)\naxes[1].add_patch(circle2)\n\n# Add colorbars\nplt.colorbar(scatter1, ax=axes[0], label='Distance from origin')\nplt.colorbar(scatter2, ax=axes[1], label='Distance from origin')\n\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMonte Carlo Simulation Results (5000 iterations):\nOriginal SATP approach out-of-range instances: 1087 (21.74%)\nRobust approach out-of-range instances: 0 (0.00%)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-12-output-2.png){width=1319 height=566}\n:::\n:::\n\n\nThe simulation results clearly demonstrate that our robust approach guarantees coordinates within the unit circle, while the original SATP approach can produce out-of-range values with certain angle configurations.\n\n## Cross-Cultural Application Analysis\n\nTo evaluate the practical impact of our normalization approach, we'll examine how the two methods affect the positioning of soundscapes using angle configurations from different language translations:\n\n::: {#5225d8de .cell execution_count=12}\n``` {.python .cell-code}\n# Define language examples from cross-cultural research\nlanguages = {\n    \"English\": np.array([0, 46, 94, 138, 177, 231, 275, 340]),\n    \"Chinese\": np.array([0, 18, 38, 154, 167, 201, 242, 308]),\n    \"Indonesian\": np.array([0, 53, 104, 123, 139, 202, 284, 308]),\n    \"German\": np.array([0, 64, 97, 132, 182, 254, 282, 336]),\n    \"Italian\": np.array([0, 57, 104, 142, 170, 274, 285, 336]),\n}\n\n# Balanced scores that should give a moderate vibrant result\nbalanced_scores = np.array([4, 4, 4, 3, 2, 2, 2, 3])\n\n# Visualize the impact across languages\nfig, ax = plt.subplots(figsize=(10, 10))\n\n# Draw circles and axes\ncircle = plt.Circle((0, 0), 1, fill=False, linestyle=\"-\", color=\"black\", alpha=0.3)\nax.add_patch(circle)\nax.axhline(y=0, color=\"gray\", linestyle=\"--\", alpha=0.5)\nax.axvline(x=0, color=\"gray\", linestyle=\"--\", alpha=0.5)\n\n# Colors for different languages\ncolors = [\"red\", \"blue\", \"green\", \"purple\", \"orange\"]\nmarkers = [\"o\", \"s\", \"^\", \"D\", \"v\"]\n\niso_direct_coords = iso_direct_differences(balanced_scores)\nax.plot(\n    iso_direct_coords[0],\n    iso_direct_coords[1],\n    marker=\"o\",\n    color=\"black\",\n    linestyle=\"\",\n    markersize=10,\n    alpha=0.5,\n    label=\"ISO 2018 Direct Differences\",\n)\n\n# Add legend for the direct differences\nax.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n\n# Plot points for each language\nfor i, (lang, angles) in enumerate(languages.items()):\n    # Calculate with different methods\n    orig_coords = original_iso_coordinates(angles, balanced_scores)\n    robust_coords = robust_iso_coordinates(angles, balanced_scores)\n\n    # Plot the points\n    ax.plot(\n        orig_coords[0],\n        orig_coords[1],\n        marker=markers[i],\n        color=colors[i],\n        linestyle=\"\",\n        markersize=10,\n        alpha=0.5,\n        label=f\"{lang} (Original)\",\n    )\n    ax.plot(\n        robust_coords[0],\n        robust_coords[1],\n        marker=\"*\",\n        color=colors[i],\n        linestyle=\"\",\n        markersize=15,\n        label=f\"{lang} (Robust)\",\n    )\n\n    # Connect the points\n    ax.plot(\n        [orig_coords[0], robust_coords[0]],\n        [orig_coords[1], robust_coords[1]],\n        color=colors[i],\n        linestyle=\"-\",\n        alpha=0.3,\n    )\n\n# Add labels and title\nax.set_xlabel(\"ISO Pleasant\")\nax.set_ylabel(\"ISO Eventful\")\nax.set_title(\n    \"Impact of Normalization Approaches on Soundscape Coordinates\\nAcross Different Languages\"\n)\n\n# Set equal aspect and limits\nax.set_aspect(\"equal\")\nax.set_xlim(-1.1, 1.1)\nax.set_ylim(-1.1, 1.1)\n\n# Add legend\nax.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n\n# Label the four quadrants\nax.text(0.7, 0.7, \"Vibrant\", ha=\"center\", fontsize=10)\nax.text(-0.7, 0.7, \"Chaotic\", ha=\"center\", fontsize=10)\nax.text(-0.7, -0.7, \"Monotonous\", ha=\"center\", fontsize=10)\nax.text(0.7, -0.7, \"Calm\", ha=\"center\", fontsize=10)\n\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-1.png){width=946 height=687}\n:::\n:::\n\n\nThis visualization reveals that the choice of normalization approach can significantly affect the relative positioning of soundscapes on the circumplex model across different languages. The robust approach ensures consistent normalization regardless of the angle distribution, which is essential for valid cross-cultural comparisons.\n\n## Technical Discussion and Recommendations\n\n### Mathematical Analysis\n\nOur formula succeeds where the original SATP approach fell short for two key reasons:\n\n1. **Proper Handling of Neutral Scores**: By explicitly subtracting the midpoint of the scale before projection, we ensure that neutral scores always map to the origin (0,0) regardless of angle distribution. With the original approach, neutral scores can produce non-zero coordinates when angles are unevenly distributed.\n\n2. **Correct Scaling for Maximum Projection**: By first normalizing scores to the [-1, +1] range and then dividing by the sum of absolute trigonometric values, we account for the maximum possible projection in both positive and negative directions. This two-stage approach handles uneven angle distributions appropriately.\n\nThe essential mathematical insight is separating the score normalization from the projection normalization. This approach recognizes that the maximum possible projection depends on the absolute sum of trigonometric values, which properly accounts for attributes that might be clustered predominantly in one part of the circumplex.\n\n### Standardization Recommendations\n\nThrough rigorous mathematical derivation and extensive testing, we have developed a robust approach to soundscape normalization that:\n\n1. Guarantees coordinates within the [-1, +1] range for any angle configuration\n2. Correctly maps neutral scores to the origin\n3. Properly handles cross-cultural adaptations with uneven angle distributions\n4. Works for any input scale range\n5. Maintains backward compatibility with the original ISO method\n\nWe recommend adopting this formulation in the revised ISO 12913-3 standard to ensure accurate and comparable soundscape assessment across different languages and cultural contexts. The final formulas:\n\n$$P_{ISO} = \\frac{\\sum_{i=1}^{n} \\cos(\\theta_i) \\cdot (\\xi_i - \\mu)}{\\rho \\cdot \\sum_{i=1}^{n} |\\cos(\\theta_i)|}$$\n\n$$E_{ISO} = \\frac{\\sum_{i=1}^{n} \\sin(\\theta_i) \\cdot (\\xi_i - \\mu)}{\\rho \\cdot \\sum_{i=1}^{n} |\\sin(\\theta_i)|}$$\n\nWhere:\n\n- $\\mu = \\frac{\\min + \\max}{2}$ is the midpoint of the scale\n- $\\rho = \\frac{\\max - \\min}{2}$ is half the range of the scale\n\nThis approach provides a solid mathematical foundation for cross-cultural soundscape research and ensures the validity of the circumplex model in diverse applications.\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}