@article{Aletta2019Associations,
  title = {Associations between Soundscape Experience and Self-Reported Wellbeing in Open Public Urban Spaces: {{A}} Field Study},
  author = {Aletta, Francesco and Oberman, Tin and Mitchell, Andrew and Erfanian, Mercede and Lionello, Matteo and Kachlicka, Magdalena and Kang, Jian},
  date = {2019-11},
  journaltitle = {The Lancet},
  volume = {394},
  pages = {S17},
  publisher = {Elsevier BV},
  issn = {0140-6736},
  doi = {10.1016/s0140-6736(19)32814-4},
  abstract = {Background Previous studies, mainly conducted in laboratory experiments, showed there are associations between the perception of acoustic environments (ie, soundscapes, as per the International Organization for Standardization [ISO] 12913-1:2014 definition) and measures of individual health and wellbeing. The aim of this study was to confirm these findings in more ecologically realistic settings, by exploring associations between soundscapes and wellbeing via a questionnaire campaign.},
  keywords = {SSID},
  annotation = {15 citations (Crossref/DOI) [2024-12-14]\\
15 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:19:13Z},
  file = {Aletta2019Associations - Associations between soundscape experience and self-reported wellbeing in open public urban spaces.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Aletta2019Associations - Associations between soundscape experience and self-reported wellbeing in open public urban spaces.pdf:application/pdf}
}

@article{Aletta2020Assessing,
  title = {Assessing the Changing Urban Sound Environment during the {{COVID-19}} Lockdown Period Using Short-Term Acoustic Measurements},
  author = {Aletta, Francesco and Oberman, Tin and Mitchell, Andrew and Tong, Huan and Kang, Jian},
  date = {2020-01},
  journaltitle = {Noise Mapping},
  shortjournal = {Noise Mapp.},
  volume = {7},
  number = {1},
  pages = {123--134},
  publisher = {Walter de Gruyter GmbH},
  issn = {2084-879X},
  doi = {10.1515/noise-2020-0011},
  url = {https://www.degruyter.com/view/journals/noise/7/1/article-p123.xml},
  abstract = {The implementation of lockdown measures due to the COVID-19 outbreak has resulted in wide-ranging social and environmental implications. Among the environmental impacts is a decrease in urban noise levels which has so far been observed at the city scale via noise mapping efforts conducted through the framework of the Environmental Noise Directive. This study aims to understand how lockdown measures have manifested at a local level to better determine how the person-level experience of the urban soundscape has been affected and how these affects differ across urban space typologies. Taking London as a case study, a series of 30-second binaural recordings were taken at 11 locations representing a cross-section of urban public spaces with varying compositions of sound sources during Spring 2019 (pre-lockdown, N = 620) and Spring 2020 (during-lockdown, N = 481). Five acoustic and psychoacoustic metrics (LAeq, LA10, LA90, Loudness, Sharpness) were calculated for each recording and their changes from the pre-lockdown scenario to the lockdown scenario are investigated. Clustering analysis was performed which grouped the locations into 3 types of urban settings based on their acoustic characteristics. An average reduction of 5.4 dB (LAeq) was observed, however significant differences in the degree of reduction were found across the locations, ranging from a 10.7 dB to a 1.2 dB reduction. This study confirms the general reduction in noise levels due to the nationally imposed lockdown measures, identifies trends which vary depending on the urban context and discusses the implications for the limits of urban noise reduction.},
  qualityassured = {qualityAssured},
  keywords = {COVID-19,lockdown,nonfile,Psychoacoustics,Quiet areas,Soundscape,Urban noise levels},
  annotation = {115 citations (Crossref/DOI) [2024-12-14]\\
115 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:19:10Z},
  file = {Aletta2020Assessing - Assessing the changing urban sound environment during the COVID-19 lockdown period using short-term.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Aletta2020Assessing - Assessing the changing urban sound environment during the COVID-19 lockdown period using short-term.pdf:application/pdf}
}

@article{Aletta2023Soundscape,
  title = {Soundscape Experience of Public Spaces in Different World Regions: A Comparison between the European and Chinese Contexts via a Large-Scale on-Site Surveya)},
  shorttitle = {Soundscape Experience of Public Spaces in Different World Regions},
  author = {Aletta, Francesco and Oberman, Tin and Mitchell, Andrew and Erfanian, Mercede and Kang, Jian},
  date = {2023-09-15},
  journaltitle = {Journal of the Acoustical Society of America},
  shortjournal = {J. Acoust. Soc. Am.},
  volume = {154},
  number = {3},
  pages = {1710--1734},
  issn = {0001-4966},
  doi = {10.1121/10.0020842},
  url = {https://doi.org/10.1121/10.0020842},
  urldate = {2024-12-12},
  abstract = {The influence of cultural background on the soundscape experience in public spaces has been widely acknowledged. However, most studies have not used standardized protocols for soundscape perception data collection, nor have they gathered large datasets across different regions of the world to investigate possible cultural differences. This study explored the relationships between soundscape descriptors, perceived dominance of sound sources, and overall soundscape qualities and whether these relationships differ across world regions. A database of over 2000 soundscape surveys was collected in situ in outdoor public spaces in Europe and China. Results highlighted differences in how European and Chinese participants perceived the pleasantness and dominance of different sound sources. Specifically, the positive correlation between perceived pleasantness and natural sounds was stronger for European participants. For Chinese participants, vibrant soundscapes were positively correlated with perceived dominance of natural sounds, whereas in Europe, they were associated more with human-generated sounds. Perceived loudness had a greater effect on the appropriateness dimension for the Chinese sample than that for the European sample. This study provides a deeper understanding of how the geographical/cultural context can influence soundscape perception in public spaces and suggests that such country-specific factors should be considered when designing urban soundscapes.},
  langid = {english},
  keywords = {/unread},
  annotation = {9 citations (Crossref/DOI) [2024-12-14]\\
9 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:21:47Z},
  file = {Aletta2023Soundscape - Soundscape experience of public spaces in different world regions a comparison between the european.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Aletta2023Soundscape - Soundscape experience of public spaces in different world regions a comparison between the european.pdf:application/pdf;2911545.html:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/2911545.html:text/html}
}

@article{Aletta2024Soundscape,
  title = {Soundscape Descriptors in Eighteen Languages: Translation and Validation through Listening Experiments},
  shorttitle = {Soundscape Descriptors in Eighteen Languages},
  author = {Aletta, Francesco and Mitchell, Andrew and Oberman, Tin and Kang, Jian and Khelil, Sara and Bouzir, Tallal Abdel Karim and Berkouk, Djihed and Xie, Hui and Zhang, Yuan and Zhang, Ruining and Yang, Xinhao and Li, Min and Jambro\v si\'c, Kristian and Zaninovi\'c, Tamara and family=Bosch, given=Kirsten, prefix=van den, useprefix=true and L\"uhr, Tamara and Orlik, Nicolas and Fitzpatrick, Darragh and Sarampalis, Anastasios and Aumond, Pierre and Lavandier, Catherine and Moshona, Cleopatra Christina and Lepa, Steffen and Fiebig, Andr\'e and Papadakis, Nikolaos M. and Stavroulakis, Georgios E. and Sudarsono, Anugrah Sabdono and Sarwono, Sugeng Joko and Puglisi, Giuseppina Emma and Jafari, Farid and Astolfi, Arianna and Shtrepi, Louena and Nagahata, Koji and Jo, Hyun In and Jeon, Jin Yong and Lam, Bhan and Chieng, Julia and Ooi, Kenneth and Hong, Joo Young and Monteiro Antunes, S\'onia and Alves, Sonia and family=Ulhoa Carvalho, given=Maria Luiza, prefix=de, useprefix=true and Michalski, Ranny Loureiro Xavier Nascimento and Kogan, Pablo and Vida Manzano, Jer\'onimo and Garc\'ia Quesada, Rafael and Su\'arez Silva, Enrique and Almagro Pastor, Jos\'e Antonio and Nilsson, Mats E. and Axelsson, \"Osten and Gan, Woon-Seng and Watcharasupat, Karn N. and Jaratjarungkiat, Sureenate and Ong, Zhen-Ting and D\"okmeci Y\"or\"uko\u glu, Papatya Nur and Er\c cakmak Osma, U\u gur Beyza and Nguyen, Thu Lan},
  date = {2024-09-05},
  journaltitle = {Applied Acoustics},
  shortjournal = {Appl. Acoust.},
  volume = {224},
  pages = {110109},
  issn = {0003-682X},
  doi = {10.1016/j.apacoust.2024.110109},
  url = {https://www.sciencedirect.com/science/article/pii/S0003682X24002603},
  urldate = {2024-12-11},
  abstract = {This paper presents the outcomes of the ``Soundscape Attributes Translation Project'' (SATP), an international initiative addressing the critical research gap in soundscape descriptors translations for cross-cultural studies. Focusing on eighteen languages -- namely: Arabic, Chinese, Croatian, Dutch, English, French, German, Greek, Indonesian, Italian, Japanese, Korean, Malay, Portuguese, Spanish, Swedish, Turkish, and Vietnamese -- the study employs a four-step procedure to evaluate the reliability and cross-cultural validity of translated soundscape descriptors. The study introduces a three-tier confidence level system (Low, Medium, High) based on ``adjusted angles'', which are a measure proposed to correct the soundscape circumplex model (i.e., the pleasant-eventful space proposed in the ISO 12913 series) of a given language. Results reveal that most languages successfully maintain the quasi-circumplex structure of the original soundscape model, ensuring robust cross-cultural validity. English, Arabic, Chinese (Mandarin), Croatian, Dutch, German, Greek, Indonesian, Italian, Spanish, Swedish, and Turkish achieve a ``High'' confidence level. French, Japanese, Korean, Malay, Portuguese, and Vietnamese demonstrate varying confidence levels, highlighting the importance of the preliminary translation. This research significantly contributes to standardized cross-cultural methodologies in soundscape perception research, emphasizing the pivotal role of adjusted angles within the soundscape circumplex model in ensuring the accuracy of dimensions (i.e., attributes) locations. The SATP initiative offers insights into the complex interplay of language and meaning in the perception of environmental sounds, opening avenues for further cross-cultural soundscape research.},
  langid = {english},
  keywords = {Adjusted angles,Circumplex,ISO 12913,Semantic scales,Structural Summary Method (SSM)},
  annotation = {4 citations (Crossref/DOI) [2024-12-14]\\
4 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:21:45Z},
  file = {Aletta2024Soundscape - Soundscape descriptors in eighteen languages translation and validation through listening experimen.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Aletta2024Soundscape - Soundscape descriptors in eighteen languages translation and validation through listening experimen.pdf:application/pdf;S0003682X24002603.html:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/S0003682X24002603.html:text/html}
}

@article{Aletta2025Soundscape,
  title = {Soundscape Attributes Translation: Current Projects and Challenges},
  shorttitle = {Soundscape Attributes Translation},
  author = {Aletta, Francesco and Astolfi, Arianna and Kang, Jian and Oberman, Tin and Mitchell, Andrew},
  date = {2025-01-15},
  journaltitle = {Applied Acoustics},
  shortjournal = {Appl. Acoust.},
  volume = {228},
  pages = {110305},
  issn = {0003-682X},
  doi = {10.1016/j.apacoust.2024.110305},
  url = {https://www.sciencedirect.com/science/article/pii/S0003682X24004560},
  urldate = {2024-12-11},
  langid = {english},
  annotation = {0 citations (Crossref/DOI) [2024-12-14]\\
0 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:21:44Z},
  file = {Aletta2025Soundscape - Soundscape attributes translation current projects and challenges.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Aletta2025Soundscape - Soundscape attributes translation current projects and challenges.pdf:application/pdf;S0003682X24004560.html:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/S0003682X24004560.html:text/html}
}

@article{Chen2024Developing,
  title = {Developing a Taxonomy of Soundscape Interventions from a Catalogue of Real-World Examples},
  author = {Chen, Xiaochao and Aletta, Francesco and Moshona, Cleopatra Christina and Fiebig, Andr\'e and Henze, Helen and Kang, Jian and Mitchell, Andrew and Oberman, Tin and Schulte-Fortkamp, Brigitte and Tong, Huan},
  date = {2024},
  journaltitle = {Acta Acustica},
  shortjournal = {Acta Acust.},
  volume = {8},
  pages = {29},
  publisher = {EDP Sciences},
  issn = {2681-4617},
  doi = {10.1051/aacus/2024027},
  url = {https://acta-acustica.edpsciences.org/articles/aacus/abs/2024/01/aacus230101/aacus230101.html},
  urldate = {2024-12-12},
  abstract = {In recent decades, there has been a growing interest in urban soundscapes and a shift towards a user-focused approach in urban sound environments. Despite this interest, there is no comprehensive taxonomy for soundscape design available. The Catalogue of Soundscape Interventions (CSI) project aims to fill this gap by creating a tool to collect and share data on real soundscape practices, with the goal of developing a design toolkit and brief to facilitate communication between local authorities, consultants, and researchers. An online platform has been launched to gather instances of soundscape interventions. This paper proposes eight dimensions of soundscape interventions and presents a taxonomy that categorizes these interventions based on recurring strategies and goals observed in 43 practice cases collected. These dimensions include stages, contributors, scale, period of time, intervention types, public involvement, aims and purposes, and approaches. As soundscape practices increase in complexity and variety, the taxonomy can be revised and expanded. Nevertheless, the provided taxonomy serves as an orientation aid for understanding, analyzing, and designing soundscapes, leading to the development of more harmonious and contextually appropriate acoustic environments.},
  langid = {english},
  keywords = {/unread},
  annotation = {0 citations (Crossref/DOI) [2024-12-14]\\
0 citations (Crossref/DOI) [2024-12-14]\\
TLDR: This paper proposes eight dimensions of soundscape interventions and presents a taxonomy that categorizes these interventions based on recurring strategies and goals observed in 43 practice cases collected, leading to the development of more harmonious and contextually appropriate acoustic environments.},
  timestamp = {2024-12-14T00:19:44Z},
  file = {Chen2024Developing - Developing a taxonomy of soundscape interventions from a catalogue of real-world examples.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Chen2024Developing - Developing a taxonomy of soundscape interventions from a catalogue of real-world examples.pdf:application/pdf}
}

@inproceedings{Erfanian2019neurophysiology,
  title = {The Neurophysiology and Physiology of Soundscape: {{A}} Review of the  Empirical Literature},
  author = {Erfanian, Mercede and Mitchell, Andrew and Kang, Jian},
  date = {2019},
  pages = {2},
  location = {Brighton, United Kingdom},
  url = {https://www.researchgate.net/publication/330988852_The_neurophysiology_and_physiology_of_soundscape_A_review_of_the_empirical_literature},
  eventtitle = {The 6th {{European Conference}} on {{Psychology}} \& the {{Behavioral Sciences}} ({{ECP2019}})},
  langid = {english},
  keywords = {No DOI found},
  timestamp = {2024-12-11T02:37:30Z},
  file = {Erfanian2019neurophysiology - The neurophysiology and physiology of soundscape A review of the  empirical literature.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Erfanian2019neurophysiology - The neurophysiology and physiology of soundscape A review of the  empirical literature.pdf:application/pdf}
}

@article{Erfanian2019Psychophysiological,
  title = {The {{Psychophysiological Implications}} of {{Soundscape}}: {{A Systematic Review}} of {{Empirical Literature}} and a {{Research Agenda}}},
  shorttitle = {The {{Psychophysiological Implications}} of {{Soundscape}}},
  author = {Erfanian, Mercede and Mitchell, Andrew and Kang, Jian and Aletta, Francesco},
  date = {2019-09-21},
  journaltitle = {International Journal of Environmental Research and Public Health},
  shortjournal = {IJERPH},
  volume = {16},
  number = {19},
  pages = {3533},
  issn = {1660-4601},
  doi = {10.3390/ijerph16193533},
  url = {https://www.mdpi.com/1660-4601/16/19/3533},
  urldate = {2022-10-22},
  abstract = {The soundscape is defined by the International Standard Organization (ISO) 12913-1 as the human's perception of the acoustic environment, in context, accompanying physiological and psychological responses. Previous research is synthesized with studies designed to investigate soundscape at the `unconscious' level in an effort to more specifically conceptualize biomarkers of the soundscape. This review aims firstly, to investigate the consistency of methodologies applied for the investigation of physiological aspects of soundscape; secondly, to underline the feasibility of physiological markers as biomarkers of soundscape; and finally, to explore the association between the physiological responses and the well-founded psychological components of the soundscape which are continually advancing. For this review, Web of Science, PubMed, Scopus, and PsycINFO were searched for peer-reviewed articles published in English with combinations of the keywords `soundscape', `environmental noise/sound', `physiology/physiological', `psychology/psychological', and `perceptual attributes/affective/subjective assessment/appraisals'. Previous research suggests that Electrocardiography (ECG) and Vectorcardiography (VCG) biometrics quantifying Heart Rate (HR), stimulus-locked experimental design, and passive listening with homogeneous populations are predominantly applied to characterize the psychophysiology underlying the soundscape. Pleasantness and arousal are the most frequent psychological descriptors for soundscape subjective appraisals. Likewise, acoustic environments are reported to inconsistently evoke physiological responses with great variability among studies. The link between the perceptual attributes and physiological responses of soundscape vary within and among existing literature. While a few studies detected a link between physiological manifestations of soundscape and the perceptual attributes, the others failed to validate this link. Additionally, the majority of the study findings were limited to one or two physiological responses.},
  langid = {english},
  keywords = {acoustic environment,Acoustic environment,auditory,Auditory,noise,Noise,perceptual attributes,Perceptual attributes,physiology,Physiology,soundscape,Soundscape,SSID},
  annotation = {85 citations (Crossref/DOI) [2024-12-14]\\
85 citations (Crossref/DOI) [2024-12-14]\\
TLDR: This review aims to investigate the consistency of methodologies applied for the investigation of physiological aspects of soundscape, to underline the feasibility of physiological markers as biomarkers of sound landscape, and to explore the association between the physiological responses and the well-founded psychological components of the soundscape which are continually advancing.},
  timestamp = {2024-12-14T00:22:15Z},
  file = {Erfanian2019Psychophysiological - The Psychophysiological Implications of Soundscape A Systematic Review of Empirical Literature and.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Erfanian2019Psychophysiological - The Psychophysiological Implications of Soundscape A Systematic Review of Empirical Literature and.pdf:application/pdf}
}

@online{Erfanian2020Psychological,
  title = {Psychological {{Well-being}}, {{Age}} and {{Gender}} Can {{Mediate Soundscapes Pleasantness}} and {{Eventfulness}}: {{A}} Large Sample Study},
  shorttitle = {Psychological {{Well-being}}, {{Age}} and {{Gender}} Can {{Mediate Soundscapes Pleasantness}} and {{Eventfulness}}},
  author = {Erfanian, Mercede and Mitchell, Andrew and Aletta, Francesco and Kang, Jian},
  date = {2020-10-17},
  doi = {10.1101/2020.10.16.341834},
  url = {http://biorxiv.org/lookup/doi/10.1101/2020.10.16.341834},
  urldate = {2021-06-09},
  abstract = {Abstract           There is a great deal of literature on contributing environmental factors of soundscape, the perception of the acoustic environment by humans in context. Yet the impact of some contextual and person-related factors is largely unknown. From the questionnaire, adapted from ISO12913-2 and the WHO-5 well-being index, three questions arose: are there differences in Pleasantness and Eventfulness of soundscape among different acoustic environments; are high levels of psychological well-being associated with increased Pleasantness and Eventfulness ratings; and is soundscape Pleasantness and Eventfulness consistent among different age and gender groups? The sample comprised 1180 individual questionnaires, 621 females (52.6\%), 532 males (45.1\%), mean age 34.95 years \textpm{} 15.62, collected from eleven urban locations. Hierarchical clustering analysis was done on the mean of each sound source question for each survey location resulting in three clusters of locations based on sound source composition: Natural-dominant, Traffic-dominant and Mixed-sources. A Kruskal-Wallis was conducted to compare the mean Pleasantness and Eventfulness scores of the three clusters, demonstrating that the soundscape assessment was significantly different depending on sound source composition. Multiple linear regression models were used to analyse the relationship between psychological well-being, age, and gender with soundscape Pleasantness and Eventfulness. Our results indicated first that the positive psychological state was associated with Pleasantness in the all-locations and mixed-sources clusters, and with Eventfulness in the traffic-dominant cluster. Secondly, while age was linked to Pleasantness in all clusters it was merely associated with the Eventfulness in the all-locations cluster. Lastly, gender was associated with Pleasantness only in the all-locations cluster. These findings offer empirical grounds for developing theories of the contextual factors on soundscape.},
  langid = {english},
  pubstate = {prepublished},
  timestamp = {2024-12-11T02:35:20Z},
  file = {Erfanian2020Psychological - Psychological Well-being, Age and Gender can Mediate Soundscapes Pleasantness and Eventfulness A la.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Erfanian2020Psychological - Psychological Well-being, Age and Gender can Mediate Soundscapes Pleasantness and Eventfulness A la.pdf:application/pdf}
}

@article{Erfanian2021Psychological,
  title = {Psychological Well-Being and Demographic Factors Can Mediate Soundscape Pleasantness and Eventfulness: {{A}} Large Sample Study},
  shorttitle = {Psychological Well-Being and Demographic Factors Can Mediate Soundscape Pleasantness and Eventfulness},
  author = {Erfanian, Mercede and Mitchell, Andrew and Aletta, Francesco and Kang, Jian},
  date = {2021-10},
  journaltitle = {Journal of Environmental Psychology},
  shortjournal = {Journal of Environmental Psychology},
  volume = {77},
  pages = {101660},
  issn = {02724944},
  doi = {10.1016/j.jenvp.2021.101660},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0272494421001134},
  urldate = {2022-10-22},
  abstract = {Soundscape studies aim to consider the holistic human perception of a sound environment, including both the physical phenomena and how these are mediated by internal factors. This study aims to assess the influence of psychological well-being and demographic factors including age, gender, occupation status, and education levels on the dimensions of the soundscape circumplex, i.e., Pleasantness and Eventfulness. Data was collected in eleven urban locations in London through a large-scale (N = 1134) soundscape survey according to the ISO 12913-2 technical specifications and incorporating the WHO-5 well-being index. Linear mixed-effects modelling applying backwards-step feature selection was used to model the interactions between internal factors including psychological well-being, age, gender, occupation status, education levels and the soundscape Pleasantness and Eventfulness, while accounting for the random effects of the survey location. The findings suggest that internal factors account for approximately 1.4\% of the variance for Pleasantness and 3.9\% for Eventfulness, while the influence of the locations accounted for approximately 34\% and 14\%, respectively. Psychological well-being is positively associated with perceived Pleasantness, while there is a negative association with Eventfulness only for males. Occupation status, in particular retirement as a proxy of age and gender, was identified as a significant factor for both dimensions. These findings offer empirical grounds for developing theories of the interaction between internal factors and soundscape formation whilst highlighting the importance of the location, namely: the context.},
  langid = {english},
  annotation = {45 citations (Crossref/DOI) [2024-12-14]\\
45 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:21:19Z},
  file = {Erfanian2021Psychological - Psychological well-being and demographic factors can mediate soundscape pleasantness and eventfulnes.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Erfanian2021Psychological - Psychological well-being and demographic factors can mediate soundscape pleasantness and eventfulnes.pdf:application/pdf}
}

@article{Fang2024Determining,
  title = {Determining Factors for the Appropriateness of Soundscapes: A Cross-Sectional Large-Sample Study in {{London}} ({{UK}})a)},
  shorttitle = {Determining Factors for the Appropriateness of Soundscapes},
  author = {Fang, Xiang and Aletta, Francesco and Mitchell, Andrew and Oberman, Tin and Kang, Jian},
  date = {2024-11-26},
  journaltitle = {Journal of the Acoustical Society of America},
  shortjournal = {J. Acoust. Soc. Am.},
  volume = {156},
  number = {5},
  pages = {3588--3607},
  issn = {0001-4966},
  doi = {10.1121/10.0034418},
  url = {https://doi.org/10.1121/10.0034418},
  urldate = {2024-12-11},
  abstract = {This study examines the association between appropriateness and the pleasantness-eventfulness circumplex model, as well as the influencing environmental and personal factors, in accordance with the recommended questionnaire of ISO/TS 12913-2 (2018). A database was used, containing over 1000 soundscape surveys collected across eleven locations in London. Confirmatory factor analysis and the structural summary method were applied to validate the relationship between appropriateness and the pleasantness-eventfulness circumplex model, while linear multilevel models were developed to investigate the effect of personal and environmental factors on appropriateness. The findings highlight varying relationship between appropriateness and the pleasantness-eventfulness dimensions of the soundscape circumplex model. The effect of personal factors on appropriateness is not negligible, accounting for approximately 2.1\% of the variance. In contrast to the effects of the categories of landscape composition and acoustic metrics, dominant sound source type is the most influential category of environmental factors, with natural sounds explaining the most variance at 6\%. Traffic noise is negatively associated with appropriateness which varies by location, while human sounds are negatively associated with appropriateness when respondents were Asian/Asian British. The findings provide empirical evidence of the relationship between appropriateness and the soundscape circumplex model and offer comprehensive insights into the affecting factors.},
  langid = {english},
  keywords = {/unread},
  annotation = {0 citations (Crossref/DOI) [2024-12-14]\\
0 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:19:43Z},
  file = {Fang2024Determining - Determining factors for the appropriateness of soundscapes a cross-sectional large-sample study in.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Fang2024Determining - Determining factors for the appropriateness of soundscapes a cross-sectional large-sample study in.pdf:application/pdf;3322472.html:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/3322472.html:text/html}
}

@inproceedings{HarvieClark2024Integrating,
  title = {Integrating Acoustics Engineering and Soundscape Design for an Urban Park: A Case Study},
  shorttitle = {Integrating Acoustics Engineering and Soundscape Design for an Urban Park},
  booktitle = {Proceedings of the 10th {{Convention}} of the {{European Acoustics Association Forum Acusticum}} 2023},
  author = {Harvie-Clark, J. and Romeo Pitone, R. and Pereira, L. and Mitchell, Andrew},
  date = {2024-01-17},
  pages = {2049--2056},
  publisher = {European Acoustics Association},
  location = {Turin, Italy},
  doi = {10.61782/fa.2023.0918},
  url = {https://dael.euracoustics.org/confs/landing_pages/fa2023/000918.html},
  urldate = {2024-12-12},
  eventtitle = {10th {{Convention}} of the {{European Acoustics Association Forum Acusticum}} 2023},
  isbn = {978-88-88942-67-4},
  langid = {english},
  annotation = {0 citations (Crossref/DOI) [2024-12-14]\\
0 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:20:23Z},
  file = {HarvieClark2024Integrating - Integrating acoustics engineering and soundscape design for an urban park a case study.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/HarvieClark2024Integrating - Integrating acoustics engineering and soundscape design for an urban park a case study.pdf:application/pdf}
}

@article{Hou2023AIbased,
  title = {{{AI-based}} Soundscape Analysis: {{Jointly}} Identifying Sound Sources and Predicting Annoyance},
  shorttitle = {{{AI-based}} Soundscape Analysis},
  author = {Hou, Yuanbo and Ren, Qiaoqiao and Zhang, Huizhong and Mitchell, Andrew and Aletta, Francesco and Kang, Jian and Botteldooren, Dick},
  date = {2023-11-01},
  journaltitle = {The Journal of the Acoustical Society of America},
  shortjournal = {The Journal of the Acoustical Society of America},
  volume = {154},
  number = {5},
  pages = {3145--3157},
  issn = {0001-4966},
  doi = {10.1121/10.0022408},
  url = {https://doi.org/10.1121/10.0022408},
  urldate = {2024-12-12},
  abstract = {Soundscape studies typically attempt to capture the perception and understanding of sonic environments by surveying users. However, for long-term monitoring or assessing interventions, sound-signal-based approaches are required. To this end, most previous research focused on psycho-acoustic quantities or automatic sound recognition. Few attempts were made to include appraisal (e.g., in circumplex frameworks). This paper proposes an artificial intelligence (AI)-based dual-branch convolutional neural network with cross-attention-based fusion (DCNN-CaF) to analyze automatic soundscape characterization, including sound recognition and appraisal. Using the DeLTA dataset containing human-annotated sound source labels and perceived annoyance, the DCNN-CaF is proposed to perform sound source classification (SSC) and human-perceived annoyance rating prediction (ARP). Experimental findings indicate that (1) the proposed DCNN-CaF using loudness and Mel features outperforms the DCNN-CaF using only one of them. (2) The proposed DCNN-CaF with cross-attention fusion outperforms other typical AI-based models and soundscape-related traditional machine learning methods on the SSC and ARP tasks. (3) Correlation analysis reveals that the relationship between sound sources and annoyance is similar for humans and the proposed AI-based DCNN-CaF model. (4) Generalization tests show that the proposed model's ARP in the presence of model-unknown sound sources is consistent with expert expectations and can explain previous findings from the literature on soundscape augmentation.},
  langid = {english},
  keywords = {annoyance,noise,soundscape},
  annotation = {5 citations (Crossref/DOI) [2024-12-14]\\
5 citations (Crossref/DOI) [2024-12-14]\\
TLDR: An artificial intelligence (AI)-based dual-branch convolutional neural network with cross-attention-based fusion (DCNN-CaF) to analyze automatic soundscape characterization, including sound recognition and appraisal is proposed.},
  timestamp = {2024-12-14T00:19:00Z},
  file = {Hou2023AIbased - AI-based soundscape analysis jointly identifying sound sources and predicting annoyance.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Hou2023AIbased - AI-based soundscape analysis jointly identifying sound sources and predicting annoyance.pdf:application/pdf}
}

@inproceedings{Hou2023Exploring,
  title = {Exploring Annoyance in a Soundscape Context by Joint Prediction of Sound Source and Annoyance},
  booktitle = {Forum {{Acusticum}} 2023},
  author = {Hou, Yuanbo and Mitchell, Andrew and Ren, Qiaoqiao and Aletta, Francesco and Kang, Jian and Botteldooren, Dick},
  date = {2023-09},
  location = {Turin},
  keywords = {nosource},
  timestamp = {2024-12-10T16:36:02Z},
  file = {Hou2023Exploring - Exploring annoyance in a soundscape context by joint prediction of sound source and annoyance.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Hou2023Exploring - Exploring annoyance in a soundscape context by joint prediction of sound source and annoyance.pdf:application/pdf}
}

@inproceedings{Hou2023Joint,
  title = {Joint {{Prediction}} of {{Audio Event}} and {{Annoyance Rating}} in an {{Urban Soundscape}} by {{Hierarchical Graph Representation Learning}}},
  booktitle = {{{INTERSPEECH}} 2023},
  author = {Hou, Yuanbo and Song, Siyang and Luo, Cheng and Mitchell, Andrew and Ren, Qiaoqiao and Xie, Weicheng and Kang, Jian and Wang, Wenwu and Botteldooren, Dick},
  date = {2023-08-20},
  pages = {331--335},
  publisher = {ISCA},
  location = {Dublin},
  doi = {10.21437/Interspeech.2023-1021},
  url = {https://www.isca-archive.org/interspeech_2023/hou23_interspeech.html},
  urldate = {2024-12-12},
  eventtitle = {{{INTERSPEECH}} 2023},
  langid = {english},
  keywords = {!! duplicate},
  annotation = {2 citations (Crossref/DOI) [2024-12-14]\\
2 citations (Crossref/DOI) [2024-12-14]\\
TLDR: Experiments show the proposed HGRL successfully integrates AE with AR for AEC and ARP tasks, while coordinating the relations between cAE and fAE and further aligning the two different grains of AE information with the AR.},
  timestamp = {2024-12-14T00:20:29Z},
  file = {Hou2023Joint - Joint Prediction of Audio Event and Annoyance Rating in an Urban Soundscape by Hierarchical Graph Re 1.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Hou2023Joint - Joint Prediction of Audio Event and Annoyance Rating in an Urban Soundscape by Hierarchical Graph Re 1.pdf:application/pdf;Hou2023Joint - Joint Prediction of Audio Event and Annoyance Rating in an Urban Soundscape by Hierarchical Graph Re.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Hou2023Joint - Joint Prediction of Audio Event and Annoyance Rating in an Urban Soundscape by Hierarchical Graph Re.pdf:application/pdf;2308.html:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/2308.html:text/html}
}

@article{Hou2024Cooperative,
  title = {Cooperative Scene-Event Modelling for Acoustic Scene Classification},
  author = {Hou, Yuanbo and Kang, Bo and Mitchell, Andrew and Wang, Wenwu and Kang, Jian and Botteldooren, Dick},
  date = {2024},
  journaltitle = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  shortjournal = {IEEE/ACM Trans. Audio, Speech, Language Process.},
  volume = {32},
  pages = {68--82},
  issn = {2329-9304},
  doi = {10.1109/TASLP.2023.3323135},
  url = {https://ieeexplore.ieee.org/abstract/document/10274856},
  urldate = {2024-12-12},
  abstract = {Acoustic scene classification (ASC) can be helpful for creating context awareness for intelligent robots. Humans naturally use the relations between acoustic scenes (AS) and audio events (AE) to understand and recognize their surrounding environments. However, in most previous works, ASC and audio event classification (AEC) are treated as independent tasks, with a focus primarily on audio features shared between scenes and events, but not their implicit relations. To address this limitation, we propose a cooperative scene-event modelling (cSEM) framework to automatically model the intricate scene-event relation by an adaptive coupling matrix to improve ASC. Compared with other scene-event modelling frameworks, the proposed cSEM offers the following advantages. First, it reduces the confusion between similar scenes by aligning the information of coarse-grained AS and fine-grained AE in the latent space, and reducing the redundant information between the AS and AE embeddings. Second, it exploits the relation information between AS and AE to improve ASC, which is shown to be beneficial, even if the information of AE is derived from unverified pseudo-labels. Third, it uses a regression-based loss function for cooperative modelling of scene-event relations, which is shown to be more effective than classification-based loss functions. Instantiated from four models based on either Transformer or convolutional neural networks, cSEM is evaluated on real-life and synthetic datasets. Experiments show that cSEM-based models work well in real-life scene-event analysis, offering competitive results on ASC as compared with other multi-feature or multi-model ensemble methods. The ASC accuracy achieved on the TUT2018, TAU2019, and JSSED datasets is 81.0\%, 88.9\% and 97.2\%, respectively.},
  eventtitle = {{{IEEE}}/{{ACM Transactions}} on {{Audio}}, {{Speech}}, and {{Language Processing}}},
  langid = {english},
  keywords = {/unread,Acoustic scene classification,Acoustics,Adaptation models,audio event classification,cooperative modelling,Couplings,Predictive models,Scene classification,scene-event relation,Speech processing,Task analysis},
  annotation = {4 citations (Crossref/DOI) [2024-12-14]\\
4 citations (Crossref/DOI) [2024-12-14]\\
TLDR: A cooperative scene-event modelling (cSEM) framework to automatically model the intricate scene- event relation by an adaptive coupling matrix by exploiting the relation information between AS and AE to improve ASC, which is shown to be beneficial.},
  timestamp = {2024-12-14T00:19:37Z},
  file = {Hou2024Cooperative - Cooperative scene-event modelling for acoustic scene classification.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Hou2024Cooperative - Cooperative scene-event modelling for acoustic scene classification.pdf:application/pdf;10274856.html:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/10274856.html:text/html}
}

@online{Hou2024Soundscape,
  title = {Soundscape Captioning Using Sound Affective Quality Network and Large Language Model},
  author = {Hou, Yuanbo and Ren, Qiaoqiao and Mitchell, Andrew and Wang, Wenwu and Kang, Jian and Belpaeme, Tony and Botteldooren, Dick},
  date = {2024-11-29},
  eprint = {2406.05914},
  eprinttype = {arXiv},
  eprintclass = {eess},
  doi = {10.48550/arXiv.2406.05914},
  url = {http://arxiv.org/abs/2406.05914},
  urldate = {2024-12-11},
  abstract = {We live in a rich and varied acoustic world, which is experienced by individuals or communities as a soundscape. Computational auditory scene analysis, disentangling acoustic scenes by detecting and classifying events, focuses on objective attributes of sounds, such as their category and temporal characteristics, ignoring their effects on people, such as the emotions they evoke within a context. To fill this gap, we propose the soundscape captioning task, which enables automated soundscape analysis, thus avoiding labour-intensive subjective ratings and surveys in conventional methods. With soundscape captioning, context-aware descriptions are generated for soundscape by capturing the acoustic scene, event information, and the corresponding human affective qualities (AQs). To this end, we propose an automatic soundscape captioner (SoundSCaper) system composed of an acoustic model, i.e. SoundAQnet, and a large language model (LLM). SoundAQnet simultaneously models multi-scale information about acoustic scenes, events, and perceived AQs, while the LLM describes the soundscape with captions by parsing the information captured with SoundAQnet. The soundscape caption's quality is assessed by a jury of 16 audio/soundscape experts. The average score (out of 5) of SoundSCaper-generated captions is lower than the score of captions generated by two soundscape experts by 0.21 and 0.25, respectively, on the evaluation set and the model-unknown mixed external dataset with varying lengths and acoustic properties, but the differences are not statistically significant. Overall, the proposed SoundSCaper shows promising performance, with captions generated being comparable to those annotated by soundscape experts. The code of models, LLM scripts, human assessment data and instructions, and expert evaluation statistics are all publicly available.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing,Electrical Engineering and Systems Science - Signal Processing},
  annotation = {TLDR: An automatic soundscape captioner (SoundSCaper) system composed of an acoustic model, i.e. SoundAQnet, and a large language model (LLM), which enables automated soundscape analysis, thus avoiding labour-intensive subjective ratings and surveys in conventional methods is proposed.},
  timestamp = {2024-12-12T00:11:46Z},
  file = {Hou2024Soundscape - Soundscape captioning using sound affective quality network and large language model.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Hou2024Soundscape - Soundscape captioning using sound affective quality network and large language model.pdf:application/pdf;2406.html:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/2406.html:text/html}
}

@inproceedings{Kang2019soundscape,
  title = {Towards Soundscape Indices},
  booktitle = {Proceedings of the 23rd {{International Congress}} on {{Acoustics}}},
  author = {Kang, Jian and Aletta, Francesco and Oberman, Tin and Erfanian, Mercede and Kachlicka, Magdalena and Lionello, Matteo and Mitchell, Andrew},
  date = {2019-09},
  volume = {integrating 4th EAA Euroregio 2019 : 9-13 September 2019},
  pages = {2488--2495},
  publisher = {RWTH Aachen University},
  location = {Aachen},
  doi = {10.18154/RWTH-CONV-239249},
  url = {https://www.researchgate.net/publication/335661596{\_}Towards{\_}soundscape{\_}indices},
  abstract = {The growing field of soundscape studies considers sound environments as perceived, in context, with an interdisciplinary approach. This paper outlines an ongoing European Research Council (ERC) Advanced Grant project, which aims to establish ``soundscape indices'' (SSID). By taking psychological, (psycho)acoustical, neural and physiological, and contextual factors into account, SSID will adequately reflect levels of human comfort to integrate side-by-side with (and eventually replace) decibel-based metrics into existing (international) regulations, shifting the focus from noise control to a more holistic approach. Steps to achieve this include: to characterise soundscapes, by capturing acoustic environments and establishing a comprehensive database; to identify key factors and their influence on soundscape quality based on the database, by conducting laboratory psychological evaluations, acoustical/psychoacoustic factors analysis, and also, to research the neural and psychophysiological underpinnings of soundscape experience, by applying techniques such as functional Magnetic Resonance Imaging (fMRI) and Skin Conductance Response (SCR); to develop, test and validate the soundscape indices, by analysing the influences of various factors; to demonstrate the applicability of the soundscape indices in practice, by establishing frameworks for soundscape prediction, design, and standardisation. Ultimately, the findings of SSID will allow for an easy assessment of public spaces and the increase of the noise management impact.},
  langid = {english},
  keywords = {contextual factors,neural and physiological,soundscape database,SSID},
  timestamp = {2024-12-13T11:36:37Z},
  file = {Kang2019soundscape - Towards soundscape indices.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Kang2019soundscape - Towards soundscape indices.pdf:application/pdf}
}

@inproceedings{Kang2023development,
  title = {On the Development of {{Soundscape Indices}} ({{SSID}})},
  booktitle = {The 29th {{International Congress}} on {{Sound}} and {{Vibration}}},
  author = {Kang, Jian and Aletta, Francesco and Oberman, Tin and Mitchell, Andrew and Erfanian, Mercede},
  date = {2023-07},
  publisher = {{International Institute of Acoustics and Vibration (IIAV)}},
  location = {Prague},
  keywords = {nosource},
  timestamp = {2024-12-10T16:36:06Z},
  file = {Kang2023development - On the development of Soundscape Indices (SSID).pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Kang2023development - On the development of Soundscape Indices (SSID).pdf:application/pdf}
}

@inproceedings{Kang2023Subjective,
  title = {Subjective Evaluation of Environmental Sounds in Context - {{Towards Soundscape Indices}} ({{SSID}})},
  booktitle = {Forum {{Acusticum}} 2023},
  author = {Kang, Jian and Aletta, Francesco and Oberman, Tin and Mitchell, Andrew and Erfanian, Mercede},
  date = {2023-09},
  location = {Turin},
  keywords = {nosource},
  timestamp = {2024-12-10T16:36:06Z},
  file = {Kang2023Subjective - Subjective evaluation of environmental sounds in context - Towards Soundscape Indices (SSID).pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Kang2023Subjective - Subjective evaluation of environmental sounds in context - Towards Soundscape Indices (SSID).pdf:application/pdf}
}

@article{Kang2023Supportive,
  title = {Supportive Soundscapes Are Crucial for Sustainable Environments},
  author = {Kang, Jian and Aletta, Francesco and Oberman, Tin and Mitchell, Andrew and Erfanian, Mercede and Tong, Huan and Torresin, Simone and Xu, Chunyang and Yang, Tingting and Chen, Xiaochao},
  date = {2023-01},
  journaltitle = {Science of The Total Environment},
  shortjournal = {Science of The Total Environment},
  volume = {855},
  pages = {158868},
  issn = {00489697},
  doi = {10.1016/j.scitotenv.2022.158868},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0048969722059678},
  urldate = {2022-10-07},
  langid = {english},
  annotation = {11 citations (Crossref/DOI) [2024-12-14]\\
11 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:21:57Z},
  file = {Kang2023Supportive - Supportive soundscapes are crucial for sustainable environments.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Kang2023Supportive - Supportive soundscapes are crucial for sustainable environments.pdf:application/pdf}
}

@article{Lionello2021Introducing,
  title = {Introducing a {{Method}} for {{Intervals Correction}} on {{Multiple Likert Scales}}: {{A Case Study}} on an {{Urban Soundscape Data Collection Instrument}}},
  author = {Lionello, Matteo and Aletta, Francesco and Mitchell, Andrew and Kang, Jian},
  date = {2021},
  journaltitle = {Frontiers in Psychology},
  shortjournal = {Front. Psychol.},
  volume = {11},
  pages = {3943},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2020.602831},
  abstract = {Likert scales are useful for collecting data on attitudes and perceptions from large samples of people. In particular, they have become a well-established tool in soundscape studies for conducting in situ surveys to determine how people experience urban public spaces. However, it is still unclear whether the metrics of the scales are consistently interpreted during a typical assessment task. The current work aims at identifying some general trends in the interpretation of Likert scale metrics and introducing a procedure for the derivation of metric corrections by analyzing a case study dataset of 984 soundscape assessments across 11 urban locations in London. According to ISO/TS 12913-2:2018, soundscapes can be assessed through the scaling of 8 dimensions: pleasant, annoying, vibrant, monotonous, eventful, uneventful, calm, and chaotic. The hypothesis underlying this study is that a link exists between correlations across the percentage of assessments falling in each Likert scale category and a dilation/compression factor affecting the interpretation of the scales metric. The outcome of this metric correction value derivation is introduced for soundscape, and a new projection of the London soundscapes according to the corrected circumplex space is compared with the initial ISO circumplex space. The overall results show a general non-equidistant interpretation of the scales, particularly on the vibrant-monotonous direction. The implications of this correction have been demonstrated through a Linear Ridge Classifier task for predicting the London soundscape responses using objective acoustic parameters, which shows significant improvement when applied to the corrected data. The results suggest that the corrected values account for the non-equidistant interpretation of the Likert metrics, thereby allowing mathematical operations to be viable when applied to the data.},
  annotation = {24 citations (Crossref/DOI) [2024-12-14]\\
24 citations (Crossref/DOI) [2024-12-14]\\
TLDR: This work aims at identifying some general trends in the interpretation of Likert scale metrics and introducing a procedure for the derivation of metric corrections by analyzing a case study dataset of 984 soundscape assessments across 11 urban locations in London, showing a general non-equidistant interpretation of the scales.},
  timestamp = {2024-12-14T00:20:25Z},
  file = {Lionello2021Introducing - Introducing a Method for Intervals Correction on Multiple Likert Scales A Case Study on an Urban So.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Lionello2021Introducing - Introducing a Method for Intervals Correction on Multiple Likert Scales A Case Study on an Urban So.pdf:application/pdf}
}

@inproceedings{MaAlsinaPages2020Urban,
  title = {Urban Environment Soundscape Evaluation: {{Milan}} Case Study of Noise Events Perceptions by Citizens},
  booktitle = {{{INTER-NOISE}} and {{NOISE-CON Congress}} and {{Conference Proceedings}}},
  author = {Ma Alsina-Pag\`es, Rosa and Orga, Ferran and Freixes, Marc and Mallol, Roger and Aletta, Francesco and Mitchell, Andrew and Kang, Jian and Foraster, Maria},
  date = {2020},
  volume = {261},
  number = {3},
  pages = {3434--3441},
  publisher = {Institute of Noise Control Engineering},
  url = {https://www.researchgate.net/profile/Francesco_Aletta/publication/345314432_Urban_environment_soundscape_evaluation_Milan_case_study_of_noise_events_perceptions_by_citizens/links/5fa32d4ba6fdcc062414f711/Urban-environment-soundscape-evaluation-Milan-case-study-of-noise-events-perceptions-by-citizens.pdf},
  keywords = {No DOI found},
  timestamp = {2024-12-11T03:00:19Z},
  file = {MaAlsinaPages2020Urban - Urban environment soundscape evaluation Milan case study of noise events perceptions by citizens.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/MaAlsinaPages2020Urban - Urban environment soundscape evaluation Milan case study of noise events perceptions by citizens.pdf:application/pdf}
}

@inproceedings{Mitchell2019Making,
  title = {Making Cities Smarter with New Soundscape Indices},
  booktitle = {178th {{Meeting}} of the {{Acoustical Society}} of {{America}}},
  author = {Mitchell, Andrew and Aletta, Francesco and Oberman, Tin and Erfanian, Mercede and Kachlicka, Magdalena and Lionello, Matteo and Kang, Jian},
  date = {2019-12},
  volume = {146},
  number = {4},
  pages = {2873--2873},
  publisher = {Acoustical Society of America (ASA)},
  location = {San Diego},
  issn = {0001-4966},
  doi = {10.1121/1.5136970},
  abstract = {The core objectives of smart city design are to increase quality of life, enhance efficiency, and move towards the sustainability of cities. While this will involve increased integration of new and...},
  keywords = {nosource,SSID},
  annotation = {1 citations (Crossref/DOI) [2024-12-14]\\
1 citations (Crossref/DOI) [2024-12-14]\\
TLDR: The SSID project will characterise soundscapes, by capturing acoustic environments and establishing a comprehensive database; identify key factors and their influence on soundscape quality based on the database, by conducting laboratory psychological evaluations, acoustical/psychoacoustic factors analysis, and research the neural and psychophysiological underpinnings of soundscape experience.},
  timestamp = {2024-12-14T00:20:39Z}
}

@inproceedings{Mitchell2019spectral,
  title = {The Spectral Structure of Acoustic Time Series Can Predict the Perceptual Assessment of Urban Soundscapes},
  booktitle = {178th {{Meeting}} of the {{Acoustical Society}} of {{America}}},
  author = {Mitchell, Andrew and Kang, Jian},
  date = {2019-12},
  volume = {146},
  number = {4},
  pages = {2795--2795},
  publisher = {Acoustical Society of America (ASA)},
  location = {San Diego},
  issn = {0001-4966},
  doi = {10.1121/1.5136681},
  abstract = {The field of soundscape studies considers sound environments as perceived, in context, and has recently focussed on understanding the potential of physical acoustical features, including temporal characteristics, for predicting human perception. This study investigates the presence of a 1/f structure in the power spectrum slope of six (psycho)acoustical parameters of 30-s recordings of urban acoustic environments. The acoustical parameters were calculated as time series throughout the recording period, then the power spectrum of the time series was calculated and plotted on a log-log scale, with the x-axis ranging from 30 s/10-1.5 Hz to 0.01 s/102 Hz. The slope of the best-fitted straight line through the power spectrum was calculated and compared to the corresponding perceptual attribute ratings of the soundscape collected on site during the recording. The dataset includes 300 + recording-response pairs. An overall 1/f structure was not found for any of the parameters. Differences in temporal behaviour are indicated at different time scales, with a deviation in slope typically occurring at {$\sim$}2 s/0.5 Hz, reflecting differences in temporal behaviour among within-sound-event time scales and between-sound-event time scales. An ordinal logistic regression model is developed which predicts the perceptual attributes of urban soundscapes based on the spectral slopes of the acoustic time series.},
  keywords = {nosource,SSID},
  annotation = {1 citations (Crossref/DOI) [2024-12-14]\\
1 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:22:22Z}
}

@article{Mitchell2020Soundscape,
  title = {The {{Soundscape Indices}} ({{SSID}}) {{Protocol}}: {{A Method}} for {{Urban Soundscape Surveys}}--{{Questionnaires}} with {{Acoustical}} and {{Contextual Information}}},
  author = {Mitchell, Andrew and Oberman, Tin and Aletta, Francesco and Erfanian, Mercede and Kachlicka, Magdalena and Lionello, Matteo and Kang, Jian},
  date = {2020-04},
  journaltitle = {Applied Sciences},
  shortjournal = {Appl. Sci.},
  volume = {10},
  number = {7},
  pages = {2397},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app10072397},
  abstract = {A protocol for characterizing urban soundscapes for use in the design of Soundscape Indices (SSID) and general urban research as implemented under the European Research Council (ERC)-funded SSID project is described in detail. The protocol consists of two stages: (1) a Recording Stage to collect audio-visual recordings for further analysis and for use in laboratory experiments, and (2) a Questionnaire Stage to collect in situ soundscape assessments via a questionnaire method paired with acoustic data collection. Key adjustments and improvements to previous methodologies for soundscape characterization have been made to enable the collation of data gathered from research groups around the world. The data collected under this protocol will form a large-scale, international soundscape database.},
  keywords = {ambisonic recording,binaural recordings,ISO12913,nonfile,questionnaire,soundscape,Soundscape,ssid,SSID,visual factors},
  annotation = {63 citations (Crossref/DOI) [2024-12-14]\\
63 citations (Crossref/DOI) [2024-12-14]\\
TLDR: A protocol for characterizing urban soundscapes for use in the design of Soundscape Indices (SSID) and general urban research as implemented under the European Research Council (ERC)-funded SSID project is described in detail.},
  timestamp = {2024-12-14T00:22:20Z},
  file = {Mitchell2020Soundscape - The Soundscape Indices (SSID) Protocol A Method for Urban Soundscape Surveys–Questionnaires with Ac.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Mitchell2020Soundscape - The Soundscape Indices (SSID) Protocol A Method for Urban Soundscape Surveys–Questionnaires with Ac.pdf:application/pdf}
}

@inproceedings{Mitchell2021Development,
  title = {Development of a Multi-Level Predictive Soundscape Model to Assess the Soundscapes of Public Spaces during the {{COVID-19}} Lockdowns},
  booktitle = {181st {{Meeting}} of the {{Acoustical Society}} of {{America}}},
  author = {Mitchell, Andrew and Oberman, Tin and Aletta, Francesco and Kang, Jian},
  date = {2021},
  volume = {150},
  number = {4},
  pages = {A293-A293},
  location = {Seattle},
  doi = {10.1121/10.0008334},
  url = {https://doi.org/10.1121/10.0008334},
  keywords = {nosource},
  annotation = {1 citations (Crossref/DOI) [2024-12-14]\\
1 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:19:46Z}
}

@software{Mitchell2021International,
  title = {The {{International Soundscape Database}}: {{An}} Integrated Multimedia Database of Urban Soundscape Surveys -- Questionnaires with Acoustical and Contextual Information},
  author = {Mitchell, Andrew and Oberman, Tin and Aletta, Francesco and Erfanian, Mercede and Kachlicka, Magdalena and Lionello, Matteo and Kang, Jian},
  date = {2021-10},
  doi = {10.5281/zenodo.5578572},
  organization = {Zenodo},
  keywords = {nosource},
  timestamp = {2024-12-10T16:37:34Z}
}

@article{Mitchell2021Investigating,
  title = {Investigating Urban Soundscapes of the {{COVID-19}} Lockdown: {{A}} Predictive Soundscape Modeling Approach},
  author = {Mitchell, Andrew and Oberman, Tin and Aletta, Francesco and Kachlicka, Magdalena and Lionello, Matteo and Erfanian, Mercede and Kang, Jian},
  date = {2021-12},
  journaltitle = {The Journal of the Acoustical Society of America},
  shortjournal = {J. Acoust. Soc. Am.},
  volume = {150},
  number = {6},
  pages = {4474--4488},
  publisher = {Acoustical Society of America (ASA)},
  doi = {10.1121/10.0008928},
  annotation = {25 citations (Crossref/DOI) [2024-12-14]\\
25 citations (Crossref/DOI) [2024-12-14]\\
TLDR: The usefulness of predictive modeling and the importance of considering contextual information when discussing the impact of sound level reductions on the soundscape are demonstrated.},
  timestamp = {2024-12-14T00:20:30Z},
  file = {Mitchell2021Investigating - Investigating urban soundscapes of the COVID-19 lockdown A predictive soundscape modeling approach.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Mitchell2021Investigating - Investigating urban soundscapes of the COVID-19 lockdown A predictive soundscape modeling approach.pdf:application/pdf}
}

@misc{Mitchell2022DeLTA,
  title = {{{DeLTA}} ({{Deep Learning Techniques}} for Noise {{Annoyance}} Detection) {{Dataset}}},
  author = {Mitchell, Andrew and Erfanian, Mercede and Soelitsyo, Christopher and Oberman, Tin and Aletta, Francesco},
  date = {2022},
  doi = {10.5281/ZENODO.7158056},
  organization = {Zenodo},
  keywords = {environmental sound recognition,nosource,sound sources,soundscape},
  timestamp = {2024-12-10T16:36:15Z}
}

@article{Mitchell2022Effects,
  title = {Effects of {{Soundscape Complexity}} on {{Urban Noise Annoyance Ratings}}: {{A Large-Scale Online Listening Experiment}}},
  shorttitle = {Effects of {{Soundscape Complexity}} on {{Urban Noise Annoyance Ratings}}},
  author = {Mitchell, Andrew and Erfanian, Mercede and Soelistyo, Christopher and Oberman, Tin and Kang, Jian and Aldridge, Robert and Xue, Jing-Hao and Aletta, Francesco},
  date = {2022-11},
  journaltitle = {International Journal of Environmental Research and Public Health},
  shortjournal = {Int. J. Environ. Res. Public. Health},
  volume = {19},
  number = {22},
  pages = {14872},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1660-4601},
  doi = {10.3390/ijerph192214872},
  url = {https://www.mdpi.com/1660-4601/19/22/14872},
  urldate = {2022-12-30},
  abstract = {Noise annoyance has been often reported as one of the main adverse effects of noise exposure on human health, and there is consensus that it relates to several factors going beyond the mere energy content of the signal. Research has historically focused on a limited set of sound sources (e.g., transport and industrial noise); only more recently is attention being given to more holistic aspects of urban acoustic environments and the role they play in the noise annoyance perceptual construct. This is the main approach promoted in soundscape studies, looking at both wanted and unwanted sounds. In this study, three specific aspects were investigated, namely: (1) the effect of different sound sources combinations, (2) the number of sound sources present in the soundscape, and (3) the presence of individual sound source, on noise annoyance perception. For this purpose, a large-scale online experiment was carried out with 1.2k+ participants, using 2.8k+ audio recordings of complex urban acoustic environments to investigate how they would influence the perceived noise annoyance. Results showed that: (1) the combinations of different sound sources were not important, compared, instead, to the number of sound sources identified in the soundscape recording (regardless of sound sources type); (2) the annoyance ratings expressed a minimum when any two clearly distinguishable sound sources were present in a given urban soundscape; and (3) the presence (either in isolation or combination) of traffic-related sound sources increases noise annoyance, while the presence (either in isolation or combination) of nature-related sound sources decreases noise annoyance.},
  issue = {22},
  langid = {english},
  keywords = {noise annoyance,sound perception,sound source recognition,soundscape,urban environments},
  annotation = {18 citations (Crossref/DOI) [2024-12-14]\\
18 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:19:57Z},
  file = {Mitchell2022Effects - Effects of Soundscape Complexity on Urban Noise Annoyance Ratings A Large-Scale Online Listening Ex.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Mitchell2022Effects - Effects of Soundscape Complexity on Urban Noise Annoyance Ratings A Large-Scale Online Listening Ex.pdf:application/pdf}
}

@article{Mitchell2022How,
  title = {How to Analyse and Represent Quantitative Soundscape Data},
  author = {Mitchell, Andrew and Aletta, Francesco and Kang, Jian},
  date = {2022},
  journaltitle = {JASA Express Letters},
  shortjournal = {JASA Express Lett.},
  volume = {2},
  number = {3},
  pages = {037201},
  doi = {10.1121/10.0009794},
  url = {https://doi.org/10.1121/10.0009794},
  annotation = {30 citations (Crossref/DOI) [2024-12-14]\\
30 citations (Crossref/DOI) [2024-12-14]\\
TLDR: This study first examines the methods presented in ISO 12913 for analysing and representing soundscape data by applying them to a large existing database of soundscape assessments and provides an open-source visualisation tool to facilitate a nuanced approach to soundscape assessment and design.},
  timestamp = {2024-12-14T00:20:15Z},
  file = {Mitchell2022How - How to analyse and represent quantitative soundscape data.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Mitchell2022How - How to analyse and represent quantitative soundscape data.pdf:application/pdf}
}

@thesis{Mitchell2022Predictive,
  type = {phdthesis},
  title = {Predictive {{Modelling}} of {{Complex Urban Soundscapes}} - {{Enabling}} an Engineering Approach to Soundscape Design},
  shorttitle = {Predictive {{Modelling}} of {{Complex Urban Soundscapes}}},
  author = {Mitchell, Andrew},
  date = {2022-06-06},
  institution = {University College London},
  location = {London, UK},
  url = {https://discovery.ucl.ac.uk/id/eprint/10156562},
  langid = {english},
  pagetotal = {232},
  timestamp = {2024-12-11T03:01:53Z},
  file = {Mitchell2022Predictive - Predictive Modelling of Complex Urban Soundscapes - Enabling an engineering approach to soundscape d.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Mitchell2022Predictive - Predictive Modelling of Complex Urban Soundscapes - Enabling an engineering approach to soundscape d.pdf:application/pdf}
}

@inproceedings{Mitchell2023conceptual,
  title = {A Conceptual Framework for the Practical Use of Predictive Models and {{Soundscape Indices}}: {{Goals}}, Constraints, and Applications},
  shorttitle = {A Conceptual Framework for the Practical Use of Predictive Models and {{Soundscape Indices}}},
  booktitle = {{{INTER-NOISE}} and {{NOISE-CON Congress}} and {{Conference Proceedings}}},
  author = {Mitchell, Andrew and Aletta, Francesco and Oberman, Tin and Erfanian, Mercede and Kang, Jian},
  date = {2023-11-30},
  volume = {268},
  pages = {2108--2118},
  location = {Chiba, Greater Tokyo},
  doi = {10.3397/IN_2023_0309},
  url = {https://www.ingentaconnect.com/content/10.3397/IN_2023_0309},
  urldate = {2024-12-11},
  abstract = {With the recent standardization of soundscape, there has been increased interest in bringing the soundscape approach into an engineering context. While traditional assessment methods, such as those given in the ISO 12913 series, provide information on the current status quo of an environment,  they offer limited insight into hypothetical environments and are therefore less relevant for design purposes. This conference paper presents a conceptual framework for the practical use of predictive soundscape models and indices. The framework outlines the goals, constraints, and potential  applications of these models and highlights the need for further research in this area to better understand the dynamics of soundscape perception and to put predictive models to practical use. Predictive soundscape models can be integrated with soundscape indices - such as those being developed  by the Soundscape Indices (SSID) project - for assessment purposes, providing a comprehensive approach to evaluating and designing sound environments. The use of predictive models is necessary to address the challenges faced in practical applications of the soundscape approach and to fill  the gap between traditional assessment methods and the design of sound environments.},
  langid = {english},
  annotation = {1 citations (Crossref/DOI) [2024-12-14]\\
1 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:18:39Z},
  file = {Mitchell2023conceptual - A conceptual framework for the practical use of predictive models and Soundscape Indices Goals, con.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Mitchell2023conceptual - A conceptual framework for the practical use of predictive models and Soundscape Indices Goals, con.pdf:application/pdf}
}

@inproceedings{Mitchell2023Deep,
  title = {Deep Learning Techniques for Noise Annoyance Detection: {{Results}} from an Intensive Workshop at the {{Alan Turing Institute}}},
  booktitle = {The {{Journal}} of the {{Acoustical Society}} of {{America}}},
  author = {Mitchell, Andrew and Brown, Emmeline and Deo, Ratneel and Hou, Yuanbo and Kirton-Wingate, Jasper and Liang, Jinhua and Sheinkman, Alisa and Soelistyo, Christopher and Sood, Hari and Wongprommoon, Arin and Xing, Kaiyue and Yip, Wingyan and Aletta, Francesco},
  date = {2023-03},
  volume = {153},
  pages = {A262--A262},
  publisher = {Acoustical Society of America (ASA)},
  location = {Chicago},
  doi = {10.1121/10.0018787},
  issue = {3\_supplement},
  keywords = {nosource},
  annotation = {2 citations (Crossref/DOI) [2024-12-14]\\
2 citations (Crossref/DOI) [2024-12-14]\\
TLDR: Investigation of how sound source information could be incorporated into deep learning models for predicting urban noise annoyance detection showed that including sound source labels as a simultaneous training output, rather than as an explicit model input resulted in the best performance.},
  timestamp = {2024-12-14T00:19:41Z}
}

@inproceedings{Mitchell2023How,
  title = {How Do We Define Soundscape?},
  booktitle = {Forum {{Acusticum}} 2023},
  author = {Mitchell, Andrew and Aletta, Francesco and Oberman, Tin},
  date = {2023-09},
  location = {Turin},
  keywords = {nosource},
  timestamp = {2024-12-10T16:36:16Z},
  file = {Mitchell2023How - How do we define soundscape.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Mitchell2023How - How do we define soundscape.pdf:application/pdf}
}

@dataset{Mitchell2023International,
  title = {The {{International Soundscape Database}}: {{An}} Integrated Multimedia Database of Urban Soundscape Surveys -- Questionnaires with Acoustical and Contextual Information},
  author = {Mitchell, Andrew and Oberman, Tin and Aletta, Francesco and Erfanian, Mercede and Kachlicka, Magdalena and Lionello, Matteo and Kang, Jian},
  date = {2023-09-19},
  publisher = {Zenodo},
  doi = {10.5281/zenodo.6331810},
  url = {https://zenodo.org/record/6331810},
  version = {v0.2.4},
  keywords = {nosource},
  timestamp = {2024-12-10T16:36:40Z}
}

@software{Mitchell2023Soundscapy,
  title = {Soundscapy},
  author = {Mitchell, Andrew},
  date = {2023-09-19},
  url = {https://github.com/MitchellAcoustics/Soundscapy},
  version = {v0.5.4},
  keywords = {nosource},
  timestamp = {2024-12-11T16:37:40Z}
}

@online{Mitchell2024Searching,
  title = {Searching for a Common Understanding of 'Soundscape': A Critical Look at the Definitions and Uses of the Term},
  shorttitle = {Searching for a Common Understanding of 'Soundscape'},
  author = {Mitchell, Andrew and Oberman, Tin and Aletta, Francesco and Kang, Jian},
  date = {2024-01-15},
  eprinttype = {OSF},
  doi = {10.31219/osf.io/6dbnu},
  url = {https://osf.io/6dbnu},
  urldate = {2024-12-12},
  abstract = {Nearly 10 years ago, the definition of soundscape was codified in an ISO standard for the first time. This definition drew from Schafer and Southworth's work, which focused squarely on human perception in context. However, the term soundscape has seen widespread academic and popular adoption in fields and applications well outside its original 'human perception' context. This paper will collect a range of definitions of soundscape across urban, underwater, ecological and other contexts. These uses often conflict with the ISO 12913 definition, both by drawing the focus away from humans and by declining to define soundscape as a perceptual construct. This paper will examine these broader uses of the term and consider a possible new definition which aims to reemphasise soundscape's relation to landscape and harmonise the standard definition with its varied uses.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {/unread,Auditory Environment,ISO 12913,Soundscape},
  annotation = {0 citations (Crossref/DOI) [2024-12-14]\\
0 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:21:32Z},
  file = {Mitchell2024Searching - Searching for a common understanding of 'soundscape' a critical look at the definitions and uses of.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Mitchell2024Searching - Searching for a common understanding of 'soundscape' a critical look at the definitions and uses of.pdf:application/pdf}
}

@article{Mitchell2024Soundscape,
  title = {Soundscape Perception Indices ({{SPIs}}): Developing Context-Dependent Single Value Scores of Multidimensional Soundscape Perceptual Quality},
  shorttitle = {Soundscape Perception Indices ({{SPIs}})},
  author = {Mitchell, Andrew and Aletta, Francesco and Oberman, Tin and Kang, Jian},
  date = {2024-12-03},
  journaltitle = {Journal of the Acoustical Society of America},
  shortjournal = {J. Acoust. Soc. Am.},
  volume = {156},
  number = {6},
  pages = {3694--3706},
  issn = {0001-4966},
  doi = {10.1121/10.0034417},
  url = {https://doi.org/10.1121/10.0034417},
  urldate = {2024-12-11},
  abstract = {The soundscape approach provides a basis for considering the holistic perception of sound environments in context. Whereas steady advancements have been made in methods for assessment and analysis, a gap exists for comparing soundscapes and quantifying improvements in the multidimensional perception of a soundscape. To this end, there is a need for the creation of single value indices to compare soundscape quality which incorporate context, aural diversity, and specific design goals for a given application. Just as a variety of decibel-based indices have been developed for various purposes (e.g.,  LAeq,  LCeq,  L90,  Lden, etc.), the soundscape approach requires the ability to create original indices for different uses, which share a common language and understanding. Therefore, a unified framework for creating bespoke and reference single index measures of soundscape perception is proposed, allowing for different metrics to be defined in the future. This framework is based on a four-step test-target paradigm wherein a desired soundscape perception is defined as a target distribution within the soundscape circumplex, and the two-dimensional Kolmogorov-Smirnov distance is used to test an assessed soundscape against this target. Applications and implications of this framework are discussed, and a multi-objective optimisation method for empirically defining perception indices is proposed.},
  langid = {english},
  annotation = {0 citations (Crossref/DOI) [2024-12-14]\\
0 citations (Crossref/DOI) [2024-12-14]\\
TLDR: A unified framework for creating bespoke and reference single index measures of soundscape perception is proposed, allowing for different metrics to be defined in the future, and a multi-objective optimisation method for empirically defining perception indices is proposed.},
  timestamp = {2024-12-14T00:21:48Z},
  file = {Mitchell2024Soundscape - Soundscape perception indices (SPIs) developing context-dependent single value scores of multidimen.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Mitchell2024Soundscape - Soundscape perception indices (SPIs) developing context-dependent single value scores of multidimen.pdf:application/pdf;3323658.html:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/3323658.html:text/html}
}

@inproceedings{Mitchell2024Soundscapy,
  title = {Soundscapy: A Python Package for Soundscape Assessment and Analysis},
  shorttitle = {Soundscapy},
  booktitle = {{{INTER-NOISE}} and {{NOISE-CON Congress}} and {{Conference Proceedings}}},
  author = {Mitchell, Andrew},
  date = {2024-10-04},
  volume = {270},
  pages = {4029--4039},
  publisher = {Institute of Noise Control Engineering},
  location = {Nantes},
  doi = {10.3397/IN_2024_3404},
  url = {https://www.ingentaconnect.com/content/10.3397/IN_2024_3404},
  urldate = {2024-12-13},
  abstract = {Soundscape questionnaires are widely used to gather subjective information about people's perceptions and attitudes towards their acoustic environment. Despite the widespread adoption of ISO/TS 12913-3 guidelines for analyzing soundscape survey data, there are still several interpretations  and challenges in application. To enable the easy, accessible, and consistent analysis of soundscape data, an open-source python package called Soundscapy has been developed. This package implements a visualization approach for soundscape data analysis using a probabilistic method that depicts  the collective perception of a soundscape as a distribution of responses within the circumplex. In addition, functions for psychoacoustic and acoustic analysis of binaural data are included, with a focus on consistent and optimized processing of multiple recordings. This conference paper outlines  the important features of Soundscapy, explains its basic functioning, lists its current capabilities, and gives recommendations for its best use. Finally, the future development of Soundscapy is proposed, including the integration of predictive soundscape models for use in automated assessment  and design.},
  eventtitle = {{{INTER-NOISE}} 2024},
  langid = {english},
  keywords = {nosource},
  annotation = {0 citations (Crossref/DOI) [2024-12-14]\\
0 citations (Crossref/DOI) [2024-12-14]\\
TLDR: The important features of Soundscapy are outlined, its basic functioning is explained, its current capabilities are listed, and its future development is proposed, including the integration of predictive soundscape models for use in automated assessment and design.},
  timestamp = {2025-01-02T19:52:28Z},
  file = {Mitchell2024Soundscapy - Soundscapy a python package for soundscape assessment and analysis.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Mitchell2024Soundscapy - Soundscapy a python package for soundscape assessment and analysis.pdf:application/pdf}
}

@inproceedings{Moshona2022What,
  title = {What Is a Soundscape Intervention? {{Exploring}} Definitions and Identifi-Cation Criteria and a Platform to Gather Real-World Examples},
  booktitle = {51st {{International Congress}} and {{Exposition}} on {{Noise Control Engineering}} ({{INTER-NOISE}} 2022)},
  author = {Moshona, Cleopatra Christina and Aletta, Francesco and Henze, Helen and Chen, Xiaochao and Mitchell, Andrew and Oberman, Tin and Tong, Huan and Fiebig, Andr\'e and Kang, Jian and Schulte-Fortkamp, Brigitte},
  date = {2022},
  url = {https://www.researchgate.net/profile/Francesco-Aletta/publication/362906252_What_is_a_soundscape_intervention_Exploring_definitions_and_identification_criteria_and_a_platform_to_gather_real-world_examples/links/630664e561e4553b95364712/What-is-a-soundscape-intervention-Exploring-definitions-and-identification-criteria-and-a-platform-to-gather-real-world-examples.pdf},
  keywords = {No DOI found},
  timestamp = {2024-12-13T11:42:35Z},
  file = {Moshona2022What - What is a soundscape intervention Exploring definitions and identification criteria and a platform.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Moshona2022What - What is a soundscape intervention Exploring definitions and identification criteria and a platform.pdf:application/pdf}
}

@article{Moshona2024framework,
  title = {A Framework to Characterize and Classify Soundscape Design Practices Based on Grounded Theory},
  author = {Moshona, Cleopatra Christina and Fiebig, Andr\'e and Aletta, Francesco and Chen, Xiaochao and Kang, Jian and Mitchell, Andrew and Oberman, Tin and Schulte-Fortkamp, Brigitte},
  date = {2024-01-01},
  journaltitle = {Noise Mapping},
  shortjournal = {Noise Mapp.},
  volume = {11},
  number = {1},
  publisher = {De Gruyter Open Access},
  issn = {2084-879X},
  doi = {10.1515/noise-2024-0002},
  url = {https://www.degruyter.com/document/doi/10.1515/noise-2024-0002/html},
  urldate = {2024-12-12},
  abstract = {In recent years, various stakeholders and political decision-makers have recognized the significance of high-quality urban sound environments, stressing the need for user-centered trajectories. Despite the rising interest in this field, the soundscape approach has not yet fully permeated urban planning and design, possibly due to a lack of comprehensible guidelines on how to implement and curate successful soundscape designs, attributed to on-going developments on this subject. In the course of the Catalogue of Soundscape Interventions (CSI) Project, a taxonomy of eight dimensions was developed to serve as an orientation aid for practitioners, describing important aspects of soundscape-related measures that can be used as a brief to facilitate communication between authorities, consultants, and researchers. This study describes the theoretical framework and, in particular, the sequential coding process involved in deriving these dimensions, which is based on grounded theory. It lists observations and limitations of the resulting taxonomy and builds upon these findings to critically review and revisit existing nomenclature and concepts. Finally, a qualitative distinction in the form of a design pyramid according to ascending levels of epistemic rigor is proposed, to differentiate between documented practices, which may serve as a reference point for future harmonization and standardization.},
  langid = {english},
  keywords = {grounded theory,ISO/TS 12913-4,pyramid,soundscape design strategies,soundscape interventions},
  annotation = {1 citations (Crossref/DOI) [2024-12-14]\\
1 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:18:42Z},
  file = {Moshona2024framework - A framework to characterize and classify soundscape design practices based on grounded theory.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Moshona2024framework - A framework to characterize and classify soundscape design practices based on grounded theory.pdf:application/pdf}
}

@article{Orga2021Multilevel,
  title = {Multilevel {{Annoyance Modelling}} of {{Short Environmental Sound Recordings}}},
  author = {Orga, Ferran and Mitchell, Andrew and Freixes, Marc and Aletta, Francesco and Alsina-Pag\`es, Rosa Ma and Foraster, Maria},
  date = {2021-05},
  journaltitle = {Sustainability},
  volume = {13},
  number = {11},
  pages = {5779},
  publisher = {MDPI AG},
  issn = {2071-1050},
  doi = {10.3390/su13115779},
  url = {https://www.mdpi.com/2071-1050/13/11/5779},
  abstract = {The recent development and deployment of Wireless Acoustic Sensor Networks (WASN) present new ways to address urban acoustic challenges in a smart city context. A focus on improving quality of life forms the core of smart-city design paradigms and cannot be limited to simply measuring objective environmental factors, but should also consider the perceptual, psychological and health impacts on citizens. This study therefore makes use of short (1--2.7 s) recordings sourced from a WASN in Milan which were grouped into various environmental sound source types and given an annoyance rating via an online survey with N=100 participants. A multilevel psychoacoustic model was found to achieve an overall R2=0.64 which incorporates Sharpness as a fixed effect regardless of the sound source type and Roughness, Impulsiveness and Tonality as random effects whose coefficients vary depending on the sound source. These results present a promising step toward implementing an on-sensor annoyance model which incorporates psychoacoustic features and sound source type, and is ultimately not dependent on sound level.},
  annotation = {9 citations (Crossref/DOI) [2024-12-14]\\
9 citations (Crossref/DOI) [2024-12-14]\\
TLDR: A multilevel psychoacoustic model was found to achieve an overall R2=0.64 which incorporates Sharpness as a fixed effect regardless of the sound source type and Roughness, Impulsiveness and Tonality as random effects whose coefficients vary depending on the sound sources.},
  timestamp = {2024-12-14T00:20:48Z},
  file = {Orga2021Multilevel - Multilevel Annoyance Modelling of Short Environmental Sound Recordings.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Orga2021Multilevel - Multilevel Annoyance Modelling of Short Environmental Sound Recordings.pdf:application/pdf}
}

@article{Papadakis2022Translation,
  title = {Translation and Cross-Cultural Adaptation Methodology for Soundscape Attributes -- {{A}} Study with Independent Translation Groups from {{English}} to {{Greek}}},
  author = {Papadakis, Nikolaos M. and Aletta, Francesco and Kang, Jian and Oberman, Tin and Mitchell, Andrew and Stavroulakis, Georgios E.},
  date = {2022-11},
  journaltitle = {Applied Acoustics},
  shortjournal = {Applied Acoustics},
  volume = {200},
  pages = {109031},
  issn = {0003682X},
  doi = {10.1016/j.apacoust.2022.109031},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X22004054},
  urldate = {2022-10-14},
  langid = {english},
  annotation = {39 citations (Crossref/DOI) [2024-12-14]\\
39 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:22:29Z},
  file = {Papadakis2022Translation - Translation and cross-cultural adaptation methodology for soundscape attributes – A study with indep.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Papadakis2022Translation - Translation and cross-cultural adaptation methodology for soundscape attributes – A study with indep.pdf:application/pdf}
}

@article{Papadakis2023City,
  title = {City, Town, Village: Potential Differences in Residents Soundscape Perception Using {{ISO}}/{{TS}} 12913-2: 2018},
  shorttitle = {City, Town, Village},
  author = {Papadakis, Nikolaos M. and Aletta, Francesco and Kang, Jian and Oberman, Tin and Mitchell, Andrew and Aroni, Ioanna and Stavroulakis, Georgios E.},
  date = {2023},
  journaltitle = {Applied Acoustics},
  shortjournal = {Appl. Acoust.},
  volume = {213},
  pages = {109659},
  publisher = {Elsevier},
  doi = {10.1016/j.apacoust.2023.109659},
  url = {https://www.sciencedirect.com/science/article/pii/S0003682X23004577},
  urldate = {2024-12-12},
  langid = {english},
  keywords = {/unread,ObsCite},
  annotation = {4 citations (Crossref/DOI) [2024-12-14]\\
4 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:19:31Z},
  file = {Papadakis2023City - City, town, village potential differences in residents soundscape perception using ISOTS 12913-2.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Papadakis2023City - City, town, village potential differences in residents soundscape perception using ISOTS 12913-2.pdf:application/pdf;S0003682X23004577.html:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/S0003682X23004577.html:text/html}
}

@article{Tong2021Increases,
  title = {Increases in Noise Complaints during the {{COVID-19}} Lockdown in {{Spring}} 2020: {{A}} Case Study in {{Greater London}}, {{UK}}},
  author = {Tong, Huan and Aletta, Francesco and Mitchell, Andrew and Oberman, Tin and Kang, Jian},
  date = {2021},
  journaltitle = {Science of The Total Environment},
  shortjournal = {Sci. Total Environ.},
  volume = {785},
  pages = {147213},
  issn = {0048-9697},
  doi = {10.1016/j.scitotenv.2021.147213},
  url = {https://www.sciencedirect.com/science/article/pii/S0048969721022841},
  abstract = {Many cities around the world have claimed that the enforcement of lockdown measures to contain the spread of COVID-19 and the corresponding limitations of human activities led to reduced environmental noise levels. However, noise complaints reported by many local authorities were on the rise soon after the local lockdowns came into force. This research took Greater London in the UK as a case study. The overall aim was examining how noise complaints changed during the first stages of the lockdown implementation, during Spring 2020, both locally and at city scale, and how urban factors may have been influencing them. Noise complaint and urban factor datasets from the Government's publicly available data warehouse were used. The results show that during the COVID-19 lockdown the number of noise complaints increased by 48\%, compared with the same period during Spring 2019. In terms of noise sources, complaints about construction (36\%) and neighbourhood (50\%) noise showed significant increases. Urban factors, including housing and demographic factors, played a more significant role than the actual noise exposure to road and rail traffic noise, as derived from the London noise maps. In detail, the change rate of noise complaints was higher in areas with higher unemployment rates, more residents with no qualifications, and lower house price. It is expected that this study could help government with allocating resources more effectively and achieve a better urban environment.},
  keywords = {COVID-19,Demographic factors,Housing factors,Noise complaint,Noise level band,Transport factors},
  annotation = {53 citations (Crossref/DOI) [2024-12-14]\\
53 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:20:18Z},
  file = {Tong2021Increases - Increases in noise complaints during the COVID-19 lockdown in Spring 2020 A case study in Greater L.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Tong2021Increases - Increases in noise complaints during the COVID-19 lockdown in Spring 2020 A case study in Greater L.pdf:application/pdf}
}

@article{Vida2021Urban,
  title = {Urban {{Soundscape Assessment}} by {{Visually Impaired People}}: {{First Methodological Approach}} in {{Granada}} ({{Spain}})},
  shorttitle = {Urban {{Soundscape Assessment}} by {{Visually Impaired People}}},
  author = {Vida, Jer\'onimo and Almagro, Jos\'e Antonio and Garc\'ia-Quesada, Rafael and Aletta, Francesco and Oberman, Tin and Mitchell, Andrew and Kang, Jian},
  date = {2021-12-15},
  journaltitle = {Sustainability},
  shortjournal = {Sustainability},
  volume = {13},
  number = {24},
  pages = {13867},
  issn = {2071-1050},
  doi = {10.3390/su132413867},
  url = {https://www.mdpi.com/2071-1050/13/24/13867},
  urldate = {2022-10-07},
  abstract = {Soundscape assessments by citizens are starting to emerge as a common practice, normally carried out in context by means of soundwalks along selected paths with volunteers. However, when such assessments are carried out, either in situ or in laboratory experiments, visually impaired citizens are not usually involved. To address this question, three soundwalks were carried out in 2020 in the city of Granada, in southern Spain, with the participation of visually impaired people. In this paper, we present the lessons learnt from this research with respect to the methodology issues that have to do with soundwalking and the surveying procedures when people with limited vison are participating, the assessment results, and a comparison with a soundscape evaluation carried out in 2019 without the collaboration of visually impaired people. The results of this preliminary campaign highlight that: (1) Adapting soundscape assessment protocols from standards for visually impaired people is a methodological challenge that requires research attention; (2) Some of the different patterns in the assessment of the soundscape pleasantness between visually impaired and nonvisually impaired participants emerged; (3) The perception of quietness may differ for visually impaired people when orientation and identification are factors that play a role in the acoustic environment evaluation.},
  langid = {english},
  annotation = {4 citations (Crossref/DOI) [2024-12-14]\\
4 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:22:36Z},
  file = {Vida2021Urban - Urban Soundscape Assessment by Visually Impaired People First Methodological Approach in Granada (S.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Vida2021Urban - Urban Soundscape Assessment by Visually Impaired People First Methodological Approach in Granada (S.pdf:application/pdf}
}

@article{Vida2023Soundscape,
  title = {Soundscape Attributes in Spanish: A Comparison with the English Version of the Protocol Proposed in Method a of the {{ISO}}/{{TS}} 12913--2},
  shorttitle = {Soundscape Attributes in Spanish},
  author = {Vida, Jer\'onimo and Antonio Almagro, Jos\'e and Garc\'ia-Quesada, Rafael and Aletta, Francesco and Oberman, Tin and Mitchell, Andrew and Kang, Jian},
  date = {2023-08-01},
  journaltitle = {Applied Acoustics},
  shortjournal = {Appl. Acoust.},
  volume = {211},
  pages = {109516},
  issn = {0003-682X},
  doi = {10.1016/j.apacoust.2023.109516},
  url = {https://www.sciencedirect.com/science/article/pii/S0003682X23003146},
  urldate = {2024-12-12},
  abstract = {In soundscape studies there is a need to validate the ISO 12913 framework and questionnaire protocols in non-English speaking regions, which is being addressed via an international translation effort carried out within the Soundscape Attributes Translation Project (SATP). The objective of the SATP initiative is to promote the widespread use of the soundscape circumplex model attributes by validating proposed translations using standardized listening experiments in different languages and geographical regions. This study compares the Spanish (ISO 639:spa) translation of the ISO soundscape circumplex model with the original English version and introduces the Structural Summary Method (SSM) for analysis. The research findings suggest a reasonable accordance in listening experiments carried out by native English and Spanish speakers, but also highlight the need for revision of the ``vibrant/monotonous'' and ``eventful/uneventful'' dimensions to harmonize the interpretation of each dimension by the affected population. These revisions not only improve the translation of the model into Spanish, but also raise questions about the adequacy of the original English formulation of the model. The study underscores the cultural differences underlying the meaning of these dimensions and the challenges of objectifying the soundscape circumplex model within the ISO 12913 framework.},
  langid = {english},
  keywords = {Circumplex model,ISO 12913,Soundscape assessment,Soundscape attributes,Spanish language},
  annotation = {19 citations (Crossref/DOI) [2024-12-14]\\
19 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:21:43Z},
  file = {Vida2023Soundscape - Soundscape attributes in spanish a comparison with the english version of the protocol proposed in.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Vida2023Soundscape - Soundscape attributes in spanish a comparison with the english version of the protocol proposed in.pdf:application/pdf;Vida2023Soundscape - Soundscape attributes in spanish a comparison with the english version of the protocol proposed in.html:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Vida2023Soundscape - Soundscape attributes in spanish a comparison with the english version of the protocol proposed in.html:text/html}
}

@article{VidaManzano2021sound,
  title = {The "Sound of Silence" in {{Granada}} during the {{COVID-19}} Lockdown},
  author = {Vida Manzano, Jer\'onimo and Almagro Pastor, Jos\'e Antonio and Garc\'ia Quesada, Rafael and Aletta, Francesco and Oberman, Tin and Mitchell, Andrew and Kang, Jian},
  date = {2021},
  journaltitle = {Noise Mapping},
  shortjournal = {Noise Mapp.},
  volume = {8},
  number = {1},
  pages = {16--31},
  publisher = {De Gruyter},
  doi = {10.1515/noise-2021-0002},
  keywords = {nonfile},
  annotation = {28 citations (Crossref/DOI) [2024-12-14]\\
28 citations (Crossref/DOI) [2024-12-14]\\
TLDR: Results show a great change in environmental noise levels that is interesting not only because of its magnitude, but also for its implications, especially at those sites where social human activity was an identifying characteristic.},
  timestamp = {2024-12-14T00:22:01Z},
  file = {VidaManzano2021sound - The sound of silence in Granada during the COVID-19 lockdown.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/VidaManzano2021sound - The sound of silence in Granada during the COVID-19 lockdown.pdf:application/pdf}
}

@inproceedings{Xu2024Effects,
  title = {Effects of Visual Stimulus on Soundscape Perception: A Pilot Study Using Immersive Virtual Reality ({{IVR}})},
  shorttitle = {Effects of Visual Stimulus on Soundscape Perception},
  booktitle = {Proceedings of the 10th {{Convention}} of the {{European Acoustics Association Forum Acusticum}} 2023},
  author = {Xu, X. and Oberman, Tin and Mitchell, Andrew and Huang, S. and Aletta, F. and Kang, J.},
  date = {2024-01-17},
  pages = {1047--1054},
  publisher = {European Acoustics Association},
  location = {Turin, Italy},
  doi = {10.61782/fa.2023.0732},
  url = {https://dael.euracoustics.org/confs/landing_pages/fa2023/000732.html},
  urldate = {2024-12-12},
  eventtitle = {10th {{Convention}} of the {{European Acoustics Association Forum Acusticum}} 2023},
  isbn = {978-88-88942-67-4},
  langid = {english},
  keywords = {/unread},
  annotation = {0 citations (Crossref/DOI) [2024-12-14]\\
0 citations (Crossref/DOI) [2024-12-14]},
  timestamp = {2024-12-14T00:19:58Z},
  file = {Xu2024Effects - Effects of visual stimulus on soundscape perception a pilot study using immersive virtual reality (.pdf:/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/References/Xu2024Effects - Effects of visual stimulus on soundscape perception a pilot study using immersive virtual reality (.pdf:application/pdf}
}
