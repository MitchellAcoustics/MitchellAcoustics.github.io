[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Appearance on Across Acoustics\n\n\n\n\n\n\n\npodcast\n\n\n\n\nI recently appeared on the official podcast of the Acoustical Society of America to talk about my paper which was published in JASA Express Letters last year.\n\n\n\n\n\n\nApr 14, 2023\n\n\nAndrew Mitchell\n\n\n\n\n\n\n  \n\n\n\n\nNavigating the UK Graduate Visa Process: A PhD Graduate’s Experience\n\n\n\n\n\n\n\nwebsite\n\n\n\n\n\n\n\n\n\n\n\nFeb 1, 2023\n\n\nAndrew Mitchell\n\n\n\n\n\n\n  \n\n\n\n\nQuarto for an Academic Website\n\n\n\n\n\n\n\nwebsite\n\n\n\n\nI continue my long search for a way to generate a nicely formatted website with publication list based on adding publication information to a single source of truth without re-remembering how all the formatting works each time.\n\n\n\n\n\n\nMay 11, 2022\n\n\nAndrew Mitchell\n\n\n\n\n\n\n  \n\n\n\n\nContributing to the Pandemic Sensory Archive\n\n\n\n\n\n\n\npodcast\n\n\n\n\nIn 2021, I was interviewed by Dr William Tullett of Anglia Ruskin University in Cambridge. Dr Tullett created the Pandemic Sensory Archive “to explore bodies and senses through a digital platform, in light of experiences of the COVID-19 pandemic”.\n\n\n\n\n\n\nJun 9, 2021\n\n\nAndrew Mitchell\n\n\n\n\n\n\n  \n\n\n\n\nPhD Upgrade done and passed, thankfully!\n\n\n\n\n\n\n\nphd-life\n\n\n\n\n\n\n\n\n\n\n\nJun 19, 2020\n\n\nAndrew Mitchell\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "circumplex\n\ncircumplex is a Python package for analyzing and visualizing circumplex data. It provides a set of tools for analyzing and visualizing circumplex data, following the Structural Summary Method. This project is a Python implementation based on the R circumplex package. Our goal is to provide a similar functionality and experience for Python users.\n\n        \n        Website\n     \n        \n        Github\n     \n        \n        Package\n    \nsoundscapy\n\nsoundscapy is a Python package for the analysis of soundscapes.\nThis package was designed to (1) load and process soundscape assessment data, (2) visualise the data, and (3) enable psychoacoustic analysis of soundscape recordings.\n\n        \n        Website\n     \n        \n        Github\n     \n        \n        Package"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Andrew Mitchell",
    "section": "",
    "text": "I am currently a Senior Research Fellow in urban soundscape modelling at University College London (UCL). My research interests include soundscape analysis and visualisation, machine learning, and human perception of complex sounds.\nI was awarded two PhD- and one Post-doctoral Enrichment Awards from The Alan Turing Institute and spent a month in early 2022 as a visiting research fellow at Stockholm University. My ongoing projects include the Soundscape Indices (SSID) Horizon 2020 project, Soundscapy, Deep Learning Techniques for noise Annoyance detection (DeLTA), the Catalogue of Soundscape Interventions (CSI), and the Soundscape Attributes Translation Project (SATP).\nI am also the host of The Rest is Just Noise, a monthly podcast exploring the relationship between sound and our cities. Each episode, along with my co-hosts and colleagues Dr Francesco Aletta and Dr Tin Oberman, I speak with researchers and experts from a wide range of backgrounds about their work in urban sounds and sound perception."
  },
  {
    "objectID": "posts/visa-process/index.html",
    "href": "posts/visa-process/index.html",
    "title": "Navigating the UK Graduate Visa Process: A PhD Graduate’s Experience",
    "section": "",
    "text": "I recently finished my PhD (yay!) and went through the process of applying for a UK Graduate Visa. Although I had a job offer lined up, I chose the Graduate Visa route instead of a standard Work Visa. In this blog post, I’ll explain my motivations for this decision and give an overview of the process.\nThe UK Graduate Visa is a type of visa that allows international students who have completed a degree programme in the UK to stay in the country for a longer period after graduation. The visa provides the opportunity to work and settle in the UK. When I completed my Bachelor’s at Cardiff University in 2015, there were limited options to remain in the country and limited benefits for having graduated from a UK university.\nThankfully this has changed somewhat with the introduction of the Graduate Visa.\nAt the time, the best option was the standard Tier 2 Skilled Worker visa. By applying for this visa from a student visa, my employer and I were able to bypass some standard work checks and I was exempt from salary requirements. However, when I was granted this visa in 2015, it was only valid for a year. When I was offered a new job with a different company, I was required to apply for a new work visa, this time subject to all the requirements.\nThis became a problem when the new job did not meet the increased salary requirements and my visa application was denied. Despite having lived in the UK for four years, earned a BSc in Physics & Music, and being actively recruited for the job, I was forced to leave the country and return to the US.\nWhen I completed my PhD and was offered a Research Fellowship at UCL, I had to decide between applying for a Skilled Worker visa or a Graduate visa. Given my previous experience with work visas, I chose the Graduate visa. Unlike the Skilled Worker visa, the Graduate visa allows PhD graduates to remain in the UK with minimal restrictions for three years, without having to reapply each time they take on a new contract or change jobs.\nHowever, there were some challenges I faced when applying for the Graduate visa. Firstly, I had to pay for the visa myself, as my prospective employer would not cover the cost for the Graduate visa since I was no longer guaranteed to work for them. Secondly, the timeline for applying for the visa was difficult; you cannot apply for the visa until you have completed everything and been awarded your degree - this means passing the viva, submitting corrections, and having those corrections approved by your examiners. From thesis submission to completion can take anywhere from 3 months to a year and a half. And this is all assuming you submit on time!\nDespite these challenges, my experience with the Graduate visa application was relatively smooth, and it was a more straightforward process compared to the Student visa or the Work visa. Although there was still some stress and uncertainty, I didn’t encounter any major issues and I was able to successfully obtain the visa."
  },
  {
    "objectID": "posts/visa-process/index.html#my-graduate-visa-timeline",
    "href": "posts/visa-process/index.html#my-graduate-visa-timeline",
    "title": "Navigating the UK Graduate Visa Process: A PhD Graduate’s Experience",
    "section": "My Graduate Visa timeline",
    "text": "My Graduate Visa timeline\n\n\n\n\n\n\nNote\n\n\n\nSome parts of this process may be specific to UCL, however the general outline should be universal. The fact that UCL lists your official completion date as the 28th of whatever month you fulfilled all of the requirements is probably specific to UCL, but there may be similar policies at other unis. I think it’s important to be aware of this sort of thing (which no one ever tells you about) especially if you’re working to potentially tight timelines.\n\n\nTo help give a concrete example for people of what this timeline looks like, I’ve laid out the exact dates for each step of my process. My Student Visa was set to expire in January of the next year, so I planned out the timeline preparing for lots of delays and issues to make sure my right to stay and work wouldn’t be in jeopardy.\n\n[June 06] - Thesis submission\n[Sept 08] - Viva\n[Sept 09] - Receive report and corrections from examiners\n[Sept 26] - Submit my corrections to examiners\n[Sept 30] - Examiners confirm their acceptance via email to me and formally inform UCL. (I had very responsive examiners and minimal corrections so this was quite fast)\n[Sept 30] - UCL sends email confirming they received the notification from examiners and instructed my to upload an electronic copy of the thesis.\n[Oct 03] - UCL sends confirmation of results email. This confirms all of the details of my degree: Name, programme, start date, end date, etc. Importantly, the official date of the award is the 28th of the month you fulfill all of the requirements (i.e. upload the electronic copy). For me, even though I uploaded on the 30th, they back dated it to the 28th of September. If I had finished everything on the 1st October, my official award date would have been 28th October.\n\n\n\n\n\n\n\nWarning\n\n\n\nVery important note: you cannot submit your visa application until the University informs the Home Office you have completed your degree. This is not the same as them sending your certificate to you. This is a separate process and should be automatically done directly from the University to the Home Office.\n\n\n\n[Oct 19] - Confirmation that UCL has informed the Home Office about my degree. Now I can submit the visa application. I think if my official date had been delayed to October 28th, I wouldn’t have been able to submit my visa application until after that date.\n[Oct 19] - Submit visa application and pay application fees and immigration health surcharge.\n[Nov 22] - Visa granted.\n\nIf you were fully funded (100% tuition and stipend) during your PhD, you will need to provide evidence from your funder that they consent to your Graduate Visa application. The reason for this requirement is unclear, but it is important to note. If you were not fully funded, you may not need to provide this consent, but it is still a good idea to be prepared in case it is required. To ease my worries, my supervisor, who was the principal investigator on my funding grant, and I drafted a letter addressing this issue. Although the Home Office did not mention it, it is always better to be safe than sorry.\nThis information is intended to give you an idea of what the application process looks like. Please note that the experience may vary from person to person. For example, my submission, viva, and correction process was quick and straightforward, which may not be the case for everyone.\nIn conclusion, the UK Graduate Visa provides an attractive option for international PhD graduates looking to stay in the UK and further their careers. While there may be some challenges in the application process, especially for those who were fully funded during their PhD studies, the benefits of not having to reapply for a work visa every time you change jobs and the freedom to change careers make it a worthwhile option to consider. Overall, my experience with the Graduate Visa application was positive and I hope this article provides some helpful insight for those who may be considering it in the future."
  },
  {
    "objectID": "posts/phd-upgrade-done/index.html",
    "href": "posts/phd-upgrade-done/index.html",
    "title": "PhD Upgrade done and passed, thankfully!",
    "section": "",
    "text": "In the UK, halfway through the PhD we undergo a process known as the ‘upgrade’. The purpose is to take stock of our progress made so far and to determine whether we are likely to make it to the end of the PhD successfully. To do this, we present a seminar and prepare a report of our current progress before having a session with an internal panel where they ask further questions about your work and the existing state of the field. If the panel confirms that we have made adequate progress and have a good plan to finish, we can be upgraded to a PhD candidate. I always find it really helpful to look at previous examples of stuff like this, and wasn’t able to find many examples or much guidance on what it should look like. To help others, I’ve decided to host my report here, feel free to use it as an example, but remember it meets the requirements of my specific department at this time, and yours may differ.\nOn a side note, because this year is wild, I received the email letting me know I passed my PhD upgrade while kneeling in the Black Lives Matter demonstration in Parliament Square. It can be difficult to process the emotions of outrage and frustration simultaneously with relief and hope. I don’t have anything more profound to say on that, except that shit’s crazy but life trudges on. I’ll be back out at the protests this weekend.\nIt also means I had to finally settle on a decent thesis title, I landed on Machine Learning and Regression Modelling of Dynamic Urban Soundscapes: A multilevel approach.\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "research/papers.html",
    "href": "research/papers.html",
    "title": "Papers",
    "section": "",
    "text": "How to analyse and represent quantitative soundscape data\n\n\n\n\n\n\n\njournal-articles\n\n\n\n\nPublished in JASA Express Letters in March, 2022. \n\n\n\n\n\n\n\nMar 16, 2022\n\n\nAndrew Mitchell, Andrew Mitchell, Francesco Aletta, Jian Kang\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research/list-of-pubs.html",
    "href": "research/list-of-pubs.html",
    "title": "List of Publications",
    "section": "",
    "text": "Journal Papers\n2024\nYuanbo Hou, Bo Kang, Andrew Mitchell, Wenwu Wang, Jian Kang, and Dick Botteldooren. (2024) \"Cooperative Scene-Event Modelling for Acoustic Scene Classification.\" IEEE/ACM Transactions on Audio, Speech, and Language Processing doi: 10.1109/TASLP.2023.3323135 \n        \n        Published\n     \n2023\nFrancesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, and Jian Kang. (2023) \"Soundscape experience of public spaces in different world regions: A comparison between the European and Chinese contexts via a large-scale on-site surveya).\" The Journal of the Acoustical Society of America doi: 10.1121/10.0020842 \n        \n        Published\n     \nYuanbo Hou, Qiaoqiao Ren, Huizhong Zhang, Andrew Mitchell, Francesco Aletta, Jian Kang, and Dick Botteldooren. (2023) \"AI-based soundscape analysis: Jointly identifying sound sources and predicting annoyancea).\" The Journal of the Acoustical Society of America doi: 10.1121/10.0022408 \n        \n        Published\n     \nJian Kang, Francesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, Huan Tong, Simone Torresin, Chunyang Xu, Tingting Yang, and Xiaochao Chen. (2023) \"Supportive soundscapes are crucial for sustainable environments.\" Science of The Total Environment doi: 10.1016/j.scitotenv.2022.158868 \n        \n        Published\n     \nNikolaos M. Papadakis, Francesco Aletta, Jian Kang, Tin Oberman, Andrew Mitchell, Ioanna Aroni, and Georgios E. Stavroulakis. (2023) \"City, town, village: Potential differences in residents soundscape perception using ISO/TS 12913-2:2018.\" Applied Acoustics doi: 10.1016/j.apacoust.2023.109659 \n        \n        Published\n     \nJerónimo Vida, José Antonio Almagro, Rafael García-Quesada, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Jian Kang. (2023) \"Soundscape attributes in Spanish: A comparison with the English version of the protocol proposed in Method A of the ISO/TS 12913–2.\" Applied Acoustics doi: 10.1016/j.apacoust.2023.109516 \n        \n        Published\n     \n2022\nAndrew Mitchell, Mercede Erfanian, Christopher Soelistyo, Tin Oberman, Jian Kang, Robert Aldridge, Jing-Hao Xue, and Francesco Aletta. (2022) \"Effects of Soundscape Complexity on Urban Noise Annoyance Ratings: A Large-Scale Online Listening Experiment.\" International Journal of Environmental Research and Public Health doi: 10.3390/ijerph192214872 \n        \n        Published\n     \nAndrew Mitchell, Francesco Aletta, and Jian Kang. (2022) \"How to analyse and represent quantitative soundscape data.\" JASA Express Letters doi: 10.1121/10.0009794 \n        \n        Published\n     \n2021\nMercede Erfanian, Andrew Mitchell, Francesco Aletta, and Jian Kang. (2021) \"Psychological well-being and demographic factors can mediate soundscape pleasantness and eventfulness: A large sample study.\" Journal of Environmental Psychology doi: 10.1016/j.jenvp.2021.101660 \n        \n        Published\n     \nMatteo Lionello, Francesco Aletta, Andrew Mitchell, and Jian Kang. (2021) \"Introducing a Method for Intervals Correction on Multiple Likert Scales: A Case Study on an Urban Soundscape Data Collection Instrument.\" Frontiers in Psychology doi: 10.3389/fpsyg.2020.602831 \n        \n        Published\n     \nAndrew Mitchell, Tin Oberman, Francesco Aletta, Magdalena Kachlicka, Matteo Lionello, Mercede Erfanian, and Jian Kang. (2021) \"Investigating urban soundscapes of the COVID-19 lockdown: A predictive soundscape modeling approach.\" The Journal of the Acoustical Society of America doi: 10.1121/10.0008928 \n        \n        Published\n     \nFerran Orga, Andrew Mitchell, Marc Freixes, Francesco Aletta, Rosa Ma Alsina-Pagès, and Maria Foraster. (2021) \"Multilevel Annoyance Modelling of Short Environmental Sound Recordings.\" Sustainability doi: 10.3390/su13115779 \n        \n        Published\n     \nHuan Tong, Francesco Aletta, Andrew Mitchell, Tin Oberman, and Jian Kang. (2021) \"Increases in noise complaints during the COVID-19 lockdown in Spring 2020: A case study in Greater London, UK.\" Science of The Total Environment doi: 10.1016/j.scitotenv.2021.147213 \n        \n        Published\n     \nJerónimo Vida Manzano, José Antonio Almagro Pastor, Rafael García Quesada, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Jian Kang. (2021) \"The \"sound of silence\" in Granada during the COVID-19 lockdown.\" Noise Mapping doi: 10.1515/noise-2021-0002 \n        \n        Published\n     \n2020\nFrancesco Aletta, Tin Oberman, Andrew Mitchell, Huan Tong, and Jian Kang. (2020) \"Assessing the changing urban sound environment during the COVID-19 lockdown period using short-term acoustic measurements.\" Noise Mapping doi: 10.1515/noise-2020-0011 \n        \n        Published\n     \nAndrew Mitchell, Tin Oberman, Francesco Aletta, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Jian Kang. (2020) \"The Soundscape Indices (SSID) Protocol: A Method for Urban Soundscape Surveys–Questionnaires with Acoustical and Contextual Information.\" Applied Sciences doi: 10.3390/app10072397 \n        \n        Published\n     \n2019\nFrancesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, Matteo Lionello, Magdalena Kachlicka, and Jian Kang. (2019) \"Associations between soundscape experience and self-reported wellbeing in open public urban spaces: A field study.\" The Lancet doi: 10.1016/s0140-6736(19)32814-4 \n        \n        Published\n     \nMercede Erfanian, Andrew J. Mitchell, Jian Kang, and Francesco Aletta. (2019) \"The Psychophysiological Implications of Soundscape: A Systematic Review of Empirical Literature and a Research Agenda.\" International Journal of Environmental Research and Public Health doi: 10.3390/ijerph16193533 \n        \n        Published\n     \nConference Papers\n2023\nJack Harvie-Clark, Rebecca Romeo Pitone, Luis Pereira, and Andrew Mitchell. (2023) \"Integrating acoustics engineering and soundscape design for an urban park: a case study.\" In Forum Acusticum 2023\n        \n        Published\n    \nYuanbo Hou, Andrew Mitchell, Qiaoqiao Ren, Francesco Aletta, Jian Kang, and Dick Botteldooren. (2023) \"Exploring annoyance in a soundscape context by joint prediction of sound source and annoyance.\" In Forum Acusticum 2023\nYuanbo Hou, Siyang Song, Cheg Luo, Andrew Mitchell, Qiaoqiao Ren, Jian Kang, Wenwu Want, and Dick Botteldooren. (2023) \"Joint prediction of audio event and annoyance rating in an urban soundscape by hierarchical graph representation learning.\" In 24th INTERSPEECH Conference\nJian Kang, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Mercede Erfanian. (2023) \"On the development of Soundscape Indices (SSID).\" In The 29th International Congress on Sound and Vibration\nJian Kang, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Mercede Erfanian. (2023) \"Subjective evaluation of environmental sounds in context - Towards Soundscape Indices (SSID).\" In Forum Acusticum 2023\nAndrew Mitchell, Francesco Aletta, Tin Oberman, Mercede Erfanian, and Jian Kang. (2023) \"A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraints, and applications.\" In INTER-NOISE 2023 Conference\nAndrew Mitchell, Emmeline Brown, Ratneel Deo, Yuanbo Hou, Jasper Kirton-Wingate, Jinhua Liang, Alisa Sheinkman, Christopher Soelistyo, Hari Sood, Arin Wongprommoon, Kaiyue Xing, Wingyan Yip, and Francesco Aletta. (2023) \"Deep learning techniques for noise annoyance detection: Results from an intensive workshop at the Alan Turing Institute.\" The Journal of the Acoustical Society of America doi: 10.1121/10.0018787 \n        \n        Published\n     \nAndrew Mitchell, Francesco Aletta, Tin Oberman, and Jian Kang. (2023) \"How do we define soundscape?.\" In Forum Acusticum 2023\nAndrew Mitchell. (2023) \"Soundscapy: A python package for soundscape assessment and analysis.\" In INTER-NOISE 2023 Conference\n2022\nCleopatra Christina Moshona, Francesco Aletta, Helen Henze, Xiaochao Chen, Andrew Mitchell, Tin Oberman, Huan Tong, André Fiebig, Jian Kang, and Brigitte Schulte-Fortkamp. (2022) \"What is a soundscape intervention? Exploring definitions and identifi-cation criteria and a platform to gather real-world examples.\" In 51st International Congress and Exposition on Noise Control Engineering (INTER-NOISE 2022)\n        \n        Published\n    \n2021\nAndrew Mitchell, Tin Oberman, Francesco Aletta, and Jian Kang. (2021) \"Development of a multi-level predictive soundscape model to assess the soundscapes of public spaces during the COVID-19 lockdowns.\" The Journal of the Acoustical Society of America In 181st Meeting of the Acoustical Society of America doi: 10.1121/10.0008334 \n        \n        Published\n     \n2020\nRosa Ma Alsina-Pagès, Ferran Orga, Marc Freixes, Roger Mallol, Francesco Aletta, Andrew Mitchell, Jian Kang, and Maria Foraster. (2020) \"Urban environment soundscape evaluation: Milan case study of noise events perceptions by citizens.\" In INTER-NOISE and NOISE-CON Congress and Conference Proceedings\n        \n        Published\n    \n2019\nMercede Erfanian, Andrew Mitchell, and Jian Kang. (2019) \"The neurophysiology and physiology of soundscape: A review of the empirical literature.\" In The 6th European Conference on Psychology & the behavioral Sciences (ECP2019)\nJian Kang, Francesco Aletta, Tin Oberman, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Andrew Mitchell. (2019) \"Towards soundscape indices.\" Proceedings of the ICA 2019 and EAA Euroregio : 23rd International Congress on Acoustics In Proceedings of the 23rd International Congress on Acoustics doi: 10.18154/RWTH-CONV-239249 \n        \n        Published\n     \nAndrew Mitchell, Francesco Aletta, Tin Oberman, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Jian Kang. (2019) \"Making cities smarter with new soundscape indices.\" In 178th Meeting of the Acoustical Society of America doi: 10.1121/1.5136970 \n        \n        Published\n     \nAndrew Mitchell and Jian Kang. (2019) \"The spectral structure of acoustic time series can predict the perceptual assessment of urban soundscapes.\" In 178th Meeting of the Acoustical Society of America doi: 10.1121/1.5136681 \n        \n        Published\n     \nOther Publications\n2023\nEmmeline Brown, Ratneel Duo, Yuanbo Hou, Jasper Kirton-Wingate, Jinhua Liang, Alisa Sheinkman, Christopher Soelistyo, Hari Sood, Arin Wongprommoon, Kaiyue Xing, Wingyan Yip, and Andrew Mitchell. (2023) \"Data Study Group Final Report: Deep Learning Techniques for noise Annoyance detection (DeLTA).\"\n2022\nAndrew Mitchell, Mercede Erfanian, Christopher Soelitsyo, Tin Oberman, and Francesco Aletta. (2022) \"DeLTA (Deep Learning Techniques for noise Annoyance detection) Dataset.\" doi: 10.5281/ZENODO.7158056 \n        \n        Published\n     \nAndrew Mitchell. (2022) \"Predictive Modelling of Complex Urban Soundscapes: Enabling an engineering approach to soundscape design.\" doi: 10.13140/RG.2.2.15590.50245 \n        \n        Published"
  },
  {
    "objectID": "research/papers/how-to-analyse-jasa/index.html",
    "href": "research/papers/how-to-analyse-jasa/index.html",
    "title": "How to analyse and represent quantitative soundscape data",
    "section": "",
    "text": "Methods for collecting data on how people experience acoustic environments have been at the forefront of the debate in soundscape studies for the past 20 years. While the soundscape research field as we understand it today dates back to the late 1960s with the pioneering work of authors like M. Southworth (Southworth 1969), R.M. Schafer (Schafer 1977), and H. Westerkamp (Westerkamp 2002), the theme of data collection methods for soundscape assessment emerged more prominently only recently (Kang et al. 2016). There is a general consensus in the research community that standardised tools to gather and report individual responses on the perception of urban acoustic environments are indeed desirable, to provide comparable datasets and soundscape characterisations across different locations, times, and samples of people, as well as allowing for replicability studies, and offering inputs for modelling algorithms in soundscape prediction and design tasks. These were among the main drivers for the establishment of a Working Group at the International Organization for Standardization (ISO) back in 2008, which was named “Perceptual assessment of soundscape quality” (ISO/TC 43/SC 1/WG 54) that has so far published three documents within the ISO 12913 series on soundscape. Part 1 (ISO 12913-1:2014) is a full standard and provides a general framework and definitions of soundscape concepts (ISO 2014), while Part 2 (ISO/TS 12913-2:2018) and Part 3 (ISO/TS 12913-3:2019) are technical specifications and offer guidance on how data should be collected and analysed, accordingly (ISO 2018, 2019) (Part 4, on soundscape design interventions, is currently under development by the working group, also registered as a technical specifications document). Specifically, Part 3 presents the proposed methods for analysing and representing the data collected by the soundscape surveys. Since the development of these standards, the focus has shifted from understanding individual perception to characterising the collective perception of increasingly large groups.\nIn a recent editorial paper on Soundscape Assessment, Axelsson and colleagues observe that it is important to critically discuss current theories and models in soundscape studies and to examine their effectiveness, while also looking at how to integrate different methods and perspectives for the discipline to make further advancements (Axelsson, Guastavino, and Payne 2019). This work was mainly aimed at addressing the issue of meaningful comparability and representation of soundscape assessments. Part 2 of the ISO 12913 standard itself does not provide ultimate answers: the technical specifications recommend multiple methods, as consensus around a single protocol could not be reached. This diversity of methodological approaches should be interpreted as a fact that soundscape theory is still under development and, for this reason, the standardisation work should probably take a step back and focus on developing a reference method for comparability among soundscape studies, rather than a single protocol for soundscape data collection. Some attempts have indeed already been made in literature for the different methods proposed in the ISO/TS 12913-2:2018 Jo, Seo, and Jeon (2020). Neither the standard nor the general soundscape literature has settled on effective methods of analysing and representing the data that results from these protocols. Data visualisations are particularly important for understanding and communicating information as multifaceted as soundscape perception (Tufte 2001). Although it is unlikely that any single method will be sufficient, attempts should be made to both facilitate future advancements in this realm and to develop a first step approach that captures the inherent uncertainty in perception studies, since including uncertainty is considered one of the core principles of good data visualisation (Midway 2020).\nThis study thus aims to review the consequences of these methods for larger datasets and provide concrete examples for how soundscapes should be represented. In particular, we aim to strengthen the practices for characterising the soundscape of a location, as a collective perception by the users of the location. We also demonstrate how the progress of these tools from their initial scope (measuring and discussing the individual perception of a soundwalk participant) have not kept up with recent advances and requirements for larger-scale soundscape datasets. We question whether there are some issues related to the data collection instruments and data analysis methods as recommended and examine the results of the model framework and mathematical transformations laid out in the ISO technical specifications to guide the interpretation of the soundscape circumplex.\nTo examine these tools and the questions raised, we apply them to an existing large scale, real-world dataset of soundscape assessments collected according to the ISO methods. Finally, we propose a more holistic and advanced method of representing soundscapes as a probabilistic distribution of perceptions within the circumplex and provide a toolbox for others to use."
  },
  {
    "objectID": "research/papers/how-to-analyse-jasa/index.html#coordinate-transformation-into-the-two-primary-dimensions",
    "href": "research/papers/how-to-analyse-jasa/index.html#coordinate-transformation-into-the-two-primary-dimensions",
    "title": "How to analyse and represent quantitative soundscape data",
    "section": "Coordinate transformation into the two primary dimensions",
    "text": "Coordinate transformation into the two primary dimensions\nTo facilitate the analysis of the PA responses, the Likert scale responses are coded from 1 (Strongly disagree) to 5 (Strongly agree) as ordinal variables. In order to reduce the 8 PA values into a pair of coordinates which can be plotted on the Pleasant-Eventful axes, Part 3 of ISO 12913 (ISO 2019) provides a trigonometric transformation, based on the 45\\degree-relationship between the diagonal axes and the pleasant and eventful axes. This transformation projects the coded values from the individual PAs down onto the primary Pleasantness and Eventfulness dimensions then adds them together to form a single coordinate pair. In theory, this coordinate pair then encapsulates information from all 8 PA dimensions onto a more easily understandable and analysable two dimensions. The ISO coordinates are thus calculated by:\n\n\\begin{split}\n    ISO Pleasant = [(pleasant - annoying) + \\cos 45\\degree * (calm - chaotic) \\\\ + \\cos 45\\degree * (vibrant - monotonous)] * 1/(4+\\sqrt{32)}\n\\end{split}\n\\tag{1}\n\n\\begin{split}\n    ISO Eventful = [(eventful - uneventful) + \\cos 45\\degree * (chaotic - calm) \\\\ + \\cos 45\\degree * (vibrant - monotonous)] * 1/(4+\\sqrt{32)}\n\\end{split}\n\\tag{2}\nwhere the PAs are arranged around the circumplex as shown in Figure 1. The \\cos 45\\degree term operates to project the diagonal terms down onto the x and y axes, and the 1 / (4 + \\sqrt{32}) scales the resulting coordinates to the range (-1, 1). The result of this transformation is demonstrated in Figure 1. This treatment of the 8 PAs makes several assumptions and inferences about the relationships between the dimensions. As stated in the standard (ISO 2019, 5):\n\nAccording to the two-dimensional model, vibrant soundscapes are both pleasant and eventful, chaotic soundscapes are both eventful and unpleasant, monotonous soundscapes are both unpleasant and uneventful, and finally calm soundscapes are both uneventful and pleasant.\n\n\n\n\nFigure 1: Example of representations of two soundscape assessments. Left: Radar plot of two example perceptual attribute (PA) ratings on the Likert scales (1 to 5). Right: Scatter plot of the same assessments on the soundscape circumplex, transformed according to ISO 12913 Part 3."
  },
  {
    "objectID": "research/papers/how-to-analyse-jasa/index.html#summarising-the-soundscape-assessment-of-a-location",
    "href": "research/papers/how-to-analyse-jasa/index.html#summarising-the-soundscape-assessment-of-a-location",
    "title": "How to analyse and represent quantitative soundscape data",
    "section": "Summarising the soundscape assessment of a location",
    "text": "Summarising the soundscape assessment of a location\nWhile the assessment methods available are able to record the soundscape perception of a single individual, and that person’s perception is valid for themselves, it is not appropriate to then state that it is representative of the collective perception of that soundscape. In order to characterise the soundscape of a particular space or time, perceptual responses from multiple people must be collected and subsequently summarised or aggregated to describe the general soundscape of the location. The ISO guidelines stipulate a minimum of 20 participants for a soundwalk, with these broken up into sessions of no more than 5 participants at a time. Part 3 then provides the recommended methods for analysing this data.\nAnnex A.2 of ISO 12913 Part 3 provides the statistical measures to be used on the raw PA responses. The recommended measure of central tendency is the median, while the recommended measure of dispersion is the range. These are chosen as the data is ordinal by nature, however as will be demonstrated later, they have significant limitations. Although it is unclear, the implied intention is then that the median value of each PA is fed into Equation 1 and Equation 2 presented above to calculate the ISOPleasant and ISOEventful values, which can then be plotted in a two-dimensional scatter plot. Thus the standard suggests that 1) the projection method equations are not applied to individual responses and 2) only the median assessment of a location should be plotted."
  },
  {
    "objectID": "research/papers/how-to-analyse-jasa/index.html#limitations-of-the-iso",
    "href": "research/papers/how-to-analyse-jasa/index.html#limitations-of-the-iso",
    "title": "How to analyse and represent quantitative soundscape data",
    "section": "Limitations of the ISO",
    "text": "Limitations of the ISO\nHow these methods should be applied to represent the soundscape of a location has not been adequately discussed in previous literature, nor sufficiently in Part 3 of ISO 1293 itself. Indeed, in Section A.3, the technical specifications document state that (ISO 2019, 5):\n\nResults can be reported in a two-dimensional scatter plot with coordinates for the two dimensions ‘pleasantness’ and ‘eventfulness’. The coordinates for ‘pleasantness’ are plotted on the X-axis, and the coordinates for ‘eventfulness’ on the Y-axis. Every data point in the scatter plot represents one investigated site.\n\nHowever, it is not made clear whether this single point on the circumplex can be considered to be a realistic representation of the average perception of the acoustic environment. Effectively, there is no representation of dispersion in the soundscape assessment, nor a recommended use of the range that was calculated as part of the analysis recommend in Section A.2 of Part 3 of the ISO 12913. Absent a suggestion from the ISO 12913 for how the range should be used, we therefore apply this analysis to an existing real-world soundscape dataset to determine whether it provides a useful measure of dispersion. Here we use the data contained in the International Soundscape Database (ISD) (Mitchell, Oberman, Aletta, Erfanian, et al. 2021), which includes 1,300+ individual responses collected across 13 locations in London and Venice, according to the SSID Protocol, which is based on the ISO methods explored in this paper (Mitchell et al. 2020).\nFor any large enough sample for a site, the range will always be from 1 to 5, the maximum and minimum available Likert-scale values. We would expect that collecting more data would result in more information or better precision, however the range will always increase as the sample size increases. As an example, within the ISD data, of the 8 PAs collected at 13 locations (for a total of 104 scales), 88% have a range from 1 to 5 and with larger sample sizes at each location, this percentage would only have increased. Using range to analyse the dispersion provides very limited information for comparing the soundscape assessments of different locations, or of a location under different conditions.\nAlthough the range does not appear to be a useful measure of dispersion, the median does provide a useful measure and appropriately functions to describe the central tendency of the soundscape assessment of the sample. However, by stipulating that the median of each PA should be taken prior to applying the circumplex projection, the ISO procedure only allows for plotting a single scatter point in the circumplex for each location and does not allow for plotting individual responses on the circumplex. This limits the possibilities for visualising the general trends in individual perception across the soundscape. Finally, no example or recommendation for how the circumplex scatter plot should be presented is given in the standard.\nThe instruments described in the ISO 12913 Part 2 (ISO 2018) were originally designed primarily for the context of individual or small group assessments. In these scenarios, the focus is on assessing the particular soundscape perception of the person in question. Recent advances in the soundscape approach since the development of the standards have shifted some focus from individual soundscapes to characterising the overall soundscape of public spaces (Mitchell et al. 2020) and to making comparisons between different groups of people (Jeon et al. 2018). In this context, a consideration of the natural variation in people’s perception and the variation over time of a soundscape must be a core feature of how the soundscape is discussed. Reducing a public space which may have between tens and tens of thousands of people moving through it in a single day down to the mean (or median, or any other single metric) soundscape assessment often dismisses the reality of the space. Likewise, this overall soundscape of a public space cannot be determined through a ten person soundwalk, as there is no guarantee that the sample of people engaged in the soundwalk is representative of the users of the space (in fact it is likely they would not be)."
  },
  {
    "objectID": "research/papers/how-to-analyse-jasa/index.html#limitations-of-the-circumplex-and-quantitative-analysis",
    "href": "research/papers/how-to-analyse-jasa/index.html#limitations-of-the-circumplex-and-quantitative-analysis",
    "title": "How to analyse and represent quantitative soundscape data",
    "section": "Limitations of the circumplex and quantitative analysis",
    "text": "Limitations of the circumplex and quantitative analysis\nThe method presented here is a solution for representing the soundscape of a space, which requires considering the perception of many people, but it is important to note that this is only one (very important) goal of the soundscape approach. Psychological and sociological investigations of people’s relationship to their sound environment and the interactions between social contexts and individual perception are a crucial aspect of the field for which this approach would likely not be sufficient (Bild et al. 2018). Open-response questions, structured interviews, and mixed-methods studies can provide additional insight into how people experience their environment and should be considered alongside or preceding this focus on how a space is likely to be perceived on a larger scale.\nThese other approaches are not in opposition to the methods proposed here, but instead further expand our view. The circumplex is a limited view of soundscape perception (this is made obvious by the fact that it excludes the third component, familiarity, identified in Axelsson, Nilsson, and Berglund (2010)) but it is an exceptionally rich tool for dealing with the two primary aspects of soundscape perception which can readily expand the much more limited view provided by existing noise and annoyance assessment tools. Aspects of the psychological and sociological emphasis can also be integrated into a circumplex-focused approach, as demonstrated in Erfanian et al. (2021), where personal factors such as age, gender, and psychological well-being were analysed in terms of how they mediated the ISOPleasant and ISOEventful outcomes.\nThere has been some discussion regarding the interdependence of the PAs and the strict validity of the 90and 45 relationships between the attributes (Lionello et al. 2021). Further work has indicated that the scaling between the attributes may vary, but the underlying relationships hold. It is for this reason that we have taken the coordinate projection as the starting point of this critique. It should also be noted that the particular PA descriptors used in ISO 12913 are intended for outdoor environments and should not be directly applied to indoor spaces. However, a proposed set of descriptors for some indoor environments has been derived which further confirms the validity of the circumplex relationships (Torresin et al. 2020). The methods proposed here should be directly applicable to indoor spaces by using the comfort/content descriptors as well as to any other translations of soundscape descriptors into other languages (Aletta et al. 2020) as long as the dimensional relationships of the circumplex are maintained."
  },
  {
    "objectID": "research/papers/how-to-analyse-jasa/index.html#footnotes",
    "href": "research/papers/how-to-analyse-jasa/index.html#footnotes",
    "title": "How to analyse and represent quantitative soundscape data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe specifics of the bivariate kernel density estimation (Silverman 2018) are beyond the scope of this discussion and the most appropriate hyperparameters (e.g. estimation methods, smoothing factors) for this visualisation may need to be further explored. These parameters will likely depend on the specific dataset used.↩︎"
  },
  {
    "objectID": "posts/across-acoustics/index.html",
    "href": "posts/across-acoustics/index.html",
    "title": "Appearance on Across Acoustics",
    "section": "",
    "text": "I recently appeared on the official podcast of the Acoustical Society of America to talk about my paper which was published in JASA Express Letters last year.\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/quarto-website/index.html",
    "href": "posts/quarto-website/index.html",
    "title": "Quarto for an Academic Website",
    "section": "",
    "text": "I’ve never been good at keeping my website updated. I always go through two different phases of maintenance:\n\nRushing around creating a new website with bells and whistles using whatever the flavor of the month is\nNever updating an existing website\n\nI’m hoping to break out of this cycle, but am currently solidly within Phase 1.\n\nA highlight from my time in Phase 2 was when I forgot to update my DNS and I totally lost control of drewdimmery.com (don’t go there, it has a squatter). I think my website at that time was some Octopress monstrosity. There are a few reasons I think Quarto might help with my vicious circle.\n\nServing static HTML pages is about as easy as it gets\nVery little Quarto-specific syntax to recall (e.g. CLI commands or abstruse markup)\nLots of flexibility (Python / R) in how to generate that static content\nFull programmability means that generation can be based on arbitrary data structures of my choosing\n\nI previously used Hugo Academic for building my website, which was much better than just editing the content directly, but I never remembered the right way to generate a new publication definition (there was a CLI, but I never remembered the syntax). Each publication got its own file describing its details, and I found this quite clunky. I wanted something extremely lightweight: there isn’t much reason for my individual publications to get pages of their own, and I really don’t need a lot of information on each of them. I just want some basic information about each and a set of appropriate links to more details.\nThis post will detail how I’ve set up Quarto to accomplish this task. I’ve nearly completely separated the two main concerns around maintaining an academic website / CV, which to me are data on publications and software from the design elements of how to display them. It’s entirely possible that my particular issues are unique and this post won’t be useful to anyone else. Luckily, the marginal cost of words on the internet is essentially zero (and maybe the marginal value is, too)."
  },
  {
    "objectID": "posts/quarto-website/index.html#data",
    "href": "posts/quarto-website/index.html#data",
    "title": "Quarto for an Academic Website",
    "section": "Data",
    "text": "Data\nI put data about each publication in a basic YAML format:\n\n\nSee example data\n\nsoftblock:\n  title: Efficient Balanced Treatment Assignments for Experimentation\n  authors:\n    - David Arbour\n    - me\n    - Anup Rao\n  year: 2021\n  venue: AISTATS\n  preprint: https://arxiv.org/abs/2010.11332\n  published_url: https://proceedings.mlr.press/v130/arbour21a.html\n  github: https://github.com/ddimmery/softblock\n\nThis is basically like a simplified bibtex entry with more URLs so I can annotate where to find replication materials for a given paper, as well as distinguish between preprints (always freely accessible) versus published versions (not always open access). A convenience that I add in the markup here is referring to myself as me in the author list (which is an ordered list). This allows me to add in extra post-processing to highlight where I sit in the author list.\nSome additional things I considered adding but chose to ignore for a first version:\n\nAn abstract\nA suggested bibtex entry\n\nBoth of these would be easy to add, but I chose to start simpler. I don’t love YAML for entering long blocks of text, which both of these are."
  },
  {
    "objectID": "posts/quarto-website/index.html#formatting",
    "href": "posts/quarto-website/index.html#formatting",
    "title": "Quarto for an Academic Website",
    "section": "Formatting",
    "text": "Formatting\nSince I can write the generation logic for page in Python, this puts me on comfortable ground to hack something together. To knit the above publication data into HTML, I just literally bind together the programmatically generated raw HTML and print it onto the page.\nI do a couple additional useful things in this process: - Separate out working papers or non-archival papers from published work (I make this distinction based on whether I include a published_url field or not). - Order and categorize papers by year - Provide nice Bootstrappy buttons for external links (e.g. to Preprints / Code / etc)\n\n\nSee research.qmd fragment\n\nimport yaml\nfrom IPython.display import display, Markdown, HTML\n\ndef readable_list(_s):\n  if len(_s) &lt; 3:\n    return ' and '.join(map(str, _s))\n  *a, b = _s\n  return f\"{', '.join(map(str, a))}, and {b}\"\n\ndef button(url, str, icon):\n    icon_base = icon[:2]\n    return f\"\"\"&lt;a class=\"btn btn-outline-dark btn-sm\", href=\"{url}\" target=\"_blank\" rel=\"noopener noreferrer\"&gt;\n        &lt;i class=\"{icon_base} {icon}\" role='img' aria-label='{str}'&gt;&lt;/i&gt;\n        {str}\n    &lt;/a&gt;\"\"\"\n\nyaml_data = yaml.safe_load(open(\"papers.yaml\"))\npub_strs = {\"pubs\": {}, \"wps\": {}}\nfor _, data in yaml_data.items():\n    title_str = data[\"title\"]\n    authors = data.get(\"authors\", [\"me\"])\n    authors = [\n        aut if aut != \"me\" else \"&lt;strong&gt;Drew Dimmery&lt;/strong&gt;\" for aut in authors\n    ]\n    author_str = readable_list(authors)\n    year_str = data[\"year\"]\n\n    buttons = []\n    preprint = data.get(\"preprint\")\n    if preprint is not None:\n        buttons.append(button(preprint, \"Preprint\", \"bi-file-earmark-pdf\"))\n\n    github = data.get(\"github\")\n    if github is not None:\n        buttons.append(button(github, \"Github\", \"bi-github\"))\n\n    pub_url = data.get(\"published_url\")\n    venue = data.get(\"venue\")\n    working_paper = pub_url is None\n    \n    pub_str = f'{author_str}. ({year_str}) \"{title_str}.\"'\n\n    if venue is not None:\n        pub_str += f\" &lt;em&gt;{venue}&lt;/em&gt;\"\n\n    if working_paper:\n        if year_str not in pub_strs[\"wps\"]:\n            pub_strs[\"wps\"][year_str] = []\n        pub_strs[\"wps\"][year_str].append(\n            \"&lt;li class='list-group-item'&gt;\" + pub_str + \"&lt;br&gt;\" + \" \".join(buttons) + \"&lt;/li&gt;\"\n        )\n    else:\n        if year_str not in pub_strs[\"pubs\"]:\n            pub_strs[\"pubs\"][year_str] = []\n        buttons.append(button(pub_url, \"Published\", \"ai-archive\"))\n        pub_strs[\"pubs\"][year_str].append(\n            \"&lt;li class='list-group-item'&gt;\" + pub_str + \"&lt;br&gt;\" + \" \".join(buttons) + \"&lt;/li&gt;\"\n        )\n\nI then print this out using the display functions from the IPython module and using the asis chunk option:\n\n\nSee research.qmd fragment\n\nfor year in sorted(pub_strs[\"pubs\"].keys(), reverse=True):\n    display(Markdown(f\"### {year}\" + \"{#\" + f\"published-{year}\" + \"}\"))\n    display(HTML(\n        \"&lt;ul class='list-group list-group-flush'&gt;\" + '\\n'.join(pub_strs[\"pubs\"][year]) + \"&lt;/ul&gt;\"\n    ))\n\nThe full code is on GitHub.\nIt’s worth noting that to get the years to show up in the Table of Contents its necessary to be careful exactly how the content is stuck onto the page. If you don’t use the asis chunk option, you can still get all the right content to show up, but it won’t necessarily appear in the ToC. I also found it necessary to include section-divs: false in the header, or else the output would get wrapped in additional div tags which made it harder to get the right classes in the right divs. There are probably more elegant ways to do all of this.\nI use the same basic setup to populate the Software page, albeit with simpler logic.\n\nAdditions\nI debated adding an abstract that expands out on click (like the code folding above in this post). This would actually be more or less trivial to add using a &lt;details&gt; HTML tag if I wanted to provide the data in the YAML. I’m ignoring this for now because I want to minimize data entry for my future self (and it’s anyway just a click away at the Preprint link)."
  },
  {
    "objectID": "posts/pandemic-sensory-archive/index.html",
    "href": "posts/pandemic-sensory-archive/index.html",
    "title": "Contributing to the Pandemic Sensory Archive",
    "section": "",
    "text": "In 2021, I was interviewed by Dr William Tullett of Anglia Ruskin University in Cambridge. Dr Tullett created the Pandemic Sensory Archive “to explore bodies and senses through a digital platform, in light of experiences of the COVID-19 pandemic”.\nDr Tullett reached out in relation to my then-recent work investigating how urban soundscapes changed as a result of the COVID-19 lockdowns. I spoke with him about both how the physical sound environment changed and how people’s perception was impacted.\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am currently a Senior Research Fellow at the Institute for Environmental Design & Engineering at University College London.\n\nResearch Interests\n\nSoundscape Engineering\nMachine Learning\nData Science\nEnvironmental Acoustics\nPsychoacoustics\n\n\n\nEducation\n\n\nUniversity College London\nPhD in Environmental Acoustics and Machine Learning\nSupervisor: Prof Jian Kang\nCo-Superverisor: Dr. Phil Symonds\n\n\nLondon, UK\nGranted September 2022\n\n\n\nDissertation: Predictive Modelling of Complex Urban Soundscapes: Enabling an Engineering Approach to Soundscape Design\n\n\n\nCardiff University\nBSc. (Hons) in Physics & Music\n\n\nCardiff, Wales, UK\nGranted August 2015\n\n\n\nDissertation: The Physics of the Trombone Mouthpiece\n\n\n\nExperience\n\n\nUniversity College London\n\n\nOctober 2023 - present\n\n\nSenior Research Fellow in Soundscape Modelling\n\nSupervisor: Prof Jian Kang\n\n\n\nUniversity College London, Institute for Environmental Design & Engineering\n\n\nJune 2022 - Oct 2023\n\n\nResearch Fellow in Soundscape Modelling\n\nSupervisor: Prof Jian Kang\n\n\n\nHoare Lea, LLC, London, UK\n\n\nJune 2019 - March 2021\n\n\nAcoustics Engineer / Soundscape Consultant\n\nAcademic/industry collaboration to design an IoT-based soundscape assessment tool\n\n\n\nNewson Brown Acoustics, Santa Monica, CA\n\n\nJune 2016 - September 2018\n\n\nAcoustical Consultant\n\nArchitectural acoustics, room acoustics modelling, & noise control\n\n\n\nHayes McKenzie Partnership, Machynlleth, Wales\n\n\nJuly 2015 - April 2016\n\n\nJunior Acoustics Consultant\n\n\nBusch Gardens Williamsburg, Williamsburg, VA\n\n\nSummer 2012\n\n\nBass Trombonist\n\n\nTeaching\n\nFacebook\n\n\nInternal datacamp class on designing and analyzing experiments\n\n\n2017-2019\n\n\n\n\nNYU Undergraduate\n\n\nTA for Power and Politics in America (under Jonathan Nagler)\n\n\nFall 2014\n\n\n\n\nTA for Games, Strategy and Politics (under Steven Brams)\n\n\nFall 2013\n\n\n\n\nNYU Graduate\n\n\nTA for Quantitative Methods II (under Nathaniel Beck)\n\n\nSpring 2015\n\n\n\n\nTA for Quantitative Methods II (under Cyrus Samii)\n\n\nSpring 2014\n\n\n\n\nHigh Performance Computing Talk for NYU Datalab\n\n\nFebruary 2014\n\n\n\n\nIntroduction to R for NYU Datalab\n\n\nJanuary 2013"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "I am currently a Senior Research Fellow at the Institute for Environmental Design & Engineering at University College London."
  },
  {
    "objectID": "cv.html#journal-papers",
    "href": "cv.html#journal-papers",
    "title": "Curriculum Vitae",
    "section": "Journal Papers",
    "text": "Journal Papers\n\n2024\nYuanbo Hou, Bo Kang, Andrew Mitchell, Wenwu Wang, Jian Kang, and Dick Botteldooren. (2024) \"Cooperative Scene-Event Modelling for Acoustic Scene Classification.\" IEEE/ACM Transactions on Audio, Speech, and Language Processing doi: 10.1109/TASLP.2023.3323135 \n        \n        Published\n     \n\n\n2023\nFrancesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, and Jian Kang. (2023) \"Soundscape experience of public spaces in different world regions: A comparison between the European and Chinese contexts via a large-scale on-site surveya).\" The Journal of the Acoustical Society of America doi: 10.1121/10.0020842 \n        \n        Published\n     \nYuanbo Hou, Qiaoqiao Ren, Huizhong Zhang, Andrew Mitchell, Francesco Aletta, Jian Kang, and Dick Botteldooren. (2023) \"AI-based soundscape analysis: Jointly identifying sound sources and predicting annoyancea).\" The Journal of the Acoustical Society of America doi: 10.1121/10.0022408 \n        \n        Published\n     \nJian Kang, Francesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, Huan Tong, Simone Torresin, Chunyang Xu, Tingting Yang, and Xiaochao Chen. (2023) \"Supportive soundscapes are crucial for sustainable environments.\" Science of The Total Environment doi: 10.1016/j.scitotenv.2022.158868 \n        \n        Published\n     \nNikolaos M. Papadakis, Francesco Aletta, Jian Kang, Tin Oberman, Andrew Mitchell, Ioanna Aroni, and Georgios E. Stavroulakis. (2023) \"City, town, village: Potential differences in residents soundscape perception using ISO/TS 12913-2:2018.\" Applied Acoustics doi: 10.1016/j.apacoust.2023.109659 \n        \n        Published\n     \nJerónimo Vida, José Antonio Almagro, Rafael García-Quesada, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Jian Kang. (2023) \"Soundscape attributes in Spanish: A comparison with the English version of the protocol proposed in Method A of the ISO/TS 12913–2.\" Applied Acoustics doi: 10.1016/j.apacoust.2023.109516 \n        \n        Published\n     \n\n\n2022\nAndrew Mitchell, Mercede Erfanian, Christopher Soelistyo, Tin Oberman, Jian Kang, Robert Aldridge, Jing-Hao Xue, and Francesco Aletta. (2022) \"Effects of Soundscape Complexity on Urban Noise Annoyance Ratings: A Large-Scale Online Listening Experiment.\" International Journal of Environmental Research and Public Health doi: 10.3390/ijerph192214872 \n        \n        Published\n     \nAndrew Mitchell, Francesco Aletta, and Jian Kang. (2022) \"How to analyse and represent quantitative soundscape data.\" JASA Express Letters doi: 10.1121/10.0009794 \n        \n        Published\n     \n\n\n2021\nMercede Erfanian, Andrew Mitchell, Francesco Aletta, and Jian Kang. (2021) \"Psychological well-being and demographic factors can mediate soundscape pleasantness and eventfulness: A large sample study.\" Journal of Environmental Psychology doi: 10.1016/j.jenvp.2021.101660 \n        \n        Published\n     \nMatteo Lionello, Francesco Aletta, Andrew Mitchell, and Jian Kang. (2021) \"Introducing a Method for Intervals Correction on Multiple Likert Scales: A Case Study on an Urban Soundscape Data Collection Instrument.\" Frontiers in Psychology doi: 10.3389/fpsyg.2020.602831 \n        \n        Published\n     \nAndrew Mitchell, Tin Oberman, Francesco Aletta, Magdalena Kachlicka, Matteo Lionello, Mercede Erfanian, and Jian Kang. (2021) \"Investigating urban soundscapes of the COVID-19 lockdown: A predictive soundscape modeling approach.\" The Journal of the Acoustical Society of America doi: 10.1121/10.0008928 \n        \n        Published\n     \nFerran Orga, Andrew Mitchell, Marc Freixes, Francesco Aletta, Rosa Ma Alsina-Pagès, and Maria Foraster. (2021) \"Multilevel Annoyance Modelling of Short Environmental Sound Recordings.\" Sustainability doi: 10.3390/su13115779 \n        \n        Published\n     \nHuan Tong, Francesco Aletta, Andrew Mitchell, Tin Oberman, and Jian Kang. (2021) \"Increases in noise complaints during the COVID-19 lockdown in Spring 2020: A case study in Greater London, UK.\" Science of The Total Environment doi: 10.1016/j.scitotenv.2021.147213 \n        \n        Published\n     \nJerónimo Vida Manzano, José Antonio Almagro Pastor, Rafael García Quesada, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Jian Kang. (2021) \"The \"sound of silence\" in Granada during the COVID-19 lockdown.\" Noise Mapping doi: 10.1515/noise-2021-0002 \n        \n        Published\n     \n\n\n2020\nFrancesco Aletta, Tin Oberman, Andrew Mitchell, Huan Tong, and Jian Kang. (2020) \"Assessing the changing urban sound environment during the COVID-19 lockdown period using short-term acoustic measurements.\" Noise Mapping doi: 10.1515/noise-2020-0011 \n        \n        Published\n     \nAndrew Mitchell, Tin Oberman, Francesco Aletta, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Jian Kang. (2020) \"The Soundscape Indices (SSID) Protocol: A Method for Urban Soundscape Surveys–Questionnaires with Acoustical and Contextual Information.\" Applied Sciences doi: 10.3390/app10072397 \n        \n        Published\n     \n\n\n2019\nFrancesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, Matteo Lionello, Magdalena Kachlicka, and Jian Kang. (2019) \"Associations between soundscape experience and self-reported wellbeing in open public urban spaces: A field study.\" The Lancet doi: 10.1016/s0140-6736(19)32814-4 \n        \n        Published\n     \nMercede Erfanian, Andrew J. Mitchell, Jian Kang, and Francesco Aletta. (2019) \"The Psychophysiological Implications of Soundscape: A Systematic Review of Empirical Literature and a Research Agenda.\" International Journal of Environmental Research and Public Health doi: 10.3390/ijerph16193533 \n        \n        Published"
  },
  {
    "objectID": "cv.html#conference-papers",
    "href": "cv.html#conference-papers",
    "title": "Curriculum Vitae",
    "section": "Conference Papers",
    "text": "Conference Papers\n\n2023\nJack Harvie-Clark, Rebecca Romeo Pitone, Luis Pereira, and Andrew Mitchell. (2023) \"Integrating acoustics engineering and soundscape design for an urban park: a case study.\" In Forum Acusticum 2023\n        \n        Published\n    \nYuanbo Hou, Andrew Mitchell, Qiaoqiao Ren, Francesco Aletta, Jian Kang, and Dick Botteldooren. (2023) \"Exploring annoyance in a soundscape context by joint prediction of sound source and annoyance.\" In Forum Acusticum 2023\nYuanbo Hou, Siyang Song, Cheg Luo, Andrew Mitchell, Qiaoqiao Ren, Jian Kang, Wenwu Want, and Dick Botteldooren. (2023) \"Joint prediction of audio event and annoyance rating in an urban soundscape by hierarchical graph representation learning.\" In 24th INTERSPEECH Conference\nJian Kang, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Mercede Erfanian. (2023) \"On the development of Soundscape Indices (SSID).\" In The 29th International Congress on Sound and Vibration\nJian Kang, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Mercede Erfanian. (2023) \"Subjective evaluation of environmental sounds in context - Towards Soundscape Indices (SSID).\" In Forum Acusticum 2023\nAndrew Mitchell, Francesco Aletta, Tin Oberman, Mercede Erfanian, and Jian Kang. (2023) \"A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraints, and applications.\" In INTER-NOISE 2023 Conference\nAndrew Mitchell, Emmeline Brown, Ratneel Deo, Yuanbo Hou, Jasper Kirton-Wingate, Jinhua Liang, Alisa Sheinkman, Christopher Soelistyo, Hari Sood, Arin Wongprommoon, Kaiyue Xing, Wingyan Yip, and Francesco Aletta. (2023) \"Deep learning techniques for noise annoyance detection: Results from an intensive workshop at the Alan Turing Institute.\" The Journal of the Acoustical Society of America doi: 10.1121/10.0018787 \n        \n        Published\n     \nAndrew Mitchell, Francesco Aletta, Tin Oberman, and Jian Kang. (2023) \"How do we define soundscape?.\" In Forum Acusticum 2023\nAndrew Mitchell. (2023) \"Soundscapy: A python package for soundscape assessment and analysis.\" In INTER-NOISE 2023 Conference\n\n\n2022\nCleopatra Christina Moshona, Francesco Aletta, Helen Henze, Xiaochao Chen, Andrew Mitchell, Tin Oberman, Huan Tong, André Fiebig, Jian Kang, and Brigitte Schulte-Fortkamp. (2022) \"What is a soundscape intervention? Exploring definitions and identifi-cation criteria and a platform to gather real-world examples.\" In 51st International Congress and Exposition on Noise Control Engineering (INTER-NOISE 2022)\n        \n        Published\n    \n\n\n2021\nAndrew Mitchell, Tin Oberman, Francesco Aletta, and Jian Kang. (2021) \"Development of a multi-level predictive soundscape model to assess the soundscapes of public spaces during the COVID-19 lockdowns.\" The Journal of the Acoustical Society of America In 181st Meeting of the Acoustical Society of America doi: 10.1121/10.0008334 \n        \n        Published\n     \n\n\n2020\nRosa Ma Alsina-Pagès, Ferran Orga, Marc Freixes, Roger Mallol, Francesco Aletta, Andrew Mitchell, Jian Kang, and Maria Foraster. (2020) \"Urban environment soundscape evaluation: Milan case study of noise events perceptions by citizens.\" In INTER-NOISE and NOISE-CON Congress and Conference Proceedings\n        \n        Published\n    \n\n\n2019\nMercede Erfanian, Andrew Mitchell, and Jian Kang. (2019) \"The neurophysiology and physiology of soundscape: A review of the empirical literature.\" In The 6th European Conference on Psychology & the behavioral Sciences (ECP2019)\nJian Kang, Francesco Aletta, Tin Oberman, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Andrew Mitchell. (2019) \"Towards soundscape indices.\" Proceedings of the ICA 2019 and EAA Euroregio : 23rd International Congress on Acoustics In Proceedings of the 23rd International Congress on Acoustics doi: 10.18154/RWTH-CONV-239249 \n        \n        Published\n     \nAndrew Mitchell, Francesco Aletta, Tin Oberman, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Jian Kang. (2019) \"Making cities smarter with new soundscape indices.\" In 178th Meeting of the Acoustical Society of America doi: 10.1121/1.5136970 \n        \n        Published\n     \nAndrew Mitchell and Jian Kang. (2019) \"The spectral structure of acoustic time series can predict the perceptual assessment of urban soundscapes.\" In 178th Meeting of the Acoustical Society of America doi: 10.1121/1.5136681 \n        \n        Published"
  },
  {
    "objectID": "cv.html#other-publications",
    "href": "cv.html#other-publications",
    "title": "Curriculum Vitae",
    "section": "Other Publications",
    "text": "Other Publications\n\n2023\nEmmeline Brown, Ratneel Duo, Yuanbo Hou, Jasper Kirton-Wingate, Jinhua Liang, Alisa Sheinkman, Christopher Soelistyo, Hari Sood, Arin Wongprommoon, Kaiyue Xing, Wingyan Yip, and Andrew Mitchell. (2023) \"Data Study Group Final Report: Deep Learning Techniques for noise Annoyance detection (DeLTA).\"\n\n\n2022\nAndrew Mitchell, Mercede Erfanian, Christopher Soelitsyo, Tin Oberman, and Francesco Aletta. (2022) \"DeLTA (Deep Learning Techniques for noise Annoyance detection) Dataset.\" doi: 10.5281/ZENODO.7158056 \n        \n        Published\n     \nAndrew Mitchell. (2022) \"Predictive Modelling of Complex Urban Soundscapes: Enabling an engineering approach to soundscape design.\" doi: 10.13140/RG.2.2.15590.50245 \n        \n        Published"
  }
]