[
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "circumplex\n\ncircumplex is a Python package for analyzing and visualizing circumplex data. It provides a set of tools for analyzing and visualizing circumplex data, following the Structural Summary Method. This project is a Python implementation based on the R circumplex package. Our goal is to provide a similar functionality and experience for Python users.\n\n        \n        Website\n     \n        \n        Github\n     \n        \n        Package\n    \nsoundscapy\n\nsoundscapy is a Python package for the analysis of soundscapes.\nThis package was designed to (1) load and process soundscape assessment data, (2) visualise the data, and (3) enable psychoacoustic analysis of soundscape recordings.\n\n        \n        Website\n     \n        \n        Github\n     \n        \n        Package"
  },
  {
    "objectID": "posts/2020-04-09_book-diary-3/index.html",
    "href": "posts/2020-04-09_book-diary-3/index.html",
    "title": "Book Diary 3 - Foundation",
    "section": "",
    "text": "I’ve been on a bit of a classic science fiction trend for the last six months or so, only broken up by some classic Americana apocalyptica with It Can’t Happen Here by Sinclair Lewis (I’ll get to its write up at some point!). Foundation is actually the first Asimov book I remember reading, and it is fantastic (it should be, it won the Hugo award for Best All-time Series)!\n\nMade up of five interrelated short stories, Foundation tells the story of a man named Hari Seldon, who invented a new field of science call Psycho-history. The primary conceit of psycho-history is that, using mathematics, and the principles of statistical mechanics of large interacting systems, Seldon can predict the future of human societies. Inspired by concepts from physics, wherein the behaviour of individual particles cannot be predicted but by looking on a macro-enough scale, we can make probabilistic statements about the behaviour of large systems of particles, Asimov has applied these same principles to the prediction of human behaviour.\nRepeated over and over again is Seldon’s mantra that single humans both cannot be predicted and cannot change the course of the system, instead the human society, as a system, is driven by its complex internal interactions, toward a series of probabilities. By solving these equations and modelling these interactions, Seldon predicts that the galactic Empire in which he lives will soon collapse. Because of the principles of his psycho-history, he knows he can do nothing to stop this, but he can help to speed of the process of recovery. Without his intervention, he predicts it would take 30,000 for the Empire to recover from barbarism, but if he can find a way to preserve some of the existing scientific knowledge, this could be reduced to 1,000 years. To do this, he creates the eponymous Foundation based on two planets at opposite ends of the galaxy to create an Encyclopedia to preserve science. What follows are the stories of the Foundation following the collapse of the Empire and the inevitable successes of Seldon’s predictions and eventual mistakes.\n\nI think this story, and the concept of psychohistory particular intrigue me now because of the nature of my research. I and our research group are essentially trying to build statistical models of human perception. Like Seldon, we generally accept that it is impossible to predict the perception of a single person, but once a large enough scale is considered, statistical probabilities take over. Also like Seldon, we believe a key point to be that the subjects should not be aware of the study, lest they adjust their behaviour (although we haven’t solved this issue).\nAs we move further and further into the Algorithm age, with more complex system models which consider increasingly complex interacting factors, I think psychohistory will be on many researcher’s minds. Not as an aspiration, since I don’t think any serious scientist would buy that, but as potential source of learning. Science fiction has always allowed thinkers and scientists to view their work in new ways, and to consider the consequences of the advances they may make.\nI hope we can all be inspired and cautioned by great thinkers such as Isaac Asimov.\n\nI’ve also finished Foundation and Empire, the sequel, and I’m currently working my way through Prelude to Foundation, which I’m very excited about as it goes more in depth about the development of psychohistory.\nDuring my science fiction stint I also read the Dune series by Frank Herbert, so hopefully I’ll write that one up soon too.\nFor further ‘reading’ on the age of algorithms:\n\nSleepwalkers podcast\nHello World: How to Be Human in the Age of the Machine by Hannah Fry\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/across-acoustics/index.html",
    "href": "posts/across-acoustics/index.html",
    "title": "Appearance on Across Acoustics",
    "section": "",
    "text": "I recently appeared on the official podcast of the Acoustical Society of America to talk about my paper which was published in JASA Express Letters last year.\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/visa-process/index.html",
    "href": "posts/visa-process/index.html",
    "title": "Navigating the UK Graduate Visa Process: A PhD Graduate’s Experience",
    "section": "",
    "text": "I recently finished my PhD (yay!) and went through the process of applying for a UK Graduate Visa. Although I had a job offer lined up, I chose the Graduate Visa route instead of a standard Work Visa. In this blog post, I’ll explain my motivations for this decision and give an overview of the process.\nThe UK Graduate Visa is a type of visa that allows international students who have completed a degree programme in the UK to stay in the country for a longer period after graduation. The visa provides the opportunity to work and settle in the UK. When I completed my Bachelor’s at Cardiff University in 2015, there were limited options to remain in the country and limited benefits for having graduated from a UK university.\nThankfully this has changed somewhat with the introduction of the Graduate Visa.\nAt the time, the best option was the standard Tier 2 Skilled Worker visa. By applying for this visa from a student visa, my employer and I were able to bypass some standard work checks and I was exempt from salary requirements. However, when I was granted this visa in 2015, it was only valid for a year. When I was offered a new job with a different company, I was required to apply for a new work visa, this time subject to all the requirements.\nThis became a problem when the new job did not meet the increased salary requirements and my visa application was denied. Despite having lived in the UK for four years, earned a BSc in Physics & Music, and being actively recruited for the job, I was forced to leave the country and return to the US.\nWhen I completed my PhD and was offered a Research Fellowship at UCL, I had to decide between applying for a Skilled Worker visa or a Graduate visa. Given my previous experience with work visas, I chose the Graduate visa. Unlike the Skilled Worker visa, the Graduate visa allows PhD graduates to remain in the UK with minimal restrictions for three years, without having to reapply each time they take on a new contract or change jobs.\nHowever, there were some challenges I faced when applying for the Graduate visa. Firstly, I had to pay for the visa myself, as my prospective employer would not cover the cost for the Graduate visa since I was no longer guaranteed to work for them. Secondly, the timeline for applying for the visa was difficult; you cannot apply for the visa until you have completed everything and been awarded your degree - this means passing the viva, submitting corrections, and having those corrections approved by your examiners. From thesis submission to completion can take anywhere from 3 months to a year and a half. And this is all assuming you submit on time!\nDespite these challenges, my experience with the Graduate visa application was relatively smooth, and it was a more straightforward process compared to the Student visa or the Work visa. Although there was still some stress and uncertainty, I didn’t encounter any major issues and I was able to successfully obtain the visa."
  },
  {
    "objectID": "posts/visa-process/index.html#my-graduate-visa-timeline",
    "href": "posts/visa-process/index.html#my-graduate-visa-timeline",
    "title": "Navigating the UK Graduate Visa Process: A PhD Graduate’s Experience",
    "section": "My Graduate Visa timeline",
    "text": "My Graduate Visa timeline\n\n\n\n\n\n\nNote\n\n\n\nSome parts of this process may be specific to UCL, however the general outline should be universal. The fact that UCL lists your official completion date as the 28th of whatever month you fulfilled all of the requirements is probably specific to UCL, but there may be similar policies at other unis. I think it’s important to be aware of this sort of thing (which no one ever tells you about) especially if you’re working to potentially tight timelines.\n\n\nTo help give a concrete example for people of what this timeline looks like, I’ve laid out the exact dates for each step of my process. My Student Visa was set to expire in January of the next year, so I planned out the timeline preparing for lots of delays and issues to make sure my right to stay and work wouldn’t be in jeopardy.\n\n[June 06] - Thesis submission\n[Sept 08] - Viva\n[Sept 09] - Receive report and corrections from examiners\n[Sept 26] - Submit my corrections to examiners\n[Sept 30] - Examiners confirm their acceptance via email to me and formally inform UCL. (I had very responsive examiners and minimal corrections so this was quite fast)\n[Sept 30] - UCL sends email confirming they received the notification from examiners and instructed my to upload an electronic copy of the thesis.\n[Oct 03] - UCL sends confirmation of results email. This confirms all of the details of my degree: Name, programme, start date, end date, etc. Importantly, the official date of the award is the 28th of the month you fulfill all of the requirements (i.e. upload the electronic copy). For me, even though I uploaded on the 30th, they back dated it to the 28th of September. If I had finished everything on the 1st October, my official award date would have been 28th October.\n\n\n\n\n\n\n\nWarning\n\n\n\nVery important note: you cannot submit your visa application until the University informs the Home Office you have completed your degree. This is not the same as them sending your certificate to you. This is a separate process and should be automatically done directly from the University to the Home Office.\n\n\n\n[Oct 19] - Confirmation that UCL has informed the Home Office about my degree. Now I can submit the visa application. I think if my official date had been delayed to October 28th, I wouldn’t have been able to submit my visa application until after that date.\n[Oct 19] - Submit visa application and pay application fees and immigration health surcharge.\n[Nov 22] - Visa granted.\n\nIf you were fully funded (100% tuition and stipend) during your PhD, you will need to provide evidence from your funder that they consent to your Graduate Visa application. The reason for this requirement is unclear, but it is important to note. If you were not fully funded, you may not need to provide this consent, but it is still a good idea to be prepared in case it is required. To ease my worries, my supervisor, who was the principal investigator on my funding grant, and I drafted a letter addressing this issue. Although the Home Office did not mention it, it is always better to be safe than sorry.\nThis information is intended to give you an idea of what the application process looks like. Please note that the experience may vary from person to person. For example, my submission, viva, and correction process was quick and straightforward, which may not be the case for everyone.\nIn conclusion, the UK Graduate Visa provides an attractive option for international PhD graduates looking to stay in the UK and further their careers. While there may be some challenges in the application process, especially for those who were fully funded during their PhD studies, the benefits of not having to reapply for a work visa every time you change jobs and the freedom to change careers make it a worthwhile option to consider. Overall, my experience with the Graduate Visa application was positive and I hope this article provides some helpful insight for those who may be considering it in the future."
  },
  {
    "objectID": "posts/2020-06-19-protocol-paper/index.html",
    "href": "posts/2020-06-19-protocol-paper/index.html",
    "title": "First paper published! SSID Protocol",
    "section": "",
    "text": "First paper published! SSID Protocol\n\nFind the full paper at the MDPI Applied Sciences Page - DOI: 10.3390/app10072397\n\nFor the past year, a huge portion of my PhD work has been focussed on data collection. Our goal in the SSID data collection is to gather a massive database of soundscape questionnaire surveys combined with objective acoustical and environmental data. Given the complexity of all of the different data sources, the protocol for correctly carrying out and organising the surveys is pretty involved.\nTo formalise it and make it available to all the other soundscape researchers out there, we have published our method as a standalone protocol paper in Applied Sciences.\nIn general, the protocol involves going out to an urban public space, setting up environmental and acoustic monitoring equipment, then stopping people as they pass through the space to get them to fill out a survey about how they perceive the sound environment. This data all then gets gathered up, collated and databased, and analysed as part of our ongoing soundscape research.\nThe whole timeline of this protocol is shown in this figure:\n\n\n\nFigure 1: Timeline of the on site soundscape protocol. RegentsParkJapan (RPJ) is used as an example. Abbreviations as defined in Table 3-QUE: Questionnaires; VID: 360 video; PIC: Site pictures; BIN: Binaural Recording; AMB: Ambisonic recording; SLM: Sound Level Meter (acoustical factors); ENV: Environmental factors\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/pandemic-sensory-archive/index.html",
    "href": "posts/pandemic-sensory-archive/index.html",
    "title": "Contributing to the Pandemic Sensory Archive",
    "section": "",
    "text": "In 2021, I was interviewed by Dr William Tullett of Anglia Ruskin University in Cambridge. Dr Tullett created the Pandemic Sensory Archive “to explore bodies and senses through a digital platform, in light of experiences of the COVID-19 pandemic”.\nDr Tullett reached out in relation to my then-recent work investigating how urban soundscapes changed as a result of the COVID-19 lockdowns. I spoke with him about both how the physical sound environment changed and how people’s perception was impacted.\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am currently a Senior Research Fellow at the Institute for Environmental Design & Engineering at University College London.\n\nResearch Interests\n\nSoundscape Engineering\nMachine Learning\nData Science\nEnvironmental Acoustics\nPsychoacoustics\n\n\n\nEducation\n\n\nUniversity College London\nPhD in Environmental Acoustics and Machine Learning\nSupervisor: Prof Jian Kang\nCo-Superverisor: Dr. Phil Symonds\n\n\nLondon, UK\nGranted September 2022\n\n\n\nDissertation: Predictive Modelling of Complex Urban Soundscapes: Enabling an Engineering Approach to Soundscape Design\n\n\n\nCardiff University\nBSc. (Hons) in Physics & Music\n\n\nCardiff, Wales, UK\nGranted August 2015\n\n\n\nDissertation: The Physics of the Trombone Mouthpiece\n\n\n\nExperience\n\n\nUniversity College London\n\n\nOctober 2023 - present\n\n\nSenior Research Fellow in Soundscape Modelling\n\nSupervisor: Prof Jian Kang\n\n\n\nUniversity College London, Institute for Environmental Design & Engineering\n\n\nJune 2022 - Oct 2023\n\n\nResearch Fellow in Soundscape Modelling\n\nSupervisor: Prof Jian Kang\n\n\n\nHoare Lea, LLC, London, UK\n\n\nJune 2019 - March 2021\n\n\nAcoustics Engineer / Soundscape Consultant\n\nAcademic/industry collaboration to design an IoT-based soundscape assessment tool\n\n\n\nNewson Brown Acoustics, Santa Monica, CA\n\n\nJune 2016 - September 2018\n\n\nAcoustical Consultant\n\nArchitectural acoustics, room acoustics modelling, & noise control\n\n\n\nHayes McKenzie Partnership, Machynlleth, Wales\n\n\nJuly 2015 - April 2016\n\n\nJunior Acoustics Consultant\n\n\nBusch Gardens Williamsburg, Williamsburg, VA\n\n\nSummer 2012\n\n\nBass Trombonist"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Andrew Mitchell",
    "section": "",
    "text": "I am currently a Senior Research Fellow in urban soundscape modelling at University College London (UCL). My research interests include soundscape analysis and visualisation, machine learning, and human perception of complex sounds.\nI was awarded two PhD- and one Post-doctoral Enrichment Awards from The Alan Turing Institute and spent a month in early 2022 as a visiting research fellow at Stockholm University. My ongoing projects include the Soundscape Indices (SSID) Horizon 2020 project, Soundscapy, Deep Learning Techniques for noise Annoyance detection (DeLTA), the Catalogue of Soundscape Interventions (CSI), and the Soundscape Attributes Translation Project (SATP).\nI am also the host of The Rest is Just Noise, a monthly podcast exploring the relationship between sound and our cities. Each episode, along with my co-hosts and colleagues Dr Francesco Aletta and Dr Tin Oberman, I speak with researchers and experts from a wide range of backgrounds about their work in urban sounds and sound perception."
  },
  {
    "objectID": "research/presentations/2023-11-28_delft-lecture/index.html",
    "href": "research/presentations/2023-11-28_delft-lecture/index.html",
    "title": "TU Delft Pi-Lab Talk: Soundscape Designs",
    "section": "",
    "text": "Unable to display PDF file. Download instead."
  },
  {
    "objectID": "research/presentations/2023-11-28_delft-lecture/index.html#new-methods-and-proposals-for-evaluating-soundscape-designs-and-interventions",
    "href": "research/presentations/2023-11-28_delft-lecture/index.html#new-methods-and-proposals-for-evaluating-soundscape-designs-and-interventions",
    "title": "TU Delft Pi-Lab Talk: Soundscape Designs",
    "section": "",
    "text": "Unable to display PDF file. Download instead."
  },
  {
    "objectID": "research/papers.html",
    "href": "research/papers.html",
    "title": "Open Source Papers (with code)",
    "section": "",
    "text": "A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraings, and applications\n\n\n\n\n\n\n\nconference-papers\n\n\n\n\nPresented at Inter-noise 2023, Chiba, Greater Tokyo.\n\n\n\n\n\n\nAug 20, 2023\n\n\nAndrew Mitchell, Andrew Mitchell, Francesco Aletta, Tin Oberman, Mercede Erfanian, Jian Kang\n\n\n\n\n\n\n  \n\n\n\n\nHow to analyse and represent quantitative soundscape data\n\n\n\n\n\n\n\njournal-articles\n\n\n\n\nPublished in JASA Express Letters in March, 2022. \n\n\n\n\n\n\n\nMar 16, 2022\n\n\nAndrew Mitchell, Andrew Mitchell, Francesco Aletta, Jian Kang\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research/papers/how-to-analyse-jasa/index.html",
    "href": "research/papers/how-to-analyse-jasa/index.html",
    "title": "How to analyse and represent quantitative soundscape data",
    "section": "",
    "text": "Methods for collecting data on how people experience acoustic environments have been at the forefront of the debate in soundscape studies for the past 20 years. While the soundscape research field as we understand it today dates back to the late 1960s with the pioneering work of authors like M. Southworth (Southworth 1969), R.M. Schafer (Schafer 1977), and H. Westerkamp (Westerkamp 2002), the theme of data collection methods for soundscape assessment emerged more prominently only recently (Kang et al. 2016). There is a general consensus in the research community that standardised tools to gather and report individual responses on the perception of urban acoustic environments are indeed desirable, to provide comparable datasets and soundscape characterisations across different locations, times, and samples of people, as well as allowing for replicability studies, and offering inputs for modelling algorithms in soundscape prediction and design tasks. These were among the main drivers for the establishment of a Working Group at the International Organization for Standardization (ISO) back in 2008, which was named “Perceptual assessment of soundscape quality” (ISO/TC 43/SC 1/WG 54) that has so far published three documents within the ISO 12913 series on soundscape. Part 1 (ISO 12913-1:2014) is a full standard and provides a general framework and definitions of soundscape concepts (ISO 2014), while Part 2 (ISO/TS 12913-2:2018) and Part 3 (ISO/TS 12913-3:2019) are technical specifications and offer guidance on how data should be collected and analysed, accordingly (ISO 2018, 2019) (Part 4, on soundscape design interventions, is currently under development by the working group, also registered as a technical specifications document). Specifically, Part 3 presents the proposed methods for analysing and representing the data collected by the soundscape surveys. Since the development of these standards, the focus has shifted from understanding individual perception to characterising the collective perception of increasingly large groups.\nIn a recent editorial paper on Soundscape Assessment, Axelsson and colleagues observe that it is important to critically discuss current theories and models in soundscape studies and to examine their effectiveness, while also looking at how to integrate different methods and perspectives for the discipline to make further advancements (Axelsson, Guastavino, and Payne 2019). This work was mainly aimed at addressing the issue of meaningful comparability and representation of soundscape assessments. Part 2 of the ISO 12913 standard itself does not provide ultimate answers: the technical specifications recommend multiple methods, as consensus around a single protocol could not be reached. This diversity of methodological approaches should be interpreted as a fact that soundscape theory is still under development and, for this reason, the standardisation work should probably take a step back and focus on developing a reference method for comparability among soundscape studies, rather than a single protocol for soundscape data collection. Some attempts have indeed already been made in literature for the different methods proposed in the ISO/TS 12913-2:2018 Jo, Seo, and Jeon (2020). Neither the standard nor the general soundscape literature has settled on effective methods of analysing and representing the data that results from these protocols. Data visualisations are particularly important for understanding and communicating information as multifaceted as soundscape perception (Tufte 2001). Although it is unlikely that any single method will be sufficient, attempts should be made to both facilitate future advancements in this realm and to develop a first step approach that captures the inherent uncertainty in perception studies, since including uncertainty is considered one of the core principles of good data visualisation (Midway 2020).\nThis study thus aims to review the consequences of these methods for larger datasets and provide concrete examples for how soundscapes should be represented. In particular, we aim to strengthen the practices for characterising the soundscape of a location, as a collective perception by the users of the location. We also demonstrate how the progress of these tools from their initial scope (measuring and discussing the individual perception of a soundwalk participant) have not kept up with recent advances and requirements for larger-scale soundscape datasets. We question whether there are some issues related to the data collection instruments and data analysis methods as recommended and examine the results of the model framework and mathematical transformations laid out in the ISO technical specifications to guide the interpretation of the soundscape circumplex.\nTo examine these tools and the questions raised, we apply them to an existing large scale, real-world dataset of soundscape assessments collected according to the ISO methods. Finally, we propose a more holistic and advanced method of representing soundscapes as a probabilistic distribution of perceptions within the circumplex and provide a toolbox for others to use."
  },
  {
    "objectID": "research/papers/how-to-analyse-jasa/index.html#coordinate-transformation-into-the-two-primary-dimensions",
    "href": "research/papers/how-to-analyse-jasa/index.html#coordinate-transformation-into-the-two-primary-dimensions",
    "title": "How to analyse and represent quantitative soundscape data",
    "section": "2.1 Coordinate transformation into the two primary dimensions",
    "text": "2.1 Coordinate transformation into the two primary dimensions\nTo facilitate the analysis of the PA responses, the Likert scale responses are coded from 1 (Strongly disagree) to 5 (Strongly agree) as ordinal variables. In order to reduce the 8 PA values into a pair of coordinates which can be plotted on the Pleasant-Eventful axes, Part 3 of ISO 12913 (ISO 2019) provides a trigonometric transformation, based on the 45\\degree-relationship between the diagonal axes and the pleasant and eventful axes. This transformation projects the coded values from the individual PAs down onto the primary Pleasantness and Eventfulness dimensions then adds them together to form a single coordinate pair. In theory, this coordinate pair then encapsulates information from all 8 PA dimensions onto a more easily understandable and analysable two dimensions. The ISO coordinates are thus calculated by:\n\n\\begin{split}\n    ISO Pleasant = [(pleasant - annoying) + \\cos 45\\degree * (calm - chaotic) \\\\ + \\cos 45\\degree * (vibrant - monotonous)] * 1/(4+\\sqrt{32)}\n\\end{split}\n\\tag{1}\n\n\\begin{split}\n    ISO Eventful = [(eventful - uneventful) + \\cos 45\\degree * (chaotic - calm) \\\\ + \\cos 45\\degree * (vibrant - monotonous)] * 1/(4+\\sqrt{32)}\n\\end{split}\n\\tag{2}\nwhere the PAs are arranged around the circumplex as shown in Figure 1. The \\cos 45\\degree term operates to project the diagonal terms down onto the x and y axes, and the 1 / (4 + \\sqrt{32}) scales the resulting coordinates to the range (-1, 1). The result of this transformation is demonstrated in Figure 1. This treatment of the 8 PAs makes several assumptions and inferences about the relationships between the dimensions. As stated in the standard (ISO 2019, 5):\n\nAccording to the two-dimensional model, vibrant soundscapes are both pleasant and eventful, chaotic soundscapes are both eventful and unpleasant, monotonous soundscapes are both unpleasant and uneventful, and finally calm soundscapes are both uneventful and pleasant.\n\n\n\n\nFigure 1: Example of representations of two soundscape assessments. Left: Radar plot of two example perceptual attribute (PA) ratings on the Likert scales (1 to 5). Right: Scatter plot of the same assessments on the soundscape circumplex, transformed according to ISO 12913 Part 3."
  },
  {
    "objectID": "research/papers/how-to-analyse-jasa/index.html#summarising-the-soundscape-assessment-of-a-location",
    "href": "research/papers/how-to-analyse-jasa/index.html#summarising-the-soundscape-assessment-of-a-location",
    "title": "How to analyse and represent quantitative soundscape data",
    "section": "2.2 Summarising the soundscape assessment of a location",
    "text": "2.2 Summarising the soundscape assessment of a location\nWhile the assessment methods available are able to record the soundscape perception of a single individual, and that person’s perception is valid for themselves, it is not appropriate to then state that it is representative of the collective perception of that soundscape. In order to characterise the soundscape of a particular space or time, perceptual responses from multiple people must be collected and subsequently summarised or aggregated to describe the general soundscape of the location. The ISO guidelines stipulate a minimum of 20 participants for a soundwalk, with these broken up into sessions of no more than 5 participants at a time. Part 3 then provides the recommended methods for analysing this data.\nAnnex A.2 of ISO 12913 Part 3 provides the statistical measures to be used on the raw PA responses. The recommended measure of central tendency is the median, while the recommended measure of dispersion is the range. These are chosen as the data is ordinal by nature, however as will be demonstrated later, they have significant limitations. Although it is unclear, the implied intention is then that the median value of each PA is fed into Equation 1 and Equation 2 presented above to calculate the ISOPleasant and ISOEventful values, which can then be plotted in a two-dimensional scatter plot. Thus the standard suggests that 1) the projection method equations are not applied to individual responses and 2) only the median assessment of a location should be plotted."
  },
  {
    "objectID": "research/papers/how-to-analyse-jasa/index.html#limitations-of-the-iso",
    "href": "research/papers/how-to-analyse-jasa/index.html#limitations-of-the-iso",
    "title": "How to analyse and represent quantitative soundscape data",
    "section": "2.3 Limitations of the ISO",
    "text": "2.3 Limitations of the ISO\nHow these methods should be applied to represent the soundscape of a location has not been adequately discussed in previous literature, nor sufficiently in Part 3 of ISO 1293 itself. Indeed, in Section A.3, the technical specifications document state that (ISO 2019, 5):\n\nResults can be reported in a two-dimensional scatter plot with coordinates for the two dimensions ‘pleasantness’ and ‘eventfulness’. The coordinates for ‘pleasantness’ are plotted on the X-axis, and the coordinates for ‘eventfulness’ on the Y-axis. Every data point in the scatter plot represents one investigated site.\n\nHowever, it is not made clear whether this single point on the circumplex can be considered to be a realistic representation of the average perception of the acoustic environment. Effectively, there is no representation of dispersion in the soundscape assessment, nor a recommended use of the range that was calculated as part of the analysis recommend in Section A.2 of Part 3 of the ISO 12913. Absent a suggestion from the ISO 12913 for how the range should be used, we therefore apply this analysis to an existing real-world soundscape dataset to determine whether it provides a useful measure of dispersion. Here we use the data contained in the International Soundscape Database (ISD) (Mitchell, Oberman, Aletta, Erfanian, et al. 2021), which includes 1,300+ individual responses collected across 13 locations in London and Venice, according to the SSID Protocol, which is based on the ISO methods explored in this paper (Mitchell et al. 2020).\nFor any large enough sample for a site, the range will always be from 1 to 5, the maximum and minimum available Likert-scale values. We would expect that collecting more data would result in more information or better precision, however the range will always increase as the sample size increases. As an example, within the ISD data, of the 8 PAs collected at 13 locations (for a total of 104 scales), 88% have a range from 1 to 5 and with larger sample sizes at each location, this percentage would only have increased. Using range to analyse the dispersion provides very limited information for comparing the soundscape assessments of different locations, or of a location under different conditions.\nAlthough the range does not appear to be a useful measure of dispersion, the median does provide a useful measure and appropriately functions to describe the central tendency of the soundscape assessment of the sample. However, by stipulating that the median of each PA should be taken prior to applying the circumplex projection, the ISO procedure only allows for plotting a single scatter point in the circumplex for each location and does not allow for plotting individual responses on the circumplex. This limits the possibilities for visualising the general trends in individual perception across the soundscape. Finally, no example or recommendation for how the circumplex scatter plot should be presented is given in the standard.\nThe instruments described in the ISO 12913 Part 2 (ISO 2018) were originally designed primarily for the context of individual or small group assessments. In these scenarios, the focus is on assessing the particular soundscape perception of the person in question. Recent advances in the soundscape approach since the development of the standards have shifted some focus from individual soundscapes to characterising the overall soundscape of public spaces (Mitchell et al. 2020) and to making comparisons between different groups of people (Jeon et al. 2018). In this context, a consideration of the natural variation in people’s perception and the variation over time of a soundscape must be a core feature of how the soundscape is discussed. Reducing a public space which may have between tens and tens of thousands of people moving through it in a single day down to the mean (or median, or any other single metric) soundscape assessment often dismisses the reality of the space. Likewise, this overall soundscape of a public space cannot be determined through a ten person soundwalk, as there is no guarantee that the sample of people engaged in the soundwalk is representative of the users of the space (in fact it is likely they would not be)."
  },
  {
    "objectID": "research/papers/how-to-analyse-jasa/index.html#limitations-of-the-circumplex-and-quantitative-analysis",
    "href": "research/papers/how-to-analyse-jasa/index.html#limitations-of-the-circumplex-and-quantitative-analysis",
    "title": "How to analyse and represent quantitative soundscape data",
    "section": "4.1 Limitations of the circumplex and quantitative analysis",
    "text": "4.1 Limitations of the circumplex and quantitative analysis\nThe method presented here is a solution for representing the soundscape of a space, which requires considering the perception of many people, but it is important to note that this is only one (very important) goal of the soundscape approach. Psychological and sociological investigations of people’s relationship to their sound environment and the interactions between social contexts and individual perception are a crucial aspect of the field for which this approach would likely not be sufficient (Bild et al. 2018). Open-response questions, structured interviews, and mixed-methods studies can provide additional insight into how people experience their environment and should be considered alongside or preceding this focus on how a space is likely to be perceived on a larger scale.\nThese other approaches are not in opposition to the methods proposed here, but instead further expand our view. The circumplex is a limited view of soundscape perception (this is made obvious by the fact that it excludes the third component, familiarity, identified in Axelsson, Nilsson, and Berglund (2010)) but it is an exceptionally rich tool for dealing with the two primary aspects of soundscape perception which can readily expand the much more limited view provided by existing noise and annoyance assessment tools. Aspects of the psychological and sociological emphasis can also be integrated into a circumplex-focused approach, as demonstrated in Erfanian et al. (2021), where personal factors such as age, gender, and psychological well-being were analysed in terms of how they mediated the ISOPleasant and ISOEventful outcomes.\nThere has been some discussion regarding the interdependence of the PAs and the strict validity of the 90and 45 relationships between the attributes (Lionello et al. 2021). Further work has indicated that the scaling between the attributes may vary, but the underlying relationships hold. It is for this reason that we have taken the coordinate projection as the starting point of this critique. It should also be noted that the particular PA descriptors used in ISO 12913 are intended for outdoor environments and should not be directly applied to indoor spaces. However, a proposed set of descriptors for some indoor environments has been derived which further confirms the validity of the circumplex relationships (Torresin et al. 2020). The methods proposed here should be directly applicable to indoor spaces by using the comfort/content descriptors as well as to any other translations of soundscape descriptors into other languages (Aletta et al. 2020) as long as the dimensional relationships of the circumplex are maintained."
  },
  {
    "objectID": "research/papers/how-to-analyse-jasa/index.html#footnotes",
    "href": "research/papers/how-to-analyse-jasa/index.html#footnotes",
    "title": "How to analyse and represent quantitative soundscape data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe specifics of the bivariate kernel density estimation (Silverman 2018) are beyond the scope of this discussion and the most appropriate hyperparameters (e.g. estimation methods, smoothing factors) for this visualisation may need to be further explored. These parameters will likely depend on the specific dataset used.↩︎"
  },
  {
    "objectID": "research/presentations.html",
    "href": "research/presentations.html",
    "title": "Presentations",
    "section": "",
    "text": "TU Delft Pi-Lab Talk: Soundscape Designs\n\n\n\n\n\n\n\nlecture\n\n\n\n\nInvited Lecture delivered at the IDE Co-Lab at TU Delft\n\n\n\n\n\n\nMay 11, 2025\n\n\nAndrew Mitchell\n\n\n\n\n\n\n  \n\n\n\n\nFree and open-source software for soundscape visualization and binaural analysis\n\n\nPoster presentation given at the Urban Sound Symposium 2023, Barcelona\n\n\n\n\nconference\n\n\n\n\n\n\n\n\n\n\n\nApr 21, 2023\n\n\nAndrew Mitchell\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html",
    "href": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html",
    "title": "A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraings, and applications",
    "section": "",
    "text": "As the future of urban sound research and practice moves toward a more holistic soundscape focus, the ability to affect change at large scales and in a wide range of projects will require that familiar engineering tools and approaches can be applied to soundscape design. When attempting to apply soundscape in practice in the built environment, it becomes apparent that a predictive model of the users’ perceptual response to the acoustic environment is necessary. Whether to determine the impact of a design change, or to integrate a large scale data at neighbourhood and city levels, a mathematical model of the interacting factors will form a vital component of the implementation of the soundscape approach.\nCurrent methods of assessing soundscapes are generally limited to a post hoc assessment of the existing environment, where users of the space in question are surveyed regarding their experience of the acoustic environment (Engel et al. 2018; Zhang et al. 2018; Ba and Kang 2019). While this approach has proved useful in identifying the impacts of an existing environment, designers require the ability to predict how a change or proposed design will impact the soundscape of the space, before its implementation. To this end, a model that is built on measurable or estimate-able quantities of the environment would represent a leap forward in the ability to design soundscapes and to assess their broad impacts on health and wellbeing.\nWe will begin by outlining the use cases of predictive soundscape models and how they are necessary for certain applications. From the desired use cases, we will then outline a framework within which practical predictive models can be developed."
  },
  {
    "objectID": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#introduction",
    "href": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#introduction",
    "title": "A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraings, and applications",
    "section": "",
    "text": "As the future of urban sound research and practice moves toward a more holistic soundscape focus, the ability to affect change at large scales and in a wide range of projects will require that familiar engineering tools and approaches can be applied to soundscape design. When attempting to apply soundscape in practice in the built environment, it becomes apparent that a predictive model of the users’ perceptual response to the acoustic environment is necessary. Whether to determine the impact of a design change, or to integrate a large scale data at neighbourhood and city levels, a mathematical model of the interacting factors will form a vital component of the implementation of the soundscape approach.\nCurrent methods of assessing soundscapes are generally limited to a post hoc assessment of the existing environment, where users of the space in question are surveyed regarding their experience of the acoustic environment (Engel et al. 2018; Zhang et al. 2018; Ba and Kang 2019). While this approach has proved useful in identifying the impacts of an existing environment, designers require the ability to predict how a change or proposed design will impact the soundscape of the space, before its implementation. To this end, a model that is built on measurable or estimate-able quantities of the environment would represent a leap forward in the ability to design soundscapes and to assess their broad impacts on health and wellbeing.\nWe will begin by outlining the use cases of predictive soundscape models and how they are necessary for certain applications. From the desired use cases, we will then outline a framework within which practical predictive models can be developed."
  },
  {
    "objectID": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#defining-what-a-predictive-soundscape-model-is",
    "href": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#defining-what-a-predictive-soundscape-model-is",
    "title": "A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraings, and applications",
    "section": "2 Defining what a predictive soundscape model is",
    "text": "2 Defining what a predictive soundscape model is\nAletta, Kang, and Axelsson (2016) provide a review of the soundscape descriptors and indicators commonly used in soundscape research and outlines an initial framework for developing predictive soundscape models. In their review, the authors identified eight potential soundscape descriptors, including perceived affective quality (Axelsson, Nilsson, and Berglund 2010), restorativeness (Payne 2013), etc. Similarly, the authors identified a range of potential indicators used to characterise the acoustic environment, including environmental acoustics indicators such as L_{Aeq}, L_{Ceq} − L_{Aeq} and psychoacoustic indicators such as Loudness (N_5) and Sharpness (S).\nHowever, it is noted that several studies show that no single psychoacoustic indicator alone can explain the variation in soundscape responses (as expressed via the descriptors) (e.g. (Persson Waye and Öhrström 2002)). The goal of statistical modelling, therefore is to create a more complex and complete representation of the relationship between soundscape indicators and descriptors, beyond what any single indicator could achieve.\nFigure 1 shows a conceptual view of this relationship. We start with soundscape indicators, which characterise the physical and contextual environment to which the listener is exposed. This can be broken down into sonic features (e.g. the acoustical features listed above) and characteristics of the space itself (e.g. the amount of visible sky, the intended use-case of the space, how crowded the space is, etc.). In order to translate from the physical inputs to an expressed description of the soundscape perception, we introduce the concept of a perceptual mapping (Lionello 2021). This mapping represents a simplified idea of how each individual’s brain processes the inputs from the soundscape which they experience, forms a perception, and finally expresses that perception through their description of the soundscape. For our purposes, this perceptual mapping is treated as essentially a black box mapping inputs to outputs. It can be conceived of as a network of weights in which certain characteristics of the sound may have different weights and directions depending on the context, through which all of the inputs are processed, resulting in the soundscape rating. Conceptually, this perceptual mapping – the pathways and weightings through which the inputs are processed before being expressed as a perceptual descriptor – is established prior to an individual’s exposure to the soundscape in question.\n\n\n\nFigure 1: The conceptual model of soundscape perception, illustrating the perceptual mapping from physical inputs, through personal experience, to soundscape descriptors. The role of the statistical model is to attempt to approximate or reflect this perceptual mappint. Reproduced with permission from Mitchell (2022)\n\n\nIt should be made clear that this represents a very simplified view of how a soundscape perception is formed, however it provides a useful conceptual framework for the purposes of understanding and modelling how someone’s perception forms in response to their exposure to a space. One way to consider the function of a statistical model of soundscape perception is as replicating the perceptual mapping between soundscape indicators and descriptors (Lionello 2021). As a person experiences an urban space, they are exposed to an array of physical inputs, these are then processed by the listener through their own personal experience and mapped to their perception of that space. This perception is then expressed through their description of this experience of the soundscape. It is this mapping of physical inputs to perceptual description which the statistical model aims to reflect. The most successful model would then accurately replicate the general perceptual mapping across the population."
  },
  {
    "objectID": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#applications-in-design-and-mapping",
    "href": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#applications-in-design-and-mapping",
    "title": "A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraings, and applications",
    "section": "3 Applications in design and mapping",
    "text": "3 Applications in design and mapping\nThe soundscape approach faces several challenges in practical applications which are unaddressed by current assessment methods, but which may be solved through the development of a predictive modelling framework. The first of these challenges is predicting how a change in an existing sound environment will be reflected in the soundscape perception. While it is possible in this scenario to measure the existing soundscape perception via questionnaire surveys, if a change is then introduced to the acoustic environment, it is so far impossible to say what the resulting soundscape change would be. This question relates strongly to the idea of soundscape interventions; where a particular noise pollution challenge is addressed by introducing more pleasant sounds (e.g. a water feature), following the soundscape principle of treating sound as a resource (Lavia et al. 2016; Moshona et al. 2022). Predicting how much a particular intervention would improve the soundscape (or, indeed whether it would improve at all) is not yet possible with the retrospective methods available.\nSeveral studies have attempted to address this gap by developing machine learning or statistical models of soundscape perception which are focussed on prediction, rather than inference. An array of modelling techniques are used, with linear regression being the most common (Lionello, Aletta, and Kang 2020), and also including artificial neural networks (ANN) (Puyana Romero et al. 2016; Yu and Kang 2009) and support vector regression (SVR) (Fan, Thorogood, and Pasquier 2016, 2017; Giannakopoulos, Orfanidi, and Perantonis 2019). However, these studies have focussed primarily on using these models to investigate the constructs of soundscape perception, with few efforts to put the models themselves to use. Mitchell et al. (2021) attempted to address this by both developing a predictive model and applying it to an applied scenario where traditional assessment methods were impractical. In a unique application, Ooi et al. (2022) created a predictive model of soundscape pleasantness which fed an automated and reactive soundscape enhancement system (Watcharasupat et al. 2022).\nRetrospective methods also struggle to capture the dynamics of the soundscape in a space. Whether through the narrative interview method of ISO/TS 12913-2 (ISO/TS 12913-2:2018 2018), through soundwalks, or through in situ questionnaires (Mitchell et al. 2020), only the soundscape during the particular period which the researchers are actively investigating is captured. This makes it very difficult to determine diurnal, seasonal, or yearly patterns of the soundscape. These patterns may be driven by corresponding diurnal, seasonal, or yearly patterns in the acoustic or visual environment, or by variations in how people process and respond to the sound at different times of day/season/year. Currently the only way to investigate any of these patterns is through repeated surveys. Predictive modelling, on the other hand, could allow a trained soundscape model to be paired with longterm monitoring methods to track how a soundscape perception may change in response to changes in the acoustic environment.\nSimilarly, a move towards modelling methods based on objective and/or measurable factors would facilitate the application of mapping in soundscape. While noise maps have become common in urban noise research and legislation (EEA 2020; Gasco et al. 2020), they can be difficult to translate into a soundscape approach. The Environmental Noise Directive (END) (European Union 2002), first implemented in 2002, is the main EU instrument to identify noise pollution impacts and track urban noise levels across the EU. Its goals were to determine the population’s exposure to environmental noise, make information on environmental noise available to the public, and prevent and reduce environmental noise and its effects. In general, noise maps are based on modelled traffic flows, from which decibel levels are extrapolated and mapped, although interpolation and mobile measurement methods have also been recently developed (see Aumond, Jacquesson, and Can 2018). Alternatively, they can be produced using longterm SLMs or sensor networks. While these methods have significant utility for tracking increases in urban noise levels and are important for determining the health and societal impacts of noise on a large scale, their restricted focus on noise levels alone limits their scope and reduces the potential for identifying more nuanced health and psychological effects of urban sound.\nSeveral studies have attempted to bring soundscape to urban noise mapping. The most notable of these attempts (Aumond, Jacquesson, and Can 2018; Aletta and Kang 2015; Hong and Jeon 2017; Kang and Aletta 2018) bring new, more sophisticated methods for mapping urban sound (not just noise levels). For instance, all four present methods which map the relative level of various sound sources, producing maps of the spatial distribution of bird sounds, human voices, water sounds, etc. In Aletta and Kang (2015) and Hong and Jeon (2017) the mapping relied on soundscape surveys conducted in public spaces, then used interpolation methods and basic relationships to the measured noise levels to generate a map of the perceived soundscape over the entire study space. Kang et al. (2018), after starting with survey responses, attempted to create a prediction methods which relied only on the audio recordings made in the space to create visual maps of the predicted soundscape perception (i.e. the perceptual attributes ’pleasant’, ’calm’, ’eventful’, ’annoying’, ’chaotic’, ’monotonous’). According to the authors, the prediction and mapping model would follow three steps: (1) sound sources recognition and profiling, (2) prediction of the soundscape’s perceptual attributes, and (3) implementation of soundscape maps. Unfortunately, from the paper, it appears that the prediction model results were not actually used for the mapping and, again, the survey responses from 21 respondents were interpolated to create the soundscape map. Their results indicated how a predictive model could have been slotted into a mapping use-case, but this was limited by (1) the relatively poor predictive performance for several of the attributes, (2) the inability to automatically recognise sound sources, and (3) a very limited dataset in terms of sample size and variety of locations.\nWhile the connection is not made to perception, Aumond, Jacquesson, and Can (2018) focussed on creating sound maps which can reflect the pattern of sound source emergences over time within a city. By stochastically activating varying sound sources across their map, they could map the percentage of time when a sound source emerges from the overall complex sound environment. If a predictive soundscape model which incorporates sound source information can be developed, then the same procedure which led to their sound source emergence maps could also feed the soundscape model, resulting in a map of predicted perception over time.\nUrban scale noise mapping and its implementation at the international level has been crucial in highlighting the health impacts of urban noise and in providing evidence for the negative cost of excess noise. Traffic flow models of noise, large community noise surveys, and policy requirements to track noise levels have all been necessary to reveal these impacts. By creating predictive soundscape models, combined with new tools and sensing capabilities from smart city efforts, we can bring soundscape into these same realms. Without this, these large-scale impact studies will be limited to valuing the negative cost of urban noise, missing the potential value of positive soundscapes. By bringing perception-based practice to the same scale and type of evidence, we can expand urban sound research to consider a holistic view of urban spaces and their impacts.\nThe broader use-case and need for such soundscape models and maps was recently highlighted by Jiang et al. (2022), which opens the discussion for how the value and impact of soundscapes should be measured and what tools are needed to enable the valuation of policy interventions for soundscapes. In response to Question 5, “What soundscape metrics and data will be needed?”, the authors make clear the necessity of predictive soundscape models: “Quantitative soundscape metrics that link subjective perceptions to objective acoustic and contextual factors will be needed, to enable monetisation while at the same time account for the perception-based nature of soundscape.” In addition, the authors make a strong case for the need for soundscape indices: “Despite the varied requirements for soundscape metrics and data between and even within valuation methods, a standardised metric or set of metrics, such as dB in noise valuation [. . . ] will allow comparison and integration of different studies and building compatible evidence bases.”"
  },
  {
    "objectID": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#the-predictive-soundscape-model-framework",
    "href": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#the-predictive-soundscape-model-framework",
    "title": "A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraings, and applications",
    "section": "4 The Predictive Soundscape Model Framework",
    "text": "4 The Predictive Soundscape Model Framework\nSeveral forms and iterations of predictive models have been developed (Lionello, Aletta, and Kang 2020) and more recently they have been put to use in real-world use cases (Mitchell et al. 2021; Watcharasupat et al. 2022). To improve on these models and make them into a useful engineering tool, we should establish a framework of overarching goals for models to achieve and the resulting development constraints. In general, the goals we define are related to how we might wish for models to be used and deployed, while the constraints are practical limitations which may make the performance of a given model less than ideal, but are necessary to achieve the deployment goals.\n\n4.1 Goals\nBefore defining what form a general practical predictive model should take, we first need to make clear what the goals of such a model are, as derived from the preceding discussion laying out why predictive models are needed in soundscape.\nAccuracy – First, that it to a reasonable extent is successful in predicting the collective perception (see Mitchell, Aletta, and Kang 2022) of a soundscape. It should succeed at both indicating the central tendency of the soundscape perception, but importantly it should also inform the likely spread of perception among the population. The outcome of the predictive model should not be focussed on predicting an individual assessment; the goal is not the predict the perception of any specific individual, but to reflect the public’s perception of a public space. In other words, ideally the model will result in an accurate distribution of soundscape perceptions for the target population.\nAutomation – Second, that it can be implemented automatically. Once an initial setup is performed, such as identifying what location the measurements are conducted in, the model should be capable of moving from recorded information to predicted soundscape distribution without human intervention. We need soundscape assessments to be able to be performed instrumentally. This enables it to be applied to unmanned uses, such as smart city sensors and soundscape mapping. It is impractical to conduct soundscape surveys or soundwalks in every location we wish to map and certainly not when we wish to see how these locations change over longer periods of time. A predictive model should allow us to survey these soundscapes remotely in order to extend soundscape to city-scale assessments.\nComparisons – Third, the model should enable us to test, score, and compare proposed interventions. In a design context, it is crucial that various strategies and interventions can be tested and that the influencing factors can be identified. The model should assist the user in highlighting what factor is limiting the success of a soundscape, spark ideas for how to address it, and allow these ideas to be tested. Several other useful features of predictive soundscape models arise out of these goals and will be discussed later, but these form the core goals of the framework.\n\n\n4.2 Constraints\nIf we accept that predictive models are necessary to advance a more holistic approach to urban sound in smart cities, we must then define the constraints of such a model. The goal here is to define a framework for what is needed from a future model intended to be used in a smart city sensors, soundscape mapping, or urban design context.\nInputs – The first constraint is that the model must be based on measurable factors. By this, we mean that the data which eventually feeds into the predictive model should be collected via sensor measurements of one sort or another; this could be acoustic sound level measurements or recordings, environmental measurements, video recordings, or GIS measurements, etc. What it certainly cannot include is perceptual data. This is strictly a practical constraint – for a predictive model designed to be used in practice, there is no justification to include other perceptual factors, such as perceived greenness, derived from surveys but not whichever factor you desire to predict. If the goal is to predict soundscape pleasantness and it is necessary to survey people about the visual pleasantness, why not just also survey them about the soundscape pleasantness directly? Certainly this mix of perceptual data is useful in research and can elucidate the relationship between the sonic and visual environments, but it is not useful in a practical predictive context. Any results which arise from research combining this sort of perceptual information must eventually be translated into a component which can itself be measured or modelled.\nCalculation – The second constraint is that any analysis of the measured data can be done automatically, without human intervention. If the eventual goal is to deploy the model on continuously-running, unmanned sensor nodes or to enable practical large-scale measurements, the predictive model should be capable of operating with minimal human input. This means, for instance that if the model includes information about the sound source, this identification of the source should be possible to do automatically (i.e. through environmental sound recognition).\nA potential constraint for some applications is related to computation time. Since one proposed application of a predictive soundscape model is to embed the model on a WASN node, the model would then need to be able to run on relatively low-power hardware such as a Raspberry Pi with a reasonable latency. This would especially present an issue for those models which rely on the combination of several psychoacoustic features (such as Mitchell et al. 2021; Orga et al. 2021), since these features are computationally intensive to calculate and several of them may need to be computed for each time step of the model. Although this is a real practical concern that should be addressed in the future, for the sake of this initial definition of a general predictive model used across many applications, we have not considered this a strict constraint.\nGeneralisability – The third constraint is for the model to be generalisable to new locations. Ideally, it will be generalisable to new and (to it) unfamiliar soundscape types, but the minimum requirement should be that it can be applied to new locations which are otherwise similar to those in the training data. This means that any factors which are used to characterise the context provided by the location should be distinguished from a simple label of the location and should instead be derived from measurements of the location. In practice this could be geographical or architectural characteristics of the space, a proposed use-case of the space, or consistent visual characteristics of the space such as the proportion of pavement to green elements. This is in contrast to the model created in Mitchell et al. (2021) which was constrained to be used only on those locations included in the training data since it made use of a location label.\nFor this third point, some aspects of the first and second constraints can be relaxed. Since this would only need to be defined once for a location, definitions such as the use case of the space could be defined by the person using the model. What is necessary is that the model and its component location-context factors can be set up ahead of time by the user, then the recording-level effects are able to be calculated automatically. In a multi-level modelling (MLM) context (such as that used in (Mitchell et al. 2021), this essentially amounts to choosing the appropriate location-level coefficients ahead of time then automatically calculating the features which are fed into those coefficients (per constraint 1 & 2).\nRobustness – Finally, the model should be robust to missing components. If the original or full construction of the model depends on demographic information of the population using the space, in cases where this information is not available, it should be possible to omit it and still obtain a reasonable result. Here we may define potential ‘must-have’ and ‘optional’ factors. Given the amount of variance explained by the various factors which have been considered in previous predictive models, in-depth acoustic information is a must-have, while demographic and personal factors are an optional factor where the trade-off of losing 3% of the explained variance in eventfulness (Erfanian et al. 2021) is accepted as reasonable. Based on the results of Mitchell et al. (2021), it would appear that location-context is crucial for modelling the pleasantness, but not for modelling the eventfulness. In order to determine the must-have factors for characterising the location-context, more work will need to be done to determine the appropriate input factors and their relative importance."
  },
  {
    "objectID": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#making-use-of-the-predictions-in-design",
    "href": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#making-use-of-the-predictions-in-design",
    "title": "A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraings, and applications",
    "section": "5 Making use of the predictions in design",
    "text": "5 Making use of the predictions in design\nThere are various potential methods for integrating the predictive soundscape approach into a design and intervention setting. Not all spaces can or should have the same soundscape and soundscapes should be treated as dynamic, not static; identifying and creating an appropriate soundscape for the particular use case of a space is crucial to guiding its design. Proper forwardlooking design of a soundscape would involve defining the desired collective perception in the space. In the probabilistic soundscape approach from Mitchell, Aletta, and Kang (2022), this can be achieved by drawing the desired shape in the circumplex and testing interventions which will bring the existing soundscape closer to the desired perception. A soundscape may need to be perceived as vibrant during the day and calm for some portion of the evening, meaning the desired shape should primarily sit within the vibrant quadrant but have some overlap into calm. This also enables designers to recognise the limitations of their environment and acknowledge that it is not always possible to transform a highly chaotic soundscape into a calm one. In these cases, instead the focus should be placed on shifting the perception to some degree in a positive direction.\n\n\n\nFigure 2: Adapted from Cain, Jennings, and Poxon (2013). Using the soundscape circumplex shape for target-setting for soundscape design. Reproduced with permission from Mitchell (2022).\n\n\nThe most sophisticated method of setting design goals is therefore to identify the desired shape which represents the variety of desired outcomes, and focus on designs and interventions which are most successful in matching the predicted outcome with that goal. This strategy of defining the optimal soundscape as an area or a shape within the 2-dimensional circumplex was previously illustrated by Cain, Jennings, and Poxon (2013). In Figure 2, we have adapted Cain’s Figure 6 to show how the shape of a target soundscape can be set and the shape of the existing soundscape compared to it. The work of a designer is then trialling intervention options which move the design soundscape closer to the target soundscape."
  },
  {
    "objectID": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#towards-soundscape-indices",
    "href": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#towards-soundscape-indices",
    "title": "A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraings, and applications",
    "section": "6 Towards Soundscape Indices",
    "text": "6 Towards Soundscape Indices\nAlthough the types of visualisations developed in (Mitchell, Aletta, and Kang 2022) and (Cain, Jennings, and Poxon 2013) are a powerful tool for viewing, analysing, and discussing the multi-dimensional aspects of soundscape perception, there are certainly cases where simpler metrics are needed to aid discussion and to set design goals. Within the practicalities of built environment projects, the consequences and successes of a design often need to be quantifiable within a single index. Whether to demonstrate performance indicators to a client or to set and meet consistent policy requirements, numerical ratings and/or rankings are necessary. This therefore necessitates the creation of consistent and validated indices which indicate the degree to which a proposal achieves a set design goal.\nThe challenge for creating a single number index lies in properly combining the two-plus dimensions of soundscape perception with the needs of a specific project into a single index. The obvious option would be to ignore the multi-dimensionality and only score soundscape designs on the basis of their pleasantness score (as done in (Ooi et al. 2022)). However, this seems to ignore both the significant importance of the eventfulness dimension in shaping the character of a soundscape and the role of appropriateness in determining the ’optimal soundscape’ for a space. Ideally, a soundscape index (or set of soundscape indices) would succeed at capturing all these aspects into a single scoring metric."
  },
  {
    "objectID": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#conclusion",
    "href": "research/papers/2023-08-20_Internoise-framework/InterNoise2023_Mitchell_Predictive_Model_Framework.html#conclusion",
    "title": "A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraings, and applications",
    "section": "7 Conclusion",
    "text": "7 Conclusion\nThe existing methods for soundscape assessment and measurement, such as those given in the ISO 12913 series, have been focussed primarily on determining the status quo of an environment. That is, they are able to determine how the space is currently perceived, but offer little insight into hypothetical environments. As such, they are less relevant for design purposes, where a key goal is to determine how a space will be perceived, not just how an existing space is perceived. The methods for assessment outlined in ISO/TS 12913-2:2018 (2018) and for analysis given in ISO/TS 12913-3:2019 (2019) are inherently limited to post hoc assessments of an existing space. Since they are focussed on surveying people on their experience of the environment, it stands that the space must already exist for people to be able to experience. Toward this, and following from the combination of perceptual and objective data collection encouraged in ISO/TS 12913-2:2018 (2018), the natural push from the design perspective is towards ’predictive modelling’."
  },
  {
    "objectID": "research/list-of-pubs.html",
    "href": "research/list-of-pubs.html",
    "title": "List of Publications",
    "section": "",
    "text": "Journal Papers\n2024\nYuanbo Hou, Bo Kang, Andrew Mitchell, Wenwu Wang, Jian Kang, and Dick Botteldooren. (2024) \"Cooperative Scene-Event Modelling for Acoustic Scene Classification.\" IEEE/ACM Transactions on Audio, Speech, and Language Processing doi: 10.1109/TASLP.2023.3323135 \n        \n        Published\n     \n2023\nFrancesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, and Jian Kang. (2023) \"Soundscape experience of public spaces in different world regions: A comparison between the European and Chinese contexts via a large-scale on-site surveya).\" The Journal of the Acoustical Society of America doi: 10.1121/10.0020842 \n        \n        Published\n     \nYuanbo Hou, Qiaoqiao Ren, Huizhong Zhang, Andrew Mitchell, Francesco Aletta, Jian Kang, and Dick Botteldooren. (2023) \"AI-based soundscape analysis: Jointly identifying sound sources and predicting annoyancea).\" The Journal of the Acoustical Society of America doi: 10.1121/10.0022408 \n        \n        Published\n     \nJian Kang, Francesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, Huan Tong, Simone Torresin, Chunyang Xu, Tingting Yang, and Xiaochao Chen. (2023) \"Supportive soundscapes are crucial for sustainable environments.\" Science of The Total Environment doi: 10.1016/j.scitotenv.2022.158868 \n        \n        Published\n     \nNikolaos M. Papadakis, Francesco Aletta, Jian Kang, Tin Oberman, Andrew Mitchell, Ioanna Aroni, and Georgios E. Stavroulakis. (2023) \"City, town, village: Potential differences in residents soundscape perception using ISO/TS 12913-2:2018.\" Applied Acoustics doi: 10.1016/j.apacoust.2023.109659 \n        \n        Published\n     \nJerónimo Vida, José Antonio Almagro, Rafael García-Quesada, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Jian Kang. (2023) \"Soundscape attributes in Spanish: A comparison with the English version of the protocol proposed in Method A of the ISO/TS 12913–2.\" Applied Acoustics doi: 10.1016/j.apacoust.2023.109516 \n        \n        Published\n     \n2022\nAndrew Mitchell, Mercede Erfanian, Christopher Soelistyo, Tin Oberman, Jian Kang, Robert Aldridge, Jing-Hao Xue, and Francesco Aletta. (2022) \"Effects of Soundscape Complexity on Urban Noise Annoyance Ratings: A Large-Scale Online Listening Experiment.\" International Journal of Environmental Research and Public Health doi: 10.3390/ijerph192214872 \n        \n        Published\n     \nAndrew Mitchell, Francesco Aletta, and Jian Kang. (2022) \"How to analyse and represent quantitative soundscape data.\" JASA Express Letters doi: 10.1121/10.0009794 \n        \n        Published\n     \n2021\nMercede Erfanian, Andrew Mitchell, Francesco Aletta, and Jian Kang. (2021) \"Psychological well-being and demographic factors can mediate soundscape pleasantness and eventfulness: A large sample study.\" Journal of Environmental Psychology doi: 10.1016/j.jenvp.2021.101660 \n        \n        Published\n     \nMatteo Lionello, Francesco Aletta, Andrew Mitchell, and Jian Kang. (2021) \"Introducing a Method for Intervals Correction on Multiple Likert Scales: A Case Study on an Urban Soundscape Data Collection Instrument.\" Frontiers in Psychology doi: 10.3389/fpsyg.2020.602831 \n        \n        Published\n     \nAndrew Mitchell, Tin Oberman, Francesco Aletta, Magdalena Kachlicka, Matteo Lionello, Mercede Erfanian, and Jian Kang. (2021) \"Investigating urban soundscapes of the COVID-19 lockdown: A predictive soundscape modeling approach.\" The Journal of the Acoustical Society of America doi: 10.1121/10.0008928 \n        \n        Published\n     \nFerran Orga, Andrew Mitchell, Marc Freixes, Francesco Aletta, Rosa Ma Alsina-Pagès, and Maria Foraster. (2021) \"Multilevel Annoyance Modelling of Short Environmental Sound Recordings.\" Sustainability doi: 10.3390/su13115779 \n        \n        Published\n     \nHuan Tong, Francesco Aletta, Andrew Mitchell, Tin Oberman, and Jian Kang. (2021) \"Increases in noise complaints during the COVID-19 lockdown in Spring 2020: A case study in Greater London, UK.\" Science of The Total Environment doi: 10.1016/j.scitotenv.2021.147213 \n        \n        Published\n     \nJerónimo Vida Manzano, José Antonio Almagro Pastor, Rafael García Quesada, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Jian Kang. (2021) \"The \"sound of silence\" in Granada during the COVID-19 lockdown.\" Noise Mapping doi: 10.1515/noise-2021-0002 \n        \n        Published\n     \n2020\nFrancesco Aletta, Tin Oberman, Andrew Mitchell, Huan Tong, and Jian Kang. (2020) \"Assessing the changing urban sound environment during the COVID-19 lockdown period using short-term acoustic measurements.\" Noise Mapping doi: 10.1515/noise-2020-0011 \n        \n        Published\n     \nAndrew Mitchell, Tin Oberman, Francesco Aletta, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Jian Kang. (2020) \"The Soundscape Indices (SSID) Protocol: A Method for Urban Soundscape Surveys–Questionnaires with Acoustical and Contextual Information.\" Applied Sciences doi: 10.3390/app10072397 \n        \n        Published\n     \n2019\nFrancesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, Matteo Lionello, Magdalena Kachlicka, and Jian Kang. (2019) \"Associations between soundscape experience and self-reported wellbeing in open public urban spaces: A field study.\" The Lancet doi: 10.1016/s0140-6736(19)32814-4 \n        \n        Published\n     \nMercede Erfanian, Andrew J. Mitchell, Jian Kang, and Francesco Aletta. (2019) \"The Psychophysiological Implications of Soundscape: A Systematic Review of Empirical Literature and a Research Agenda.\" International Journal of Environmental Research and Public Health doi: 10.3390/ijerph16193533 \n        \n        Published\n     \nConference Papers\n2023\n Andrew Mitchell. (2023) \"Soundscapy: A python package for soundscape assessment and analysis.\" In INTER-NOISE 2023 Conference\nJack Harvie-Clark, Rebecca Romeo Pitone, Luis Pereira, and Andrew Mitchell. (2023) \"Integrating acoustics engineering and soundscape design for an urban park: a case study.\" In Forum Acusticum 2023\n        \n        Published\n    \nYuanbo Hou, Andrew Mitchell, Qiaoqiao Ren, Francesco Aletta, Jian Kang, and Dick Botteldooren. (2023) \"Exploring annoyance in a soundscape context by joint prediction of sound source and annoyance.\" In Forum Acusticum 2023\nYuanbo Hou, Siyang Song, Cheg Luo, Andrew Mitchell, Qiaoqiao Ren, Jian Kang, Wenwu Want, and Dick Botteldooren. (2023) \"Joint prediction of audio event and annoyance rating in an urban soundscape by hierarchical graph representation learning.\" In 24th INTERSPEECH Conference\nJian Kang, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Mercede Erfanian. (2023) \"On the development of Soundscape Indices (SSID).\" In The 29th International Congress on Sound and Vibration\nJian Kang, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Mercede Erfanian. (2023) \"Subjective evaluation of environmental sounds in context - Towards Soundscape Indices (SSID).\" In Forum Acusticum 2023\nAndrew Mitchell, Francesco Aletta, Tin Oberman, Mercede Erfanian, and Jian Kang. (2023) \"A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraints, and applications.\" In INTER-NOISE 2023 Conference\nAndrew Mitchell, Emmeline Brown, Ratneel Deo, Yuanbo Hou, Jasper Kirton-Wingate, Jinhua Liang, Alisa Sheinkman, Christopher Soelistyo, Hari Sood, Arin Wongprommoon, Kaiyue Xing, Wingyan Yip, and Francesco Aletta. (2023) \"Deep learning techniques for noise annoyance detection: Results from an intensive workshop at the Alan Turing Institute.\" The Journal of the Acoustical Society of America doi: 10.1121/10.0018787 \n        \n        Published\n     \nAndrew Mitchell, Francesco Aletta, Tin Oberman, and Jian Kang. (2023) \"How do we define soundscape?.\" In Forum Acusticum 2023\n2022\nCleopatra Christina Moshona, Francesco Aletta, Helen Henze, Xiaochao Chen, Andrew Mitchell, Tin Oberman, Huan Tong, André Fiebig, Jian Kang, and Brigitte Schulte-Fortkamp. (2022) \"What is a soundscape intervention? Exploring definitions and identifi-cation criteria and a platform to gather real-world examples.\" In 51st International Congress and Exposition on Noise Control Engineering (INTER-NOISE 2022)\n        \n        Published\n    \n2021\nAndrew Mitchell, Tin Oberman, Francesco Aletta, and Jian Kang. (2021) \"Development of a multi-level predictive soundscape model to assess the soundscapes of public spaces during the COVID-19 lockdowns.\" The Journal of the Acoustical Society of America In 181st Meeting of the Acoustical Society of America doi: 10.1121/10.0008334 \n        \n        Published\n     \n2020\nRosa Ma Alsina-Pagès, Ferran Orga, Marc Freixes, Roger Mallol, Francesco Aletta, Andrew Mitchell, Jian Kang, and Maria Foraster. (2020) \"Urban environment soundscape evaluation: Milan case study of noise events perceptions by citizens.\" In INTER-NOISE and NOISE-CON Congress and Conference Proceedings\n        \n        Published\n    \n2019\nMercede Erfanian, Andrew Mitchell, and Jian Kang. (2019) \"The neurophysiology and physiology of soundscape: A review of the empirical literature.\" In The 6th European Conference on Psychology & the behavioral Sciences (ECP2019)\nJian Kang, Francesco Aletta, Tin Oberman, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Andrew Mitchell. (2019) \"Towards soundscape indices.\" Proceedings of the ICA 2019 and EAA Euroregio : 23rd International Congress on Acoustics In Proceedings of the 23rd International Congress on Acoustics doi: 10.18154/RWTH-CONV-239249 \n        \n        Published\n     \nAndrew Mitchell and Jian Kang. (2019) \"The spectral structure of acoustic time series can predict the perceptual assessment of urban soundscapes.\" In 178th Meeting of the Acoustical Society of America doi: 10.1121/1.5136681 \n        \n        Published\n     \nAndrew Mitchell, Francesco Aletta, Tin Oberman, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Jian Kang. (2019) \"Making cities smarter with new soundscape indices.\" In 178th Meeting of the Acoustical Society of America doi: 10.1121/1.5136970 \n        \n        Published\n     \nOther Publications\n2023\nData Study Group Team and Andrew Mitchell. (2023) \"Data Study Group Final Report: IEDE Acoustics Group, University College London Deep Learning Techniques for noise annoyance detection (DeLTA).\" doi: 10.5281/ZENODO.10090651 \n        \n        Published\n     \n2022\nAndrew Mitchell. (2022) \"Predictive Modelling of Complex Urban Soundscapes: Enabling an engineering approach to soundscape design.\" doi: 10.13140/RG.2.2.15590.50245 \n        \n        Published\n     \nAndrew Mitchell, Mercede Erfanian, Christopher Soelitsyo, Tin Oberman, and Francesco Aletta. (2022) \"DeLTA (Deep Learning Techniques for noise Annoyance detection) Dataset.\" doi: 10.5281/ZENODO.7158056 \n        \n        Published"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Appearance on Across Acoustics\n\n\n\n\n\n\n\npodcast\n\n\n\n\nI recently appeared on the official podcast of the Acoustical Society of America to talk about my paper which was published in JASA Express Letters last year.\n\n\n\n\n\n\nApr 14, 2023\n\n\nAndrew Mitchell\n\n\n\n\n\n\n  \n\n\n\n\nNavigating the UK Graduate Visa Process: A PhD Graduate’s Experience\n\n\n\n\n\n\n\nwebsite\n\n\n\n\n\n\n\n\n\n\n\nFeb 1, 2023\n\n\nAndrew Mitchell\n\n\n\n\n\n\n  \n\n\n\n\nContributing to the Pandemic Sensory Archive\n\n\n\n\n\n\n\npodcast\n\n\n\n\nIn 2021, I was interviewed by Dr William Tullett of Anglia Ruskin University in Cambridge. Dr Tullett created the Pandemic Sensory Archive “to explore bodies and senses through a digital platform, in light of experiences of the COVID-19 pandemic”.\n\n\n\n\n\n\nJun 9, 2021\n\n\nAndrew Mitchell\n\n\n\n\n\n\n  \n\n\n\n\nFirst paper published! SSID Protocol\n\n\n\n\n\n\n\n\n\n\n\n\nJun 19, 2020\n\n\nAndrew Mitchell\n\n\n\n\n\n\n  \n\n\n\n\nPhD Upgrade done and passed, thankfully!\n\n\n\n\n\n\n\nphd-life\n\n\n\n\n\n\n\n\n\n\n\nJun 19, 2020\n\n\nAndrew Mitchell\n\n\n\n\n\n\n  \n\n\n\n\nClustering analysis in R, with factoextra and NbClust\n\n\n\n\n\n\n\nsoundscape\n\n\nPhD\n\n\nmachine learning\n\n\n\n\nI recently gave a small talk on some packages I like using for doing clustering analysis in R. Here’s a brief introduction to some features of factoextra and NbClust\n\n\n\n\n\n\nJun 18, 2020\n\n\nAndrew Mitchell\n\n\n\n\n\n\n  \n\n\n\n\nBook Diary 3 - Foundation\n\n\n\n\n\n\n\nbook diary\n\n\npersonal\n\n\n\n\nFoundation by Isaac Asimov\n\n\n\n\n\n\nApr 9, 2020\n\n\nAndrew Mitchell\n\n\n\n\n\n\n  \n\n\n\n\nBook Diary 2 - Bad Science\n\n\n\n\n\n\n\nbook diary\n\n\npersonal\n\n\n\n\nA review of Ben Goldacre’s Bad Science\n\n\n\n\n\n\nMay 11, 2019\n\n\nAndrew Mitchell\n\n\n\n\n\n\n  \n\n\n\n\nBook Diary 1 - The Kingdom\n\n\n\n\n\n\n\nbook diary\n\n\npersonal\n\n\n\n\nThe Kingdom, by Emmanuel Carrère\n\n\n\n\n\n\nMay 10, 2019\n\n\nAndrew Mitchell\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2019-05-11_book-diary-2/index.html",
    "href": "posts/2019-05-11_book-diary-2/index.html",
    "title": "Book Diary 2 - Bad Science",
    "section": "",
    "text": "While I generally enjoyed the book, and I wholeheartedly support Goldacre’s goal and overall point, I was a bit disappointed by this book. I was initially inspired to pick it up by a friend recommending his book Bad Pharma.\nI had hoped that Bad Science would move away from his focus on medicine and turn instead to addressing mistakes and malpractice in science more generally. To my (only slight) disappointment, Goldacre hasn’t strayed far from his usual territory of medical frauds, mistakes, and hucksters.\nMy personal disappointment notwithstanding, this is in the end a well-written, well-researched, entertaining, and educational trawl through the depths of homeopaths and their overly diluted morals.\n\nAs always, I enjoy the insertion of personal details about the author, reminding me that there’s an actual person writing the words and that I’m allowed to both relate to and associate myself with the man behind the page, and to question and criticize him. Specific to this author was his mention of renting a small flat in Kentish Town on a junior medic’s salary – which I read while sat in a cafe next to my (smaller) flat in Kentish Town rented on a doctoral student’s stipend. While I suspect, with his multiple bestseller books, recognitions, and awards, Goldacre no longer rents a small flat in Kentish Town, it’d be nice to imagine having a friendly chat with him in the cafe.\nI felt the chapter ‘Pill Solves Complex Societal Problem’ was the most impactful. Here, Goldacre expands his discussion about the mechanics of poorly done science to address the media response to it and, more importantly, the potential motivations behind it. See this quote from page 154:\n\nBut above all we should pay tribute to the genius of this huge fish-oil project, and every other nutritionist who has gotten their pills into the media, and into schools, because more than anything else, they have sold children, at the most impressionable time of their lives, one very compelling message: that you need to take pills to lead a healthy normal life, and that a pill can even make up for failings elsewhere.\n\nWhat I can absolutely get behind is the view Goldacre reiterates over and over in the last few chapters: the blame for the dissemination of bad, misleading, or malicious science is not down to the bad actions of individual malevolent or ignorant scientists, but instead falls on the head of the system of media which not only allows this bad science to be spread, but encourages its spread. The individual scientists should absolutely be punished if wrong-doing is discovered, and bad practices should be stamped out, but the media system which publicises this work has a journalistic responsibility to look critically at everything it publishes. In general, it is more productive and more correct to lay the blame for societal issues at the feet of systems, not individuals.\n\nYou’ll notice, I hope, that I’m more interested in the cultural impact of nonsense – the medicalisation of everyday life, the undermining of sense – and in general I blame systems more than particular people. […] I do not blame individual journalists (for the most part) but I do blame whole systems of editors, and the people who buy newspapers with values to profess to despise.\n\n\nAs I’ve said, I thoroughly enjoyed Bad Science and I applaud Goldacre’s writing and his ability to distill the important aspects of scientific research into a wide-ranging and engaging discussion, but I hope he someday chooses to move beyond medicine and discuss ‘science’ more fully. As he notes in his afterword,\n\n…in the 1950s science reporting was about engineering and inventions, but by the 1990s everything had changed. Science coverage now tends to come from the world of medicine, and the stories are of what will kill you, or save you.\n\nPeople have forgotten that science can be about more than medicine and about more than our constant human obsession with death and illness, and I’d like to see more authors remind us of that.\nFurther reading: https://en.m.wikipedia.org/wiki/List_of_animals_with_fraudulent_diplomas\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/2019-05-10_book-diary-1/index.html",
    "href": "posts/2019-05-10_book-diary-1/index.html",
    "title": "Book Diary 1 - The Kingdom",
    "section": "",
    "text": "I’ve started writing short ‘reviews’ of all of the books I’m reading in a book diary I bought while in Venice. I decided I might as well sheare them here, so welcome to my book diary, starting with my favourite author, Emmanuel Carrère. These are not full reviews, they won’t give you really any background on the plot or context of the book. These were intended as notes to my future self looking back on the books I’ve read and so they are more personal, and, possibly, more intimate and engaging. I hope someone enjoys, even if it’s just old-man Andrew.\nI’ve read this several times now, and always come away with something different. This time, it is a terrible sadness and contemplation of love and life, so much so that I have written a letter to the author expressing it. Who knows if I’ll send it, and what his response will be.\nBut, what I should say is I LOVE this book. It satisfies my academic side with a wonderful semi-historical look at the writing of the early Bible and formation of the Church. Interspersed are stories from the author’s life and his reflections on authorship, on religiosity, on conversion.\nIt’s a gorgeously composed work of tremendous talent. Probably my favourite book I’ve ever read."
  },
  {
    "objectID": "posts/2019-05-10_book-diary-1/index.html#extra-info",
    "href": "posts/2019-05-10_book-diary-1/index.html#extra-info",
    "title": "Book Diary 1 - The Kingdom",
    "section": "Extra info:",
    "text": "Extra info:\nDate finished: March 10, 2019\nTitle: The Kingdom\nAuthor: Emmanuel Carrère\nPublisher: Penguin Random House UK\nDate Published: 2017\nBookstore/Library: Can’t remember\nSuggested/found by: The New Yorker Review"
  },
  {
    "objectID": "posts/phd-upgrade-done/index.html",
    "href": "posts/phd-upgrade-done/index.html",
    "title": "PhD Upgrade done and passed, thankfully!",
    "section": "",
    "text": "In the UK, halfway through the PhD we undergo a process known as the ‘upgrade’. The purpose is to take stock of our progress made so far and to determine whether we are likely to make it to the end of the PhD successfully. To do this, we present a seminar and prepare a report of our current progress before having a session with an internal panel where they ask further questions about your work and the existing state of the field. If the panel confirms that we have made adequate progress and have a good plan to finish, we can be upgraded to a PhD candidate. I always find it really helpful to look at previous examples of stuff like this, and wasn’t able to find many examples or much guidance on what it should look like. To help others, I’ve decided to host my report here, feel free to use it as an example, but remember it meets the requirements of my specific department at this time, and yours may differ.\nOn a side note, because this year is wild, I received the email letting me know I passed my PhD upgrade while kneeling in the Black Lives Matter demonstration in Parliament Square. It can be difficult to process the emotions of outrage and frustration simultaneously with relief and hope. I don’t have anything more profound to say on that, except that shit’s crazy but life trudges on. I’ll be back out at the protests this weekend.\nIt also means I had to finally settle on a decent thesis title, I landed on Machine Learning and Regression Modelling of Dynamic Urban Soundscapes: A multilevel approach.\nDownload Report\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/2020-06-18_cluster-analysis-in-r/index.html",
    "href": "posts/2020-06-18_cluster-analysis-in-r/index.html",
    "title": "Clustering analysis in R, with factoextra and NbClust",
    "section": "",
    "text": "factoextra:\n\nhttps://www.rdocumentation.org/packages/factoextra/versions/1.0.3\n\nNbClust:\n\nhttps://www.rdocumentation.org/packages/NbClust/versions/3.0\nhttps://www.jstatsoft.org/article/view/v061i06/v61i06.pdf\n\nThere are many libraries and functions in R for performing clustering analysis, so why look at these 2? Well, they solve two important challenges with clustering: visualisation and determining the optimal number of clusters.\nIn general, cluster analysis is an unsupervised machine learning task, meaning we don’t predefine a target output for the learning. For clustering, this mainly means that we don’t know what the categories will be before we start the analysis. We also don’t know how many clusters are present.\nMany indices have been created to help with determining the optimal number of clusters, however these each have their own advantages and disadvantages and often give conflicting results. We’ll demonstrate this by looking at the results from three popular graphical methods: elbow plot, silhouette, and gap statistic."
  },
  {
    "objectID": "posts/2020-06-18_cluster-analysis-in-r/index.html#clustering-analysis-libraries",
    "href": "posts/2020-06-18_cluster-analysis-in-r/index.html#clustering-analysis-libraries",
    "title": "Clustering analysis in R, with factoextra and NbClust",
    "section": "",
    "text": "factoextra:\n\nhttps://www.rdocumentation.org/packages/factoextra/versions/1.0.3\n\nNbClust:\n\nhttps://www.rdocumentation.org/packages/NbClust/versions/3.0\nhttps://www.jstatsoft.org/article/view/v061i06/v61i06.pdf\n\nThere are many libraries and functions in R for performing clustering analysis, so why look at these 2? Well, they solve two important challenges with clustering: visualisation and determining the optimal number of clusters.\nIn general, cluster analysis is an unsupervised machine learning task, meaning we don’t predefine a target output for the learning. For clustering, this mainly means that we don’t know what the categories will be before we start the analysis. We also don’t know how many clusters are present.\nMany indices have been created to help with determining the optimal number of clusters, however these each have their own advantages and disadvantages and often give conflicting results. We’ll demonstrate this by looking at the results from three popular graphical methods: elbow plot, silhouette, and gap statistic."
  },
  {
    "objectID": "posts/2020-06-18_cluster-analysis-in-r/index.html#dataset",
    "href": "posts/2020-06-18_cluster-analysis-in-r/index.html#dataset",
    "title": "Clustering analysis in R, with factoextra and NbClust",
    "section": "Dataset",
    "text": "Dataset\nWe’ll be looking at data from the Soundscape Indices (SSID) Database. This dataset contains data in-situ perceptual assessments of urban soundscapes, paired with acoustic and environmental data. For this set, we’ll be looking at the perceptual data only.\nTo collect the data, random members of the public were approached while in urban public spaces and asked to take a survey about how they perceive the sound environment. A section of the questions ask specifically about the perceived dominance of sound sources in the space. Sound sources are categorized as Traffic noise, Other noise, Human sounds, Natural sounds, and are rated from 1 [not at all] to 5 [dominates completely].\nThe data was collected across 27 locations in the UK, Italy, Spain, the Netherlands, and China. The goal here is to investigate whether these locations can be categorized based on their composition of sound sources.\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)  # Data processing and piping\n\n# Clustering libraries\nlibrary(factoextra) # Clustering and visualisation\nlibrary(NbClust)    # Optimal Number of Clusters\nlibrary(RCurl)      # For downloading data from Zenodo\n\ntemp.file &lt;- paste0(tempfile(), \".xlsx\")\ndownload.file(\"https://zenodo.org/record/5705908/files/SSID%20Lockdown%20Database%20VL0.2.2.xlsx\", temp.file, mode=\"wb\")\nssid.data &lt;- read_excel(temp.file)\n\nvars &lt;- c(\"Traffic\", \"Other\", \"Natural\", \"Human\")\n# vars &lt;- c(\"pleasant\", \"chaotic\", \"vibrant\", \"uneventful\", \"calm\", \"annoying\", \"eventful\", \"monotonous\")\n\n# Cutdown the dataset\nssid.data &lt;- ssid.data[c(\"GroupID\", \"SessionID\", \"LocationID\", vars)]\n\n# ssid.data &lt;- subset(ssid.data, Lockdown != 1)\n\n# Set GroupID, SessionID, Location as factor type\nssid.data &lt;- ssid.data %&gt;% mutate_at(vars(GroupID, SessionID, LocationID),\n                                     funs(as.factor))\nssid.data &lt;- ssid.data %&gt;% mutate_at(vars(vars),\n                                     funs(as.numeric))\n\n# Calculate the mean response for each GroupID\nssid.data &lt;- ssid.data %&gt;% \n    group_by(GroupID) %&gt;%\n    summarize(\n              Traffic = mean(Traffic, na.rm=TRUE),\n              Other = mean(Other, na.rm=TRUE),\n              Natural = mean(Natural, na.rm=TRUE),\n              Human = mean(Human, na.rm=TRUE),\n              # pleasant = mean(pleasant, na.rm = TRUE),\n              # chaotic = mean(chaotic, na.rm = TRUE),\n              # vibrant = mean(vibrant, na.rm = TRUE),\n              # uneventful = mean(uneventful, na.rm = TRUE),\n              # calm = mean(calm, na.rm = TRUE),\n              # annoying = mean(annoying, na.rm = TRUE),\n              # eventful = mean(eventful, na.rm = TRUE),\n              # monotonous = mean(monotonous, na.rm = TRUE),\n              LocationID = LocationID[1])\n\n# analysis.data$LocationID &lt;- unique(ssid.data[c('GroupID', 'LocationID')])['LocationID']\nssid.data &lt;- na.omit(ssid.data)\n\nknitr::kable(head(ssid.data))\n\n\n\n\n\nGroupID\nTraffic\nOther\nNatural\nHuman\nLocationID\n\n\n\n\nAM01\n1\n3.0\n1.0\n4.000000\nSanMarco\n\n\nAM02\n2\n1.5\n3.5\n4.000000\nSanMarco\n\n\nAM03\n1\n1.0\n2.0\n4.666667\nSanMarco\n\n\nAM05\n2\n2.0\n3.0\n1.000000\nSanMarco\n\n\nAM06\n1\n4.0\n1.5\n3.500000\nSanMarco\n\n\nAM07\n1\n1.0\n4.0\n4.000000\nSanMarco\n\n\n\n\n\nOur locations are:\n\n\nCode\nprint(levels(ssid.data$LocationID))\n\n\n [1] \"CamdenTown\"         \"EustonTap\"          \"MarchmontGarden\"   \n [4] \"MonumentoGaribaldi\" \"PancrasLock\"        \"RegentsParkFields\" \n [7] \"RegentsParkJapan\"   \"RussellSq\"          \"SanMarco\"          \n[10] \"StPaulsCross\"       \"StPaulsRow\"         \"TateModern\"        \n[13] \"TorringtonSq\""
  },
  {
    "objectID": "posts/2020-06-18_cluster-analysis-in-r/index.html#calculate-the-mean-value-for-each-location",
    "href": "posts/2020-06-18_cluster-analysis-in-r/index.html#calculate-the-mean-value-for-each-location",
    "title": "Clustering analysis in R, with factoextra and NbClust",
    "section": "Calculate the mean value for each Location",
    "text": "Calculate the mean value for each Location\nNote: If the data use different scales, they should always be standardised before clustering. In this case, all of the data are on the same scale, so we don’t need to worry.\n\n\nCode\nmeans &lt;- aggregate(ssid.data[c(vars)], by=list(ssid.data$LocationID), FUN=mean, na.rm=TRUE)\nmeans &lt;- data.frame(means[, -1], row.names = means[, 1])\n\nknitr::kable(means)\n\n\n\n\n\n\nTraffic\nOther\nNatural\nHuman\n\n\n\n\nCamdenTown\n3.787745\n2.652941\n1.316667\n3.219608\n\n\nEustonTap\n3.717857\n2.858929\n1.642262\n2.515476\n\n\nMarchmontGarden\n2.663542\n2.412500\n2.564583\n2.695833\n\n\nMonumentoGaribaldi\n1.903509\n1.885965\n2.982456\n3.254386\n\n\nPancrasLock\n2.457500\n3.144167\n2.391667\n2.453333\n\n\nRegentsParkFields\n2.422886\n1.911692\n3.148010\n2.866915\n\n\nRegentsParkJapan\n1.867179\n1.528718\n3.974103\n2.450000\n\n\nRussellSq\n2.668120\n2.027132\n3.334302\n2.987403\n\n\nSanMarco\n1.431852\n1.895926\n2.230370\n4.041852\n\n\nStPaulsCross\n2.503704\n2.000000\n2.266667\n3.311111\n\n\nStPaulsRow\n2.527132\n2.294574\n1.744186\n3.368217\n\n\nTateModern\n2.541667\n2.150833\n2.598333\n3.660833\n\n\nTorringtonSq\n3.230676\n2.848068\n1.957005\n3.269565"
  },
  {
    "objectID": "posts/2020-06-18_cluster-analysis-in-r/index.html#clustering-analysis",
    "href": "posts/2020-06-18_cluster-analysis-in-r/index.html#clustering-analysis",
    "title": "Clustering analysis in R, with factoextra and NbClust",
    "section": "Clustering Analysis",
    "text": "Clustering Analysis\n\nSome standard, single indices\nElbow plot (within-sum-of-squares), Silhouette, Gap statistic\n\n\nCode\nset.seed(123)\nfviz_nbclust(means, hcut, method=\"wss\", ggtheme = theme_bw())\n\n\n\n\n\nCode\nfviz_nbclust(means, hcut, method=\"silhouette\", ggtheme = theme_bw())\n\n\n\n\n\nCode\nfviz_nbclust(means, hcut, method=\"gap_stat\", ggtheme=theme_bw())\n\n\n\n\n\nAs we can see, it can be less than obvious how to interpret some of these - where exactly is the ‘elbow’ in the elbow plot? Silhouette pretty clearly says k = 2, but the Gap stat gives k = 1, which isn’t very useful. How do we know which is right?\n\n\n30 indices using NbClust\nNbClust\n\n\nCode\nindices = c(\"kl\", \"ch\", \"ccc\", \"cindex\", \"db\", \"silhouette\", \"duda\", \"pseudot2\", \"ratkowsky\", \"ptbiserial\", \"gap\", \"mcclain\", \"gamma\", \"gplus\", \"tau\",\"sdindex\", \"sdbw\")\nres &lt;- NbClust(data = means, distance='euclidean', min.nc = 2, max.nc=9, method=\"ward.D2\", index = \"alllong\")\n\n\nWarning in pf(beale, pp, df2): NaNs produced\n\n\n\n\n\n*** : The Hubert index is a graphical method of determining the number of clusters.\n                In the plot of Hubert index, we seek a significant knee that corresponds to a \n                significant increase of the value of the measure i.e the significant peak in Hubert\n                index second differences plot. \n \n\n\n\n\n\n*** : The D index is a graphical method of determining the number of clusters. \n                In the plot of D index, we seek a significant knee (the significant peak in Dindex\n                second differences plot) that corresponds to a significant increase of the value of\n                the measure. \n \n******************************************************************* \n* Among all indices:                                                \n* 9 proposed 2 as the best number of clusters \n* 4 proposed 3 as the best number of clusters \n* 2 proposed 4 as the best number of clusters \n* 1 proposed 5 as the best number of clusters \n* 4 proposed 6 as the best number of clusters \n* 1 proposed 7 as the best number of clusters \n* 2 proposed 8 as the best number of clusters \n* 5 proposed 9 as the best number of clusters \n\n                   ***** Conclusion *****                            \n \n* According to the majority rule, the best number of clusters is  2 \n \n \n******************************************************************* \n\n\nCode\nknitr::kable(res)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKL\nCH\nHartigan\nCCC\nScott\nMarriot\nTrCovW\nTraceW\nFriedman\nRubin\nCindex\nDB\nSilhouette\nDuda\nPseudot2\nBeale\nRatkowsky\nBall\nPtbiserial\nGap\nFrey\nMcClain\nGamma\nGplus\nTau\nDunn\nHubert\nSDindex\nDindex\nSDbw\n\n\n\n\n2\n1.0970\n8.1449\n6.0597\n7.5851\n102.6537\n30.2615\n13.4952\n10.1742\n351.3546\n36.9377\n0.4269\n0.8174\n0.3529\n0.6156\n4.9946\n1.3398\n0.3840\n5.0871\n0.5020\n-0.9326\n1.0370\n0.4096\n0.5903\n3.7821\n10.8974\n0.3539\n0.0753\n2.5622\n0.8042\n0.4459\n\n\n3\n1.1005\n8.4961\n5.2330\n6.3990\n119.6026\n18.4865\n5.5195\n6.5603\n404.1006\n57.2860\n0.3951\n1.0948\n0.2818\n0.4299\n5.3038\n2.5609\n0.4103\n2.1868\n0.4710\n-1.6230\n0.2765\n1.3913\n0.6265\n3.1026\n10.4103\n0.3626\n0.0800\n2.8643\n0.6523\n0.3387\n\n\n4\n1.6303\n9.3352\n3.5123\n5.9285\n136.6838\n8.8328\n2.0114\n4.3066\n514.5025\n87.2635\n0.5492\n0.8335\n0.3286\n2.5977\n-1.2301\n-0.9899\n0.4303\n1.0767\n0.4840\n-1.8404\n0.2171\n2.0924\n0.7560\n1.5513\n9.6154\n0.5689\n0.0773\n2.4025\n0.5465\n0.2559\n\n\n5\n0.8819\n9.4327\n4.1056\n5.4008\n150.1412\n4.9017\n0.9988\n3.0977\n615.3276\n121.3182\n0.5171\n0.6492\n0.4032\n2.6324\n-1.2402\n-0.9981\n0.4026\n0.6195\n0.4854\n-2.3510\n0.1834\n2.4726\n0.8391\n0.8718\n9.0897\n0.6139\n0.0863\n2.3482\n0.4455\n0.1689\n\n\n6\n2.4474\n10.7100\n1.9565\n5.2900\n170.5431\n1.4694\n0.3679\n2.0471\n969.8285\n183.5792\n0.5973\n0.5852\n0.4719\n1.8668\n-0.4643\n-0.5605\n0.3812\n0.3412\n0.4830\n-2.4797\n0.5241\n2.9403\n0.9529\n0.2051\n8.3077\n0.8559\n0.1062\n2.4432\n0.3528\n0.1185\n\n\n7\n0.9458\n10.0676\n1.9696\n4.5460\n183.1309\n0.7595\n0.2213\n1.5999\n1194.4928\n234.8889\n0.5305\n0.5508\n0.4589\n3.4939\n-0.7138\n-0.8616\n0.3578\n0.2286\n0.4476\n-2.9193\n0.8670\n3.6092\n0.9643\n0.1282\n6.9231\n0.8905\n0.1153\n3.0849\n0.2980\n0.0970\n\n\n8\n0.9554\n9.7863\n2.1072\n4.5678\n213.5276\n0.0957\n0.1542\n1.2045\n3652.8265\n311.9964\n0.4860\n0.4826\n0.5005\n3.0804\n-0.6754\n-0.8152\n0.3386\n0.1506\n0.3947\n-3.0908\n0.5258\n4.8153\n0.9537\n0.1282\n5.2821\n0.7320\n0.1161\n3.2357\n0.2402\n0.0697\n\n\n9\n0.9437\n9.9481\n2.5926\n3.7773\n235.4352\n0.0225\n0.0873\n0.8474\n6052.3637\n443.4830\n0.4147\n0.4100\n0.5619\n4.7507\n0.0000\n0.0000\n0.3219\n0.0942\n0.3339\n-3.4867\n0.1666\n7.0102\n0.9662\n0.0641\n3.6667\n0.7386\n0.1163\n3.4232\n0.1907\n0.0490\n\n\n\n\n\n\n\n\n\nCritValue_Duda\nCritValue_PseudoT2\nFvalue_Beale\nCritValue_Gap\n\n\n\n\n2\n0.2019\n31.6230\n0.2766\n0.7534\n\n\n3\n0.0160\n246.4030\n0.0787\n0.2949\n\n\n4\n-0.1694\n-13.8056\n1.0000\n0.6048\n\n\n5\n-0.1694\n-13.8056\n1.0000\n0.2346\n\n\n6\n-0.3257\n-4.0703\n1.0000\n0.5672\n\n\n7\n-0.3257\n-4.0703\n1.0000\n0.3163\n\n\n8\n-0.3257\n-4.0703\n1.0000\n0.5663\n\n\n9\n-0.5879\n0.0000\nNaN\n0.3864\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKL\nCH\nHartigan\nCCC\nScott\nMarriot\nTrCovW\nTraceW\nFriedman\nRubin\nCindex\nDB\nSilhouette\nDuda\nPseudoT2\nBeale\nRatkowsky\nBall\nPtBiserial\nGap\nFrey\nMcClain\nGamma\nGplus\nTau\nDunn\nHubert\nSDindex\nDindex\nSDbw\n\n\n\n\nNumber_clusters\n6.0000\n6.00\n6.0000\n2.0000\n8.0000\n4.0000\n3.0000\n3.0000\n8.000\n6.0000\n3.0000\n9.00\n9.0000\n2.0000\n2.0000\n2.0000\n4.0000\n3.0000\n2.000\n2.0000\n2.000\n2.0000\n9.0000\n9.0000\n2.0000\n7.0000\n0\n5.0000\n0\n9.000\n\n\nValue_Index\n2.4474\n10.71\n2.1492\n7.5851\n30.3968\n5.7226\n7.9756\n1.3603\n2458.334\n-10.9512\n0.3951\n0.41\n0.5619\n0.6156\n4.9946\n1.3398\n0.4303\n2.9003\n0.502\n-0.9326\n1.037\n0.4096\n0.9662\n0.0641\n10.8974\n0.8905\n0\n2.3482\n0\n0.049\n\n\n\n\n\n\n\n\n\nx\n\n\n\n\nCamdenTown\n1\n\n\nEustonTap\n1\n\n\nMarchmontGarden\n2\n\n\nMonumentoGaribaldi\n2\n\n\nPancrasLock\n2\n\n\nRegentsParkFields\n2\n\n\nRegentsParkJapan\n2\n\n\nRussellSq\n2\n\n\nSanMarco\n2\n\n\nStPaulsCross\n2\n\n\nStPaulsRow\n2\n\n\nTateModern\n2\n\n\nTorringtonSq\n1\n\n\n\n\n\n\n\n\n\n\nCode\nfviz_nbclust(res)\n\n\nError in if (class(best_nc) == \"numeric\") print(best_nc) else if (class(best_nc) == : the condition has length &gt; 1\n\n\n\n\nCode\nk = 2\nk.fit &lt;- kmeans(means, k)\nknitr::kable(k.fit)\n\n\nError in as.data.frame.default(x): cannot coerce class '\"kmeans\"' to a data.frame\n\n\nCode\nfviz_cluster(k.fit, means, repel=TRUE, ggtheme = theme_bw())\n\n\n\n\n\n\n\nCode\nres.pca &lt;- prcomp(means, scale=TRUE)\nfacto_summarize(res.pca, \"var\")\n\n\n           name      Dim.1      Dim.2     coord      cos2  contrib\nTraffic Traffic -0.8891690 -0.1531570 0.8140785 0.8140785 22.70701\nOther     Other -0.9153206 -0.1088317 0.8496561 0.8496561 23.69937\nNatural Natural  0.8316428 -0.5046107 0.9462617 0.9462617 26.39398\nHuman     Human  0.1897201  0.9690987 0.9751460 0.9751460 27.19965\n\n\nCode\nfviz_contrib(res.pca, \"var\")\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfit &lt;- eclust(means, \"kmeans\", k=k)\n\n\n\n\n\n\n\nCode\nh.fit &lt;- eclust(means, \"hclust\", k=k, stand = T, hc_method = \"ward.D2\")\n\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the factoextra package.\n  Please report the issue at &lt;https://github.com/kassambara/factoextra/issues&gt;.\n\n\nCode\nfviz_dend(h.fit, labels_track_height = 2.5, horiz=TRUE, rect = TRUE, cex = 0.5)"
  },
  {
    "objectID": "posts/2020-06-18_cluster-analysis-in-r/index.html#methods-i-havent-really-tested-out-thoroughly",
    "href": "posts/2020-06-18_cluster-analysis-in-r/index.html#methods-i-havent-really-tested-out-thoroughly",
    "title": "Clustering analysis in R, with factoextra and NbClust",
    "section": "Methods I haven’t really tested out thoroughly",
    "text": "Methods I haven’t really tested out thoroughly\n\n\nCode\nfviz_pca_biplot(res.pca, repel=T,ggtheme = theme_bw())\n\n\n\n\n\n\nfviz_silhouette()\nSilhouette (Si) analysis is a cluster validation approach that measures how well an observation is clustered and it estimates the average distance between clusters.\nDetails\n\nObservations with a large silhouette Si (almost 1) are very well clustered\nA small Si (around 0) means that the observation lies between two clusters\nObservations with a negative Si are probably placed in the wrong cluster\n\n\n\nCode\nfviz_silhouette(h.fit)\n\n\n  cluster size ave.sil.width\n1       1    5          0.32\n2       2    8          0.32\n\n\n\n\n\n\n\nget_clust_tendency\nBefore applying cluster methods, the first step is to assess whether the data is clusterable, a process defined as the assessing of clustering tendency. get_clust_tendency() assesses clustering tendency using Hopkins’ statistic and a visual approach.\nDetails\nHopkins Statistic: If the value of Hopkins statistic is close to 1 (far above 0.5), then we can conclude that the dataset is significantly clusterable.\n\n\n$hopkins_stat\n[1] 0.6977892\n\n$plot"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "I am currently a Senior Research Fellow at the Institute for Environmental Design & Engineering at University College London."
  },
  {
    "objectID": "cv.html#journal-papers",
    "href": "cv.html#journal-papers",
    "title": "Curriculum Vitae",
    "section": "Journal Papers",
    "text": "Journal Papers\n\n2024\nYuanbo Hou, Bo Kang, Andrew Mitchell, Wenwu Wang, Jian Kang, and Dick Botteldooren. (2024) \"Cooperative Scene-Event Modelling for Acoustic Scene Classification.\" IEEE/ACM Transactions on Audio, Speech, and Language Processing doi: 10.1109/TASLP.2023.3323135 \n        \n        Published\n     \n\n\n2023\nFrancesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, and Jian Kang. (2023) \"Soundscape experience of public spaces in different world regions: A comparison between the European and Chinese contexts via a large-scale on-site surveya).\" The Journal of the Acoustical Society of America doi: 10.1121/10.0020842 \n        \n        Published\n     \nYuanbo Hou, Qiaoqiao Ren, Huizhong Zhang, Andrew Mitchell, Francesco Aletta, Jian Kang, and Dick Botteldooren. (2023) \"AI-based soundscape analysis: Jointly identifying sound sources and predicting annoyancea).\" The Journal of the Acoustical Society of America doi: 10.1121/10.0022408 \n        \n        Published\n     \nJian Kang, Francesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, Huan Tong, Simone Torresin, Chunyang Xu, Tingting Yang, and Xiaochao Chen. (2023) \"Supportive soundscapes are crucial for sustainable environments.\" Science of The Total Environment doi: 10.1016/j.scitotenv.2022.158868 \n        \n        Published\n     \nNikolaos M. Papadakis, Francesco Aletta, Jian Kang, Tin Oberman, Andrew Mitchell, Ioanna Aroni, and Georgios E. Stavroulakis. (2023) \"City, town, village: Potential differences in residents soundscape perception using ISO/TS 12913-2:2018.\" Applied Acoustics doi: 10.1016/j.apacoust.2023.109659 \n        \n        Published\n     \nJerónimo Vida, José Antonio Almagro, Rafael García-Quesada, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Jian Kang. (2023) \"Soundscape attributes in Spanish: A comparison with the English version of the protocol proposed in Method A of the ISO/TS 12913–2.\" Applied Acoustics doi: 10.1016/j.apacoust.2023.109516 \n        \n        Published\n     \n\n\n2022\nAndrew Mitchell, Mercede Erfanian, Christopher Soelistyo, Tin Oberman, Jian Kang, Robert Aldridge, Jing-Hao Xue, and Francesco Aletta. (2022) \"Effects of Soundscape Complexity on Urban Noise Annoyance Ratings: A Large-Scale Online Listening Experiment.\" International Journal of Environmental Research and Public Health doi: 10.3390/ijerph192214872 \n        \n        Published\n     \nAndrew Mitchell, Francesco Aletta, and Jian Kang. (2022) \"How to analyse and represent quantitative soundscape data.\" JASA Express Letters doi: 10.1121/10.0009794 \n        \n        Published\n     \n\n\n2021\nMercede Erfanian, Andrew Mitchell, Francesco Aletta, and Jian Kang. (2021) \"Psychological well-being and demographic factors can mediate soundscape pleasantness and eventfulness: A large sample study.\" Journal of Environmental Psychology doi: 10.1016/j.jenvp.2021.101660 \n        \n        Published\n     \nMatteo Lionello, Francesco Aletta, Andrew Mitchell, and Jian Kang. (2021) \"Introducing a Method for Intervals Correction on Multiple Likert Scales: A Case Study on an Urban Soundscape Data Collection Instrument.\" Frontiers in Psychology doi: 10.3389/fpsyg.2020.602831 \n        \n        Published\n     \nAndrew Mitchell, Tin Oberman, Francesco Aletta, Magdalena Kachlicka, Matteo Lionello, Mercede Erfanian, and Jian Kang. (2021) \"Investigating urban soundscapes of the COVID-19 lockdown: A predictive soundscape modeling approach.\" The Journal of the Acoustical Society of America doi: 10.1121/10.0008928 \n        \n        Published\n     \nFerran Orga, Andrew Mitchell, Marc Freixes, Francesco Aletta, Rosa Ma Alsina-Pagès, and Maria Foraster. (2021) \"Multilevel Annoyance Modelling of Short Environmental Sound Recordings.\" Sustainability doi: 10.3390/su13115779 \n        \n        Published\n     \nHuan Tong, Francesco Aletta, Andrew Mitchell, Tin Oberman, and Jian Kang. (2021) \"Increases in noise complaints during the COVID-19 lockdown in Spring 2020: A case study in Greater London, UK.\" Science of The Total Environment doi: 10.1016/j.scitotenv.2021.147213 \n        \n        Published\n     \nJerónimo Vida Manzano, José Antonio Almagro Pastor, Rafael García Quesada, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Jian Kang. (2021) \"The \"sound of silence\" in Granada during the COVID-19 lockdown.\" Noise Mapping doi: 10.1515/noise-2021-0002 \n        \n        Published\n     \n\n\n2020\nFrancesco Aletta, Tin Oberman, Andrew Mitchell, Huan Tong, and Jian Kang. (2020) \"Assessing the changing urban sound environment during the COVID-19 lockdown period using short-term acoustic measurements.\" Noise Mapping doi: 10.1515/noise-2020-0011 \n        \n        Published\n     \nAndrew Mitchell, Tin Oberman, Francesco Aletta, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Jian Kang. (2020) \"The Soundscape Indices (SSID) Protocol: A Method for Urban Soundscape Surveys–Questionnaires with Acoustical and Contextual Information.\" Applied Sciences doi: 10.3390/app10072397 \n        \n        Published\n     \n\n\n2019\nFrancesco Aletta, Tin Oberman, Andrew Mitchell, Mercede Erfanian, Matteo Lionello, Magdalena Kachlicka, and Jian Kang. (2019) \"Associations between soundscape experience and self-reported wellbeing in open public urban spaces: A field study.\" The Lancet doi: 10.1016/s0140-6736(19)32814-4 \n        \n        Published\n     \nMercede Erfanian, Andrew J. Mitchell, Jian Kang, and Francesco Aletta. (2019) \"The Psychophysiological Implications of Soundscape: A Systematic Review of Empirical Literature and a Research Agenda.\" International Journal of Environmental Research and Public Health doi: 10.3390/ijerph16193533 \n        \n        Published"
  },
  {
    "objectID": "cv.html#conference-papers",
    "href": "cv.html#conference-papers",
    "title": "Curriculum Vitae",
    "section": "Conference Papers",
    "text": "Conference Papers\n\n2023\n Andrew Mitchell. (2023) \"Soundscapy: A python package for soundscape assessment and analysis.\" In INTER-NOISE 2023 Conference\nJack Harvie-Clark, Rebecca Romeo Pitone, Luis Pereira, and Andrew Mitchell. (2023) \"Integrating acoustics engineering and soundscape design for an urban park: a case study.\" In Forum Acusticum 2023\n        \n        Published\n    \nYuanbo Hou, Andrew Mitchell, Qiaoqiao Ren, Francesco Aletta, Jian Kang, and Dick Botteldooren. (2023) \"Exploring annoyance in a soundscape context by joint prediction of sound source and annoyance.\" In Forum Acusticum 2023\nYuanbo Hou, Siyang Song, Cheg Luo, Andrew Mitchell, Qiaoqiao Ren, Jian Kang, Wenwu Want, and Dick Botteldooren. (2023) \"Joint prediction of audio event and annoyance rating in an urban soundscape by hierarchical graph representation learning.\" In 24th INTERSPEECH Conference\nJian Kang, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Mercede Erfanian. (2023) \"On the development of Soundscape Indices (SSID).\" In The 29th International Congress on Sound and Vibration\nJian Kang, Francesco Aletta, Tin Oberman, Andrew Mitchell, and Mercede Erfanian. (2023) \"Subjective evaluation of environmental sounds in context - Towards Soundscape Indices (SSID).\" In Forum Acusticum 2023\nAndrew Mitchell, Francesco Aletta, Tin Oberman, Mercede Erfanian, and Jian Kang. (2023) \"A conceptual framework for the practical use of predictive models and Soundscape Indices: Goals, constraints, and applications.\" In INTER-NOISE 2023 Conference\nAndrew Mitchell, Emmeline Brown, Ratneel Deo, Yuanbo Hou, Jasper Kirton-Wingate, Jinhua Liang, Alisa Sheinkman, Christopher Soelistyo, Hari Sood, Arin Wongprommoon, Kaiyue Xing, Wingyan Yip, and Francesco Aletta. (2023) \"Deep learning techniques for noise annoyance detection: Results from an intensive workshop at the Alan Turing Institute.\" The Journal of the Acoustical Society of America doi: 10.1121/10.0018787 \n        \n        Published\n     \nAndrew Mitchell, Francesco Aletta, Tin Oberman, and Jian Kang. (2023) \"How do we define soundscape?.\" In Forum Acusticum 2023\n\n\n2022\nCleopatra Christina Moshona, Francesco Aletta, Helen Henze, Xiaochao Chen, Andrew Mitchell, Tin Oberman, Huan Tong, André Fiebig, Jian Kang, and Brigitte Schulte-Fortkamp. (2022) \"What is a soundscape intervention? Exploring definitions and identifi-cation criteria and a platform to gather real-world examples.\" In 51st International Congress and Exposition on Noise Control Engineering (INTER-NOISE 2022)\n        \n        Published\n    \n\n\n2021\nAndrew Mitchell, Tin Oberman, Francesco Aletta, and Jian Kang. (2021) \"Development of a multi-level predictive soundscape model to assess the soundscapes of public spaces during the COVID-19 lockdowns.\" The Journal of the Acoustical Society of America In 181st Meeting of the Acoustical Society of America doi: 10.1121/10.0008334 \n        \n        Published\n     \n\n\n2020\nRosa Ma Alsina-Pagès, Ferran Orga, Marc Freixes, Roger Mallol, Francesco Aletta, Andrew Mitchell, Jian Kang, and Maria Foraster. (2020) \"Urban environment soundscape evaluation: Milan case study of noise events perceptions by citizens.\" In INTER-NOISE and NOISE-CON Congress and Conference Proceedings\n        \n        Published\n    \n\n\n2019\nMercede Erfanian, Andrew Mitchell, and Jian Kang. (2019) \"The neurophysiology and physiology of soundscape: A review of the empirical literature.\" In The 6th European Conference on Psychology & the behavioral Sciences (ECP2019)\nJian Kang, Francesco Aletta, Tin Oberman, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Andrew Mitchell. (2019) \"Towards soundscape indices.\" Proceedings of the ICA 2019 and EAA Euroregio : 23rd International Congress on Acoustics In Proceedings of the 23rd International Congress on Acoustics doi: 10.18154/RWTH-CONV-239249 \n        \n        Published\n     \nAndrew Mitchell and Jian Kang. (2019) \"The spectral structure of acoustic time series can predict the perceptual assessment of urban soundscapes.\" In 178th Meeting of the Acoustical Society of America doi: 10.1121/1.5136681 \n        \n        Published\n     \nAndrew Mitchell, Francesco Aletta, Tin Oberman, Mercede Erfanian, Magdalena Kachlicka, Matteo Lionello, and Jian Kang. (2019) \"Making cities smarter with new soundscape indices.\" In 178th Meeting of the Acoustical Society of America doi: 10.1121/1.5136970 \n        \n        Published"
  },
  {
    "objectID": "cv.html#other-publications",
    "href": "cv.html#other-publications",
    "title": "Curriculum Vitae",
    "section": "Other Publications",
    "text": "Other Publications\n\n2023\nData Study Group Team and Andrew Mitchell. (2023) \"Data Study Group Final Report: IEDE Acoustics Group, University College London Deep Learning Techniques for noise annoyance detection (DeLTA).\" doi: 10.5281/ZENODO.10090651 \n        \n        Published\n     \n\n\n2022\nAndrew Mitchell. (2022) \"Predictive Modelling of Complex Urban Soundscapes: Enabling an engineering approach to soundscape design.\" doi: 10.13140/RG.2.2.15590.50245 \n        \n        Published\n     \nAndrew Mitchell, Mercede Erfanian, Christopher Soelitsyo, Tin Oberman, and Francesco Aletta. (2022) \"DeLTA (Deep Learning Techniques for noise Annoyance detection) Dataset.\" doi: 10.5281/ZENODO.7158056 \n        \n        Published"
  }
]